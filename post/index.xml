<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Posts on networkop</title>
    <link>https://networkop.co.uk/post/</link>
    <description>Recent content in Posts on networkop</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>&amp;copy; Michael Kashin 2018</copyright>
    <lastBuildDate>Sun, 01 Jan 2017 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="https://networkop.co.uk/post/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Multi-Vendor Network Simulations at Scale with meshnet-cni and vrnetlab</title>
      <link>https://networkop.co.uk/post/2019-01-k8s-vrnetlab/</link>
      <pubDate>Thu, 17 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>https://networkop.co.uk/post/2019-01-k8s-vrnetlab/</guid>
      <description>In the previous post I&amp;rsquo;ve demonstrated how to build virtual network topologies on top of Kubernetes with the help of meshnet-cni plugin. As an example, I&amp;rsquo;ve shown topologies with 50 cEOS instances and 250 Quagga nodes. In both of these examples virtual network devices were running natively inside Docker containers, meaning they were running as (a set of) processes directly attached to the TCP/IP stack of the network namespace provided by the k8s pod.</description>
    </item>
    
    <item>
      <title>Large-scale network simulations in Kubernetes, Part 2 - Network topology orchestration</title>
      <link>https://networkop.co.uk/post/2018-11-k8s-topo-p2/</link>
      <pubDate>Sat, 01 Dec 2018 00:00:00 +0000</pubDate>
      
      <guid>https://networkop.co.uk/post/2018-11-k8s-topo-p2/</guid>
      <description>In the previous post I&amp;rsquo;ve demonstrated a special-purpose CNI plugin for network simulations inside kubernetes called meshnet. I&amp;rsquo;ve shown how relatively easy it is to build a simple 3-node topology spread across multiple kubernetes nodes. However, when it comes to real-life large-scale topology simulations, using meshnet &amp;ldquo;as is&amp;rdquo; becomes problematic due to the following reasons:
 Uploading topology information into etcd requires a lot of manual effort. Any customisation like startup configuration injection or exposure of internal ports is still a manual process.</description>
    </item>
    
    <item>
      <title>Large-scale network simulations in Kubernetes, Part 1 - Building a CNI plugin</title>
      <link>https://networkop.co.uk/post/2018-11-k8s-topo-p1/</link>
      <pubDate>Fri, 02 Nov 2018 00:00:00 +0000</pubDate>
      
      <guid>https://networkop.co.uk/post/2018-11-k8s-topo-p1/</guid>
      <description>Building virtualised network topologies has been one of the best ways to learn new technologies and to test new designs before implementing them on a production network. There are plenty of tools that can help build arbitrary network topologies, some with an interactive GUI (e.g. GNS3 or EVE-NG/Unetlab) and some &amp;ldquo;headless&amp;rdquo;, with text-based configuration files (e.g. vrnetlab or topology-converter). All of these tools work by spinning up multiple instances of virtual devices and interconnecting them according to a user-defined topology.</description>
    </item>
    
    <item>
      <title>Serverless SDN - Network Engineering Analysis of Appswitch</title>
      <link>https://networkop.co.uk/post/2018-05-29-appswitch-sdn/</link>
      <pubDate>Thu, 21 Jun 2018 00:00:00 +0000</pubDate>
      
      <guid>https://networkop.co.uk/post/2018-05-29-appswitch-sdn/</guid>
      <description>Virtual networking has been one of the hottest areas of research and development in recent years. Kubernetes alone has, at the time of writing, 20 different networking plugins, some of which can be combined to build even more plugins. However, if we dig a bit deeper, most of these plugins and solutions are built out of two very simple constructs:
 a virtual switch - anything from a linux bridge through VPP and IOVisor to OVS ACL/NAT - most commonly implemented as iptables, with anything from netfilter to eBPF under the hood   Note1: for the purpose of this article I won&amp;rsquo;t consider service meshes as a network solution, although it clearly is one, simply because it operates higher than TCP/IP and ultimately still requires network plumbing to be in place</description>
    </item>
    
    <item>
      <title>The problem of unpredictable interface order in multi-network Docker containers</title>
      <link>https://networkop.co.uk/post/2018-03-03-docker-multinet/</link>
      <pubDate>Sat, 03 Mar 2018 00:00:00 +0000</pubDate>
      
      <guid>https://networkop.co.uk/post/2018-03-03-docker-multinet/</guid>
      <description>Whether we like it or not, the era of DevOps is upon us, fellow network engineers, and with it come opportunities to approach and solve common networking problems in new, innovative ways. One such problem is automated network change validation and testing in virtual environments, something I&amp;rsquo;ve already written about a few years ago. The biggest problem with my original approach was that I had to create a custom REST API SDK to work with a network simulation environment (UnetLab) that was never designed to be interacted with in a programmatic way.</description>
    </item>
    
    <item>
      <title>OpenStack SDN - OpenContrail With BGP VPN</title>
      <link>https://networkop.co.uk/blog/2018/01/02/os-contrail/</link>
      <pubDate>Tue, 02 Jan 2018 00:00:00 +0000</pubDate>
      
      <guid>https://networkop.co.uk/blog/2018/01/02/os-contrail/</guid>
      <description>Continuing on the trend started in my previous post about OpenDaylight, I&amp;rsquo;ll move on to the next open-source product that uses BGP VPNs for optimal North-South traffic forwarding. OpenContrail is one of the most popular SDN solutions for OpenStack. It was one of the first hybrid SDN solutions, offering both pure overlay and overlay/underlay integration. It is the default SDN platform of choice for Mirantis Cloud Platform, it has multiple large-scale deployments in companies like Workday and AT&amp;amp;T.</description>
    </item>
    
    <item>
      <title>OpenStack SDN - OpenDaylight With BGP VPN</title>
      <link>https://networkop.co.uk/blog/2017/12/15/os-odl-netvirt/</link>
      <pubDate>Fri, 15 Dec 2017 00:00:00 +0000</pubDate>
      
      <guid>https://networkop.co.uk/blog/2017/12/15/os-odl-netvirt/</guid>
      <description>For the last 5 years OpenStack has been the training ground for a lot of emerging DC SDN solutions. OpenStack integration use case was one of the most compelling and easiest to implement thanks to the limited and suboptimal implementation of the native networking stack. Today, in 2017, features like L2 population, local ARP responder, L2 gateway integration, distributed routing and service function chaining have all become available in vanilla OpenStack and don&amp;rsquo;t require a proprietary SDN controller anymore.</description>
    </item>
    
    <item>
      <title>OpenStack SDN - NFV Management and Orchestration</title>
      <link>https://networkop.co.uk/blog/2017/11/23/os-nfv-mano/</link>
      <pubDate>Thu, 23 Nov 2017 00:00:00 +0000</pubDate>
      
      <guid>https://networkop.co.uk/blog/2017/11/23/os-nfv-mano/</guid>
      <description>In the ongoing hysteria surrounding all things SDN, one important thing gets often overlooked. You don&amp;rsquo;t build SDN for its own sake. SDN is just a little cog in a big machine called &amp;ldquo;cloud&amp;rdquo;. To take it even further, I would argue that the best SDN solution is the one that you don&amp;rsquo;t know even exists. Despite what the big vendors tell you, operators are not supposed to interact with SDN interface, be it GUI or CLI.</description>
    </item>
    
    <item>
      <title>OpenStack SDN - Skydiving Into Service Function Chaining</title>
      <link>https://networkop.co.uk/blog/2017/09/15/os-sfc-skydive/</link>
      <pubDate>Fri, 15 Sep 2017 00:00:00 +0000</pubDate>
      
      <guid>https://networkop.co.uk/blog/2017/09/15/os-sfc-skydive/</guid>
      <description>SFC is another SDN feature that for a long time only used to be available in proprietary SDN solutions and that has recently become available in vanilla OpenStack. It serves as another proof that proprietary SDN solutions are losing the competitive edge, especially for Telco SDN/NFV use cases. Hopefully, by the end of this series of posts I&amp;rsquo;ll manage do demonstrate how to build a complete open-source solution that has feature parity (in terms of major networking features) with all the major proprietary data centre SDN platforms.</description>
    </item>
    
    <item>
      <title>OpenStack SDN - Building a Containerized OpenStack Lab</title>
      <link>https://networkop.co.uk/blog/2017/09/08/os-lab-docker/</link>
      <pubDate>Fri, 08 Sep 2017 00:00:00 +0000</pubDate>
      
      <guid>https://networkop.co.uk/blog/2017/09/08/os-lab-docker/</guid>
      <description>For quite a long time installation and deployment have been deemed as major barriers for OpenStack adoption. The classic &amp;ldquo;install everything manually&amp;rdquo; approach could only work in small production or lab environments and the ever increasing number of project under the &amp;ldquo;Big Tent&amp;rdquo; made service-by-service installation infeasible. This led to the rise of automated installers that over time evolved from a simple collection of scripts to container management systems.</description>
    </item>
    
    <item>
      <title>Linux SSH Session Management for Network Engineers</title>
      <link>https://networkop.co.uk/blog/2017/05/12/linux-ssh/</link>
      <pubDate>Fri, 12 May 2017 00:00:00 +0000</pubDate>
      
      <guid>https://networkop.co.uk/blog/2017/05/12/linux-ssh/</guid>
      <description>A few weeks ago I bought myself a new Dell XPS-13 and decided for the n-th time to go all-in Linux, that is to have Linux as the main and only laptop OS. Since most of my Linux experience is with Fedora-family distros, I quickly installed Fedora-25 and embarked on a long and painful journey of getting out of my Windows comfort zone and re-establishing it in Linux. One of the most important aspects for me, as a network engineer, is to have a streamlined process of accessing network devices.</description>
    </item>
    
    <item>
      <title>Using YANG Models in Ansible to Configure and Verify State of IOS-XE and JUNOS Devices</title>
      <link>https://networkop.co.uk/blog/2017/04/04/ansible-yang/</link>
      <pubDate>Tue, 04 Apr 2017 00:00:00 +0000</pubDate>
      
      <guid>https://networkop.co.uk/blog/2017/04/04/ansible-yang/</guid>
      <description>The idea of using Ansible for configuration changes and state verification is not new. However the approach I&amp;rsquo;m going to demonstrate in this post, using YANG and NETCONF, will have a few notable differences:
 I will not use any templates and absolutely no XML/JSON for device config generation All changes will be pushed through a single, vendor and model-independent Ansible module State verification will be done with no pattern-matching or screen-scraping All configuration and operational state will be based on a couple of YAML files To demonstrate the model-agnostic behaviour I will use a mixture of vendor&amp;rsquo;s native, IETF and OpenConfig YANG models  I hope this promise is exciting enough so without further ado, let&amp;rsquo;s get cracking.</description>
    </item>
    
    <item>
      <title>Configuring Cisco IOS XE With YANG-based YAML Files</title>
      <link>https://networkop.co.uk/blog/2017/03/13/yaml-yang/</link>
      <pubDate>Mon, 13 Mar 2017 00:00:00 +0000</pubDate>
      
      <guid>https://networkop.co.uk/blog/2017/03/13/yaml-yang/</guid>
      <description>XML, just like many more structured data formats, was not designed to be human-friendly. That&amp;rsquo;s why many network engineers lose interest in YANG as soon as the conversation gets to the XML part. JSON is a much more human-readable alternative, however very few devices support RESTCONF, and the ones that do may have buggy implementations. At the same time, a lot of network engineers have happily embraced Ansible, which extensively uses YAML.</description>
    </item>
    
    <item>
      <title>Configuring Cisco IOS XE With YDK and OpenDaylight</title>
      <link>https://networkop.co.uk/blog/2017/02/22/odl-ydk/</link>
      <pubDate>Wed, 22 Feb 2017 00:00:00 +0000</pubDate>
      
      <guid>https://networkop.co.uk/blog/2017/02/22/odl-ydk/</guid>
      <description>In the previous posts about NETCONF and RESTCONF I&amp;rsquo;ve demonstrated how to interact with Cisco IOS XE device directly from the Linux shell of my development VM. This approach works fine in some cases, e.g. whenever I setup a new DC fabric, I would make calls directly to the devices I&amp;rsquo;m configuring. However, it becomes impractical in the Ops world where change is constant and involves a large number of devices.</description>
    </item>
    
    <item>
      <title>Introduction to YANG Programming and RESTCONF on Cisco IOS XE</title>
      <link>https://networkop.co.uk/blog/2017/02/15/restconf-yang/</link>
      <pubDate>Wed, 15 Feb 2017 00:00:00 +0000</pubDate>
      
      <guid>https://networkop.co.uk/blog/2017/02/15/restconf-yang/</guid>
      <description>In the previous post I have demonstrated how to make changes to interface configuration of Cisco IOS XE device using the standard IETF model. In this post I&amp;rsquo;ll show how to use Cisco&amp;rsquo;s native YANG model to modify static IP routes. To make things even more interesting I&amp;rsquo;ll use RESTCONF, an HTTP-based sibling of NETCONF.
RESTCONF primer RESTCONF is a very close functional equivalent of NETCONF. Instead of SSH, RESTCONF relies on HTTP to interact with configuration data and operational state of the network device and encodes all exchanged data in either XML or JSON.</description>
    </item>
    
    <item>
      <title>Getting Started With NETCONF and YANG on Cisco IOS XE</title>
      <link>https://networkop.co.uk/blog/2017/01/25/netconf-intro/</link>
      <pubDate>Wed, 25 Jan 2017 00:00:00 +0000</pubDate>
      
      <guid>https://networkop.co.uk/blog/2017/01/25/netconf-intro/</guid>
      <description>To kick things off I will show how to use ncclient and pyang to configure interfaces on Cisco IOS XE device. In order to make sure everyone is on the same page and to provide some reference points for the remaining parts of the post, I would first need to cover some basic theory about NETCONF, XML and YANG.
NETCONF primer NETCONF is a network management protocol that runs over a secure transport (SSH, TLS etc.</description>
    </item>
    
    <item>
      <title>OpenStack SDN With OVN (Part 2) - Network Engineering Analysis</title>
      <link>https://networkop.co.uk/blog/2016/12/10/ovn-part2/</link>
      <pubDate>Sat, 10 Dec 2016 00:00:00 +0000</pubDate>
      
      <guid>https://networkop.co.uk/blog/2016/12/10/ovn-part2/</guid>
      <description>Table of Contents  OpenStack - virtual network topology OVN Northbound DB - logical network topology OVN Southbound DB - logical flows  L2 datapath L3 datapath  OVN Controller - OpenFlow flows Physical network - GENEVE overlay Conclusion   OpenStack - virtual network topology In the previous post we have installed OpenStack and created a simple virtual topology as shown below. In OpenStack&amp;rsquo;s data model this topology consists of the following elements:</description>
    </item>
    
    <item>
      <title>OpenStack SDN With OVN (Part 1) - Build and Install</title>
      <link>https://networkop.co.uk/blog/2016/11/27/ovn-part1/</link>
      <pubDate>Sun, 27 Nov 2016 00:00:00 +0000</pubDate>
      
      <guid>https://networkop.co.uk/blog/2016/11/27/ovn-part1/</guid>
      <description>Vanilla OpenStack networking has many functional, performance and scaling limitations. Projects like L2 population, local ARP responder, L2 Gateway and DVR were conceived to address those issues. However good a job these projects do, they still remain a collection of separate projects, each with its own limitations, configuration options and sets of dependencies. That led to an effort outside of OpenStack to develop a special-purpose OVS-only SDN controller that would address those issues in a centralised and consistent manner.</description>
    </item>
    
    <item>
      <title>Type-2 and Type-5 EPVN on vQFX 10k in UnetLab</title>
      <link>https://networkop.co.uk/blog/2016/10/26/qfx-unl/</link>
      <pubDate>Wed, 26 Oct 2016 00:00:00 +0000</pubDate>
      
      <guid>https://networkop.co.uk/blog/2016/10/26/qfx-unl/</guid>
      <description>News about UnetLab Those who read my blog regularly know that I&amp;rsquo;m a big fan of a network simulator called UnetLab. For the last two years I&amp;rsquo;ve done all my labbing in UNL and was constantly surprised by how extensible and stable it has been. I believe that projects like this are very important to our networking community because they help train the new generation of network engineers and enable them to expand their horizons.</description>
    </item>
    
    <item>
      <title>OpenStack SDN - Distributed Virtual Routing</title>
      <link>https://networkop.co.uk/blog/2016/10/13/os-dvr/</link>
      <pubDate>Thu, 13 Oct 2016 00:00:00 +0000</pubDate>
      
      <guid>https://networkop.co.uk/blog/2016/10/13/os-dvr/</guid>
      <description>Table of Contents  Virtual topology overview Virtual topology setup non-DVR traffic flow Enabling DVR DVR East-West traffic flow External connectivity  Case 1 - Overload NAT (VM2 with no FIP) Case 2 - Static NAT (VM1 with FIP)  DVR Pros and Cons   To be honest I was a little hesitant to write this post because the topic of Neutron&amp;rsquo;s DVR has already been exhaustively covered by many, including Assaf Muller, Eran Gampel and in the official OpenStack networking guide.</description>
    </item>
    
    <item>
      <title>Automating the Build of OpenStack Lab (Part 2)</title>
      <link>https://networkop.co.uk/blog/2016/09/09/os-lab-p2/</link>
      <pubDate>Fri, 09 Sep 2016 00:00:00 +0000</pubDate>
      
      <guid>https://networkop.co.uk/blog/2016/09/09/os-lab-p2/</guid>
      <description>In the last post we&amp;rsquo;ve seen how to use Chef to automate the build of a 3-node OpenStack cloud. The only thing remaining is to build an underlay network supporting communication between the nodes, which is what we&amp;rsquo;re going to do next. The build process will, again, be relatively simple and will include only a few manual steps, but before we get there let me go over some of the decisions and assumptions I&amp;rsquo;ve made in my network design.</description>
    </item>
    
    <item>
      <title>Automating the Build of OpenStack Lab (Part 1)</title>
      <link>https://networkop.co.uk/blog/2016/08/26/os-lab-p1/</link>
      <pubDate>Fri, 26 Aug 2016 00:00:00 +0000</pubDate>
      
      <guid>https://networkop.co.uk/blog/2016/08/26/os-lab-p1/</guid>
      <description>Now that I&amp;rsquo;m finally beginning to settle down at my new place of residence I can start spending more time on research and blogging. I have left off right before I was about to start exploring the native OpenStack distributed virtual routing function. However as I&amp;rsquo;d started rebuilding my OpenStack lab from scratch I realised that I was doing a lot of repetitive tasks which can be easily automated. Couple that with the fact that I needed to learn Chef for my new work and you&amp;rsquo;ve got this blogpost describing a few Chef cookbooks (similar to Ansible&amp;rsquo;s playbook) automating all those manual steps described in my earlier blogposts 1 and 2.</description>
    </item>
    
    <item>
      <title>OpenStack SDN - Interconnecting VMs and Physical Devices With Cumulus VX L2 Gateway</title>
      <link>https://networkop.co.uk/blog/2016/05/21/neutron-l2gw/</link>
      <pubDate>Sat, 21 May 2016 00:00:00 +0000</pubDate>
      
      <guid>https://networkop.co.uk/blog/2016/05/21/neutron-l2gw/</guid>
      <description>Since I have all my OpenStack environment running inside UNetLab, it makes it really easy for me to extend my L3 fabric with a switch from another vendor. In my previous posts I&amp;rsquo;ve used Cisco and Arista switches to build a 4-leaf 2-spine CLOS fabric. For this task I&amp;rsquo;ve decided to use a Cumulus VX switch which I&amp;rsquo;ve downloaded and imported into my lab.
To simulate the baremetal server (10.</description>
    </item>
    
    <item>
      <title>OpenStack SDN - Extending a L2 Provider Network Over a L3 Fabric</title>
      <link>https://networkop.co.uk/blog/2016/05/11/neutron-routed-extnet/</link>
      <pubDate>Wed, 11 May 2016 00:00:00 +0000</pubDate>
      
      <guid>https://networkop.co.uk/blog/2016/05/11/neutron-routed-extnet/</guid>
      <description>Provider vs Tenant networks Before we start, let&amp;rsquo;s recap the difference between the two major Neutron network types:
 Tenant networks are:  provisioned by tenants used for inter-VM (east-west) communication use Neutron virtual router as their default gateway  Provider networks are:  provisioned by OpenStack administrator(for use by tenants) match existing physical networks can be either flat (untagged VLAN) or VLAN-based (multiple VLANs) need to be L2 adjacent to network and/or compute nodes   These two network types are not mutually exclusive.</description>
    </item>
    
    <item>
      <title>OpenStack SDN - L2 Population and ARP Proxy</title>
      <link>https://networkop.co.uk/blog/2016/05/06/neutron-l2pop/</link>
      <pubDate>Fri, 06 May 2016 00:00:00 +0000</pubDate>
      
      <guid>https://networkop.co.uk/blog/2016/05/06/neutron-l2pop/</guid>
      <description>MAC learning in a controller-less VXLAN overlay VXLAN standard does not specify any control plane protocol to exchange MAC-IP bindings between VTEPs. Instead it relies on data plane flood-and-learn behaviour, just like a normal switch. To force this behaviour in an underlay, the standard stipulates that each VXLAN network should be mapped to its own multicast address and each VTEP participating in a network should join the corresponding multicast group.</description>
    </item>
    
    <item>
      <title>Network Engineering Analysis of OpenStack SDN</title>
      <link>https://networkop.co.uk/blog/2016/04/22/neutron-native/</link>
      <pubDate>Fri, 22 Apr 2016 00:00:00 +0000</pubDate>
      
      <guid>https://networkop.co.uk/blog/2016/04/22/neutron-native/</guid>
      <description>Table of Contents  Intro High Level Overview Unicast frame between VM1 and VM2 Unicast frame between VM1 and External host BUM frame from VM1 for MAC address of VM2 OpenvSwitch quick intro Detailed packet flow analysis Enumerating OVS ports Unicast frame between VM1 and VM2 Unicast frame to external host (192.168.247.1) BUM frame from VM1 for MAC address of VM2 Native OpenStack SDN advantages and limitation Things to explore next C2O References   Intro This is going to be quite a lengthy blogpost so I&amp;rsquo;ll try to explain its structure first.</description>
    </item>
    
    <item>
      <title>Building a Multi-node OpenStack Lab in UNetLab</title>
      <link>https://networkop.co.uk/blog/2016/04/18/os-unl-lab/</link>
      <pubDate>Tue, 19 Apr 2016 00:00:00 +0000</pubDate>
      
      <guid>https://networkop.co.uk/blog/2016/04/18/os-unl-lab/</guid>
      <description>OpenStack network requirements Depending on the number of deployed components, OpenStack physical network requirements could be different. In our case we&amp;rsquo;re not going to deploy any storage solution and simply use the ephemeral storage, i.e. hard disk that&amp;rsquo;s a part of a virtual machine. However, even in minimal installations, there are a number of networks that should be considered individually due to different connectivity requirements:
 Server OOB management network - this is usually a dedicated physical network used mainly for server bootstrapping and OS deployment.</description>
    </item>
    
    <item>
      <title>OpenStack on UNetlab</title>
      <link>https://networkop.co.uk/blog/2016/04/04/openstack-unl/</link>
      <pubDate>Mon, 04 Apr 2016 00:00:00 +0000</pubDate>
      
      <guid>https://networkop.co.uk/blog/2016/04/04/openstack-unl/</guid>
      <description>What the hell am I trying to do? I admit that running OpenStack on anything other than baremetal is nonsense. So why would anyone want to run it with two layers of virtualisation underneath? My goal is to explore some of the new SDN/NFV technologies without leaving the confines of my home area network and/or racking up a triple-digit electricity bill. I also wanted to be able to swap underlay networks without spending hours trying to plumb together virtualized switches and servers from multiple vendors.</description>
    </item>
    
    <item>
      <title>Network-CI Part 3 - OSPF to BGP Migration in Active/Standby DC</title>
      <link>https://networkop.co.uk/blog/2016/03/03/network-ci-demo-large/</link>
      <pubDate>Wed, 23 Mar 2016 00:00:00 +0000</pubDate>
      
      <guid>https://networkop.co.uk/blog/2016/03/03/network-ci-demo-large/</guid>
      <description>Current network overview Let&amp;rsquo;s start by taking a high-level look at our DC network routing topology. The core routing protocol is OSPF, it is responsible for distributing routing information between the Core and WAN layers of the network. WAN layer consists of two MPLS L3VPN services running BGP as PE-CE protocol and two DMVPN Hubs running EIGRP. All WAN layer devices perform mutual redistribution between the respective WAN protocol and OSPF.</description>
    </item>
    
    <item>
      <title>Network-CI Part 2 - Small Network Demo</title>
      <link>https://networkop.co.uk/blog/2016/03/03/network-ci-demo-small/</link>
      <pubDate>Thu, 03 Mar 2016 00:00:00 +0000</pubDate>
      
      <guid>https://networkop.co.uk/blog/2016/03/03/network-ci-demo-small/</guid>
      <description>Demo network overview The network consists of 4 nodes interconnected via point-to-point links and running EIGRP as a routing protocol.
To create a local development environment you can clone my repository and reset it to work with your own Github account using git remote set-url origin https://github.com/USERNAME/OTHERREPOSITORY.git command.
Local development environment contains the following files describing the modelled topology:
 Configuration files for each node under the ./config directory Network topology in .</description>
    </item>
    
    <item>
      <title>Network-CI Part 1 - Automatically Building a VM With UNetLab and Jenkins</title>
      <link>https://networkop.co.uk/blog/2016/02/25/network-ci-dev-setup/</link>
      <pubDate>Thu, 25 Feb 2016 00:00:00 +0000</pubDate>
      
      <guid>https://networkop.co.uk/blog/2016/02/25/network-ci-dev-setup/</guid>
      <description>Packer intro Packer is a tool that can automatically create virtual machines for different hypervisors and cloud platforms. The goal is to produce identically configured VMs for either VirtualBox, VMWare, Amazon or Google clouds based on a single template file. If you&amp;rsquo;re familiar with Vagrant, then you can also use Packer to create custom Vagrant boxes. In our case, however, we&amp;rsquo;re only concerned about VMWare since it&amp;rsquo;s the only type-2 hypervisor that supports nested hardware virtualisation (e.</description>
    </item>
    
    <item>
      <title>Network Continuous Integration and Delivery</title>
      <link>https://networkop.co.uk/blog/2016/02/19/network-ci-intro/</link>
      <pubDate>Fri, 19 Feb 2016 00:00:00 +0000</pubDate>
      
      <guid>https://networkop.co.uk/blog/2016/02/19/network-ci-intro/</guid>
      <description>CI/CD vs ITIL How do you implement changes in your network? In today&amp;rsquo;s world there&amp;rsquo;s 95% chance that you have to write up an RFC, submit it at least a week before the planned implementation date, go through at least one CAB meeting and only then, assuming it got approved, can you implement it. But the most important question is &amp;lsquo;how do you test&amp;rsquo;? Do you simply content yourself with a few pings or do you make sure all main routes are in place?</description>
    </item>
    
    <item>
      <title>REST for Network Engineers Part 3 - Advanced Operations With UnetLab</title>
      <link>https://networkop.co.uk/blog/2016/01/17/rest-unl-advanced/</link>
      <pubDate>Sun, 17 Jan 2016 00:00:00 +0000</pubDate>
      
      <guid>https://networkop.co.uk/blog/2016/01/17/rest-unl-advanced/</guid>
      <description>Extracting Node&amp;rsquo;s UUID In the previous post we have learned how to create a Node. To perform further actions on it we need to know it&amp;rsquo;s UUID. According to HTTP specification 201 - Created response SHOULD return a Location header with resource URI, which would contain resource UUID. However, UNetLab&amp;rsquo;s implementation does not return a Location header so we need to extract that information ourselves. To do that we&amp;rsquo;ll use the previously defined .</description>
    </item>
    
    <item>
      <title>REST for Network Engineers Part 2 - Basic Operations With UnetLab</title>
      <link>https://networkop.co.uk/blog/2016/01/06/rest-basic-operations/</link>
      <pubDate>Wed, 06 Jan 2016 00:00:00 +0000</pubDate>
      
      <guid>https://networkop.co.uk/blog/2016/01/06/rest-basic-operations/</guid>
      <description>REST SDK Design As it is with networks, design is a very crucial part of programming. I won&amp;rsquo;t pretend to be an expert in that field and merely present the way I&amp;rsquo;ve built REST SDK. Fortunately, a lot of design will mimic the objects and their relationship on the server side. I&amp;rsquo;ll slightly enhance it to improve code re-use and portability. Here are the basic objects:
 RestServer - implements basic application-agnostic HTTP CRUD logic UnlServer - an extension of a RestServer with specific authentication method (cookie-based) and several additional methods Device - an instance of a network device with specific attributes like type, image name, number of CPUs UnlLab - a lab instance existing inside a UnlServer UnlNode - a node instance existing inside a UnlLab UnlNet - a network instance also existing inside a UnlLab object  All these objects and their relationships are depicted on the following simplified UML diagram.</description>
    </item>
    
    <item>
      <title>REST for Network Engineers Part 1 - Development Environment Setup</title>
      <link>https://networkop.co.uk/blog/2016/01/03/dev-env-setup-rest/</link>
      <pubDate>Sun, 03 Jan 2016 00:00:00 +0000</pubDate>
      
      <guid>https://networkop.co.uk/blog/2016/01/03/dev-env-setup-rest/</guid>
      <description>UnetLab Installation Since UNL is a separate project with its own evolving documentation I won&amp;rsquo;t try to reproduce it in my blog and I&amp;rsquo;ll simply refer all my readers to UNL download page, UNL installation instructions and UNL first boot configuration.
At the time of writing UNL is distributed as an image packaged in Open Virtualization Format. I&amp;rsquo;m using VMWare Workstation as a type-2 hypervisor to import and run this image.</description>
    </item>
    
    <item>
      <title>REST API for Network Engineers</title>
      <link>https://networkop.co.uk/blog/2016/01/01/rest-for-neteng/</link>
      <pubDate>Fri, 01 Jan 2016 00:00:00 +0000</pubDate>
      
      <guid>https://networkop.co.uk/blog/2016/01/01/rest-for-neteng/</guid>
      <description>Management interface evolution Since the early dawn of networking, devices have been configured through VTYs. The transport has evolved from telnet to ssh but the underlying rule still maintained that network is configured manually, device-by-device by a human administrator. It&amp;rsquo;s obvious that this approach does not scale and is prone to human error, however it still remains the most prevalent method of network device configuration.
The first attempt to tackle these issues has been made in 1988 with the introduction of SNMP.</description>
    </item>
    
    <item>
      <title>Automating the Build of a FlexVPN Network</title>
      <link>https://networkop.co.uk/blog/2015/11/13/automating-flexvpn-config/</link>
      <pubDate>Fri, 13 Nov 2015 00:00:00 +0000</pubDate>
      
      <guid>https://networkop.co.uk/blog/2015/11/13/automating-flexvpn-config/</guid>
      <description>In this post I will also introduce two concepts that are frequently used in software development world - DRY and &amp;ldquo;Convention over Configuration&amp;rdquo;. This post is a precursor to the upcoming FlexVPN configuration post on Packetpushers.
FlexVPN network overview FlexVPN topology will consist of two FlexVPN &amp;ldquo;clouds&amp;rdquo;. Each cloud has a Hub router and multiple Spokes. Each Spoke is connected to each of the two Hubs thereby participating in both FlexVPN clouds.</description>
    </item>
    
    <item>
      <title>Automating New Network Build - Part 2 (BGP)</title>
      <link>https://networkop.co.uk/blog/2015/09/03/automating-bgp-config/</link>
      <pubDate>Thu, 03 Sep 2015 00:00:00 +0000</pubDate>
      
      <guid>https://networkop.co.uk/blog/2015/09/03/automating-bgp-config/</guid>
      <description>This is where configuration may get particularly messy especially in presence of backdoor links and complex routing failover policies. However, as I will show, it is still possible to create a standard set of routing manipulation policies and selectively apply them to the required adjacencies to achieve the desired effect.
Requirements and assumptions The new office network is designed with several layers of WAN redundancy. Primary WAN link is the preferred option to reach all other WAN destination except for the Main office which is connected via a dedicated high-throughput link.</description>
    </item>
    
    <item>
      <title>Automating New Network Build - Part 1</title>
      <link>https://networkop.co.uk/blog/2015/08/26/automating-network-build-p1/</link>
      <pubDate>Wed, 26 Aug 2015 00:00:00 +0000</pubDate>
      
      <guid>https://networkop.co.uk/blog/2015/08/26/automating-network-build-p1/</guid>
      <description>Prerequisites It is assumed that by this time all detailed network design information is known including interfaces numbers, VLANs, IP addresses and LAGs. This information will be used as an input to configuration automation scripts.
The inventory file is updated with a new branch-2 group
[branch-2] BR2-CORE ansible_ssh_host=10.0.3.1 BR2-WAN1 ansible_ssh_host=10.0.3.2 BR2-WAN2 ansible_ssh_host=10.0.3.3 BR2-AS01 ansible_ssh_host=10.0.3.130 BR2-AS02 ansible_ssh_host=10.0.3.131 BR2-AS03 ansible_ssh_host=10.0.3.132  Creating device bootstrap configuration A lot of times when building a new network it is required to create a bootstrap config that would have some basic AAA configuration along with the layer 2 and layer 3 links configuration.</description>
    </item>
    
    <item>
      <title>Automating Legacy Network Configuration</title>
      <link>https://networkop.co.uk/blog/2015/08/14/automating-legacy-networks/</link>
      <pubDate>Fri, 14 Aug 2015 00:00:00 +0000</pubDate>
      
      <guid>https://networkop.co.uk/blog/2015/08/14/automating-legacy-networks/</guid>
      <description>A lot of configuration files referenced throughout this post will be omitted for the sake of brevity, however all of them can be found in my github repository.
Legacy network overview The network I&amp;rsquo;m using for demonstration is a cut-down version of a typical enterprise network. At this point of time it consists of a branch office network and a central DC network interconnected via redundant WAN links. The branch office consists of a main computer room hosting all core network devices and interconnecting with access switches on each of the office floors.</description>
    </item>
    
    <item>
      <title>Network Configuration Automation</title>
      <link>https://networkop.co.uk/blog/2015/08/07/configuration-automation/</link>
      <pubDate>Fri, 07 Aug 2015 00:00:00 +0000</pubDate>
      
      <guid>https://networkop.co.uk/blog/2015/08/07/configuration-automation/</guid>
      <description>Automating Network Configuration Automation and programmability steadily make their way into a networking domain. The idea was born in application development world where makefiles served a role of automated installation scripts. It later spread into application testing and deployment so now hardly anyone does these two things by hand. Next in line were the operating systems largely thanks to the raising popularity of PaaS solutions. Until recently network configuration has been the prerogative of us, network engineers.</description>
    </item>
    
    <item>
      <title>Network TDD Quickstart Guide</title>
      <link>https://networkop.co.uk/blog/2015/07/17/tdd-quickstart/</link>
      <pubDate>Fri, 17 Jul 2015 00:00:00 +0000</pubDate>
      
      <guid>https://networkop.co.uk/blog/2015/07/17/tdd-quickstart/</guid>
      <description>Network overview Let&amp;rsquo;s assume you&amp;rsquo;re working in a proverbial Acme Inc. It has a Data Centre hosting all centralised services and a single office branch (Branch #1). Sites are interconnected using active/backup WAN links. The company decides to expand and adds a new office in a city nearby. In additional to standard dual WAN links it&amp;rsquo;s possible to buy a cheap and high throughput backdoor link between the two branches.</description>
    </item>
    
    <item>
      <title>Verifying TDD Scenarios</title>
      <link>https://networkop.co.uk/blog/2015/07/10/test-verification/</link>
      <pubDate>Fri, 10 Jul 2015 00:00:00 +0000</pubDate>
      
      <guid>https://networkop.co.uk/blog/2015/07/10/test-verification/</guid>
      <description>Now that Ansible has done all the information gathering for us it&amp;rsquo;s time to finally make use of it. In this post I will show how to use Ansible to run traceroutes from and to the hosts defined in a test scenario and perform verification of the results of those tests. Should any of those tests fail, Ansible will provide a meaningful description of what exactly failed and why. While doing all this I&amp;rsquo;ll introduce a couple of new Ansible features like conditional looping and interactive prompts.</description>
    </item>
    
    <item>
      <title>Developing Custom Ansible Modules</title>
      <link>https://networkop.co.uk/blog/2015/07/03/parser-modules/</link>
      <pubDate>Fri, 03 Jul 2015 00:00:00 +0000</pubDate>
      
      <guid>https://networkop.co.uk/blog/2015/07/03/parser-modules/</guid>
      <description>Ansible has a very neat feature called &amp;ldquo;fact gathering&amp;rdquo;, which collects useful information from hosts prior to executing any of the tasks and makes this information available for use within those tasks. Unfortunately, this also relies on Python being available on the remote machine which doesn&amp;rsquo;t work for Cisco IOS. In this post I&amp;rsquo;ll show how to write a simple module which will collect IP address information from remote devices and store it in global variable for future use.</description>
    </item>
    
    <item>
      <title>Getting Started With Ansible for Cisco IOS</title>
      <link>https://networkop.co.uk/blog/2015/06/24/ansible-intro/</link>
      <pubDate>Mon, 22 Jun 2015 00:00:00 +0000</pubDate>
      
      <guid>https://networkop.co.uk/blog/2015/06/24/ansible-intro/</guid>
      <description>Ansible is well-known for it&amp;rsquo;s low entry threshold. All what&amp;rsquo;s required to get started is just one inventory file. However Cisco IOS devices require special considerations. Passwordless SSH RSA-based authentication is still a novelty and in most cases users are authenticated based on their passwords. Another problem is the lack of Python execution environment on IOS devices, which seriously limits the choice of Ansible modules that can be used. In this post I will show how to setup Ansible environment to control Cisco IOS devices</description>
    </item>
    
    <item>
      <title>Windows-Linux File Synchronisation</title>
      <link>https://networkop.co.uk/blog/2015/06/22/dev-file-sync/</link>
      <pubDate>Mon, 22 Jun 2015 00:00:00 +0000</pubDate>
      
      <guid>https://networkop.co.uk/blog/2015/06/22/dev-file-sync/</guid>
      <description>My development environment usually consists of a host machine running Windows and a development Linux &amp;ldquo;headless&amp;rdquo; virtual machine. I create and edit files in a Notepad++ text editor and then transfer them over to the Linux VM. Until recently I&amp;rsquo;ve been using a hypervisor-enabled &amp;ldquo;shared&amp;rdquo; folder. However, Windows file system emulators in Linux do not support symbolic links and therefore breaks a lot of applications that rely on them. This prompted me to start looking for a new way to sync my files.</description>
    </item>
    
    <item>
      <title>Development Environment Setup</title>
      <link>https://networkop.co.uk/blog/2015/06/17/dev-env-setup/</link>
      <pubDate>Wed, 17 Jun 2015 00:00:00 +0000</pubDate>
      
      <guid>https://networkop.co.uk/blog/2015/06/17/dev-env-setup/</guid>
      <description>Before we proceed with TDD framework build it is important to have the development environment setup. In our case it will consist of two major components:
 Network Simulation Environment Ansible Development Environment  To simplify things I will run both of these environments on the same Virtual Machine. For network simulation I will use UnetLab, a wonderful product developed by Andrea Dainese. Currently, UnetLab is distributed as an OVA package and is available for free download on the website.</description>
    </item>
    
    <item>
      <title>Building a Simple Network TDD Framework</title>
      <link>https://networkop.co.uk/blog/2015/06/15/simple-tdd-framework/</link>
      <pubDate>Mon, 15 Jun 2015 00:00:00 +0000</pubDate>
      
      <guid>https://networkop.co.uk/blog/2015/06/15/simple-tdd-framework/</guid>
      <description>Before we begin (optional section) Before we go on, I&amp;rsquo;d like to put a little disclaimer about terms being used in this post. TDD, and its counterpart BDD, are well-known and accepted practices in development world. Both rely on the assumption that tests will be written before the code and will drive code development. This seemingly unnatural approach became extremely popular with the advent of Agile and is still being widely used, specifically in web development.</description>
    </item>
    
    <item>
      <title>iBGP Fall-over Trick</title>
      <link>https://networkop.co.uk/blog/2015/06/11/ibgp-fallover-trick/</link>
      <pubDate>Thu, 11 Jun 2015 00:00:00 +0000</pubDate>
      
      <guid>https://networkop.co.uk/blog/2015/06/11/ibgp-fallover-trick/</guid>
      <description>BGP fall-over is a neat BGP convergence optimisation technique whereby BGP peering is brought down as soon as the route to neighbor disappears from a routing table. The difference between external and internal BGP is that the former usually peers over a directly-attached interface so that when the interface to neighbor is disconnected, route is withdrawn from the routing table which triggers eBGP fall-over to bring down the neighborship. iBGP, on the other hand, normally uses device loopbacks to establish peering sessions.</description>
    </item>
    
    <item>
      <title>Structured Approach to Troubleshooting of L3VPN Networks</title>
      <link>https://networkop.co.uk/blog/2015/06/10/l3vpn-mpls-troubleshoot/</link>
      <pubDate>Wed, 10 Jun 2015 00:00:00 +0000</pubDate>
      
      <guid>https://networkop.co.uk/blog/2015/06/10/l3vpn-mpls-troubleshoot/</guid>
      <description>&lt;p&gt;With the amount of configuration involved in a typical L3VPN configuration, troubleshooting process can get pretty chaotic, especially
in a time-constrained environments like CCIE lab. That&amp;rsquo;s why it is extremely important to have a well-structured approach to quickly
narrow down the potential problem area. I used the below algorithm while preparing for my lab exam.
Like most of the networking problems, troubleshooting of L3VPNs can and must be split into two different phases - control plane and data plane.
All steps must be done sequentially with each next step relying on the successful verification of all previous steps.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://networkop.co.uk/img/l3vpn.jpg&#34; alt=&#34;Test topology&#34; /&gt;&lt;/p&gt;

&lt;dl&gt;
&lt;dt&gt;Problem definition&lt;/dt&gt;
&lt;dd&gt;CE-1 (10.0.0.1) can not reach CE-2 (10.0.0.2)&lt;/dd&gt;
&lt;/dl&gt;

&lt;p&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Best practices for enterprise IP routing</title>
      <link>https://networkop.co.uk/blog/2015/06/03/ent-ip-routing-bcp/</link>
      <pubDate>Fri, 05 Jun 2015 00:00:00 +0000</pubDate>
      
      <guid>https://networkop.co.uk/blog/2015/06/03/ent-ip-routing-bcp/</guid>
      <description>What motivated me to write this post is a state of the IP routing of some of the enterprise networks I&amp;rsquo;ve seen. A quick show ip route command reveals a non-disentanglable mixture of dynamic and static route with multiple points of redistribution and complex, rigid filtering rules, something you&amp;rsquo;d only see in your bad dream or a CCIE-level lab. It certainly takes a good engineer to understand how it works and even that can take up to several hours.</description>
    </item>
    
  </channel>
</rss>