<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>networkop on networkop</title>
    <link>https://networkop.co.uk/</link>
    <description>Recent content in networkop on networkop</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>&amp;copy; Michael Kashin 2018</copyright>
    <lastBuildDate>Sun, 15 Oct 2017 00:00:00 +0000</lastBuildDate>
    <atom:link href="/" rel="self" type="application/rss+xml" />
    
    <item>
      <title>Terraform your physical network with YANG</title>
      <link>https://networkop.co.uk/post/2019-04-tf-yang/</link>
      <pubDate>Thu, 11 Apr 2019 00:00:00 +0000</pubDate>
      
      <guid>https://networkop.co.uk/post/2019-04-tf-yang/</guid>
      <description>

&lt;p&gt;Every time when I get bored from my day job I tend to find some small interesting project that I can do that can give me an instant sense of accomplishment and as the result lift my spirits and improve motivation. So this time I remembered when someone once asked me if they could use Terraform to control their physical network devices and I had to explain how this is the wrong tool for the job. Somehow the question got stuck in my head and now it came to fruition in the form of &lt;a href=&#34;https://github.com/networkop/terraform-yang&#34; target=&#34;_blank&#34;&gt;terraform-yang&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;This is a small Terraform plugin (provider) that allows users to manipulate interface-level settings of a network device. And I&amp;rsquo;m not talking about a VM in the cloud that runs network OS of your favourite vendor, this stuff is trivial and doesn&amp;rsquo;t require anything special from Terraform. I&amp;rsquo;m talking about Terraform controlling your individual physical network devices over an OpenConfig&amp;rsquo;s gNMI interface with standard Create/Read/Update/Delete operations exposed all the way to Terraform&amp;rsquo;s playbooks (or whatever they are called). Network Infrastructure as code nirvana&amp;hellip;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://networkop.co.uk/img/tf-gnmi.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h2 id=&#34;writing-a-custom-terraform-provider-for-a-network-device&#34;&gt;Writing a custom Terraform provider for a network device&lt;/h2&gt;

&lt;p&gt;Although this may look scary at the beginning, the process of creating your own TF provider is fairly easy. In fact a provider is nothing but a pointer to a remote API, which from the client point of view is just a URL (or a session to that URL) along with the necessary authentication credentials. TF provider simply combines all that information in a struct, which is later made available to various resource-specific API calls. For a network device with a gNMI interface, this is all the work that needs to be done to initialise the provider:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;cfg := &amp;amp;gnmi.Config{
	Addr:     d.Get(&amp;quot;address&amp;quot;).(string),
	TLS:      d.Get(&amp;quot;tls&amp;quot;).(bool),
	Username: d.Get(&amp;quot;username&amp;quot;).(string),
	Password: d.Get(&amp;quot;password&amp;quot;).(string),
}
client, err := gnmi.Dial(cfg)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The only problem with this approach is that we have multiple devices and obviously it wouldn&amp;rsquo;t make sense to write a dedicated provider for each one. This is where Terraform &lt;a href=&#34;https://www.terraform.io/docs/configuration/providers.html#alias-multiple-provider-instances&#34; target=&#34;_blank&#34;&gt;aliases&lt;/a&gt; come to the rescue. With aliases we can define different providers that all use the same custom gNMI provider logic. This is how a &lt;code&gt;provider.tf&lt;/code&gt; file may look like:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;provider &amp;quot;gnmi&amp;quot; {
  alias    = &amp;quot;SW1&amp;quot;
  address  = &amp;quot;192.0.2.0:6030&amp;quot;
  username = &amp;quot;admin&amp;quot;
  password = &amp;quot;admin&amp;quot;
}

provider &amp;quot;gnmi&amp;quot; {
  alias    = &amp;quot;SW2&amp;quot;
  address  = &amp;quot;192.0.2.1:6030&amp;quot;
  username = &amp;quot;admin&amp;quot;
  password = &amp;quot;admin&amp;quot;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;writing-a-resource-for-an-interface&#34;&gt;Writing a resource for an interface&lt;/h2&gt;

&lt;p&gt;Most of the work and logic goes into resources. Each resource represents an object hosted by a provider, that can be manipulated, i.e. created, updated and deleted. For public clouds, this could be a VM, a disk or a security group. For my little experiment, I&amp;rsquo;ve picked the simplest (and most common) configuration object that exists on a network device - an interface. I didn&amp;rsquo;t have time to boil the ocean so I decided to expose only a subset of interface-level settings:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;description&lt;/li&gt;
&lt;li&gt;switchport flag&lt;/li&gt;
&lt;li&gt;IPv4 Address&lt;/li&gt;
&lt;li&gt;Access VLAN&lt;/li&gt;
&lt;li&gt;Trunk VLANs&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;In order to build the structured configuration data, I&amp;rsquo;m using Go structs generated by &lt;a href=&#34;https://github.com/openconfig/ygot&#34; target=&#34;_blank&#34;&gt;ygot&lt;/a&gt; based on OpenConfig&amp;rsquo;s YANG models. A little hint for those of you who&amp;rsquo;ve read my Ansible &amp;amp; YANG &lt;a href=&#34;https://networkop.co.uk/tags/ansible-yang/&#34; target=&#34;_blank&#34;&gt;series&lt;/a&gt; and know what pyangbind or YDK are: ygot to gNMI is what pyangbind/YDK is to ncclient. So to configure a new interface, I first build an empty struct skeleton with ygot, populate it with values inside &lt;a href=&#34;https://github.com/networkop/terraform-yang/blob/master/resource_interface.go#L64&#34; target=&#34;_blank&#34;&gt;&lt;code&gt;resourceInterfaceCreate()&lt;/code&gt;&lt;/a&gt; and then do &lt;code&gt;gnmi.Set()&lt;/code&gt; to send them off to the device. The logic for &lt;a href=&#34;https://github.com/networkop/terraform-yang/blob/master/resource_interface.go#L156&#34; target=&#34;_blank&#34;&gt;resource update&lt;/a&gt; is slightly more complicated since it should take into account mutually exclusive modes (e.g. switchport) and the behaviour when multiple conflicting arguments are defined. But ultimately you can decide how far you want to go and for a simple use case I&amp;rsquo;ve chosen, it only took me a few hours to &lt;a href=&#34;https://github.com/networkop/terraform-yang/blob/master/resource_interface.go#L64&#34; target=&#34;_blank&#34;&gt;codify&lt;/a&gt; the logic I wanted.&lt;/p&gt;

&lt;h2 id=&#34;using-a-gnmi-interface-resource&#34;&gt;Using a gNMI interface resource&lt;/h2&gt;

&lt;p&gt;With all of the provider/resource work done, making interface changes becomes really easy. Here&amp;rsquo;s an example of two different interfaces being configured on two different devices. The &lt;code&gt;provider&lt;/code&gt; argument points TF to one of the pre-defined aliases (i.e. network devices) and &lt;code&gt;name&lt;/code&gt; tells it which interface to configure. The rest of the arguments should be fairly self-explanatory.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;resource &amp;quot;gnmi_interface&amp;quot; &amp;quot;SW1_Eth1&amp;quot; {
    provider = &amp;quot;gnmi.SW1&amp;quot;
    name = &amp;quot;Ethernet1&amp;quot;
    description = &amp;quot;TF_INT_ETH1&amp;quot;
    switchport = false
    ipv4_address = &amp;quot;12.12.12.1/24&amp;quot;
}
resource &amp;quot;gnmi_interface&amp;quot; &amp;quot;SW2_Eth1&amp;quot; {
    provider = &amp;quot;gnmi.SW1&amp;quot;
    name = &amp;quot;Ethernet1&amp;quot;
    description = &amp;quot;TF_INT_ETH1&amp;quot;
    switchport = true
    trunk_vlans = [100, 200]
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;surprises-and-gotchas&#34;&gt;Surprises and Gotchas&lt;/h2&gt;

&lt;p&gt;While writing this plugin I&amp;rsquo;ve stumbled across several interesting and what I thought were surprising issues with gNMI and OpenConfig models in general.&lt;/p&gt;

&lt;p&gt;Firstly, because the gNMI spec is in a constant state of flux, the official &lt;a href=&#34;https://github.com/openconfig&#34; target=&#34;_blank&#34;&gt;tools&lt;/a&gt; may not work with your device out of the box. There may be slightly different implementations of gNMI/gRPC clients, which obviously make it difficult to operate in a multivendor environment.&lt;/p&gt;

&lt;p&gt;Second, I was surprised to discover that a lot of structured data is still encoded as JSON. This JSON is serialised into a string and later encoded as protobuf as it gets sent to the device but still, my naive assumption was that protobuf was used for everything.&lt;/p&gt;

&lt;p&gt;Third, there are still a lot of vendor augments to standard openconfig models, which results in a vendor-specific ygot code. This feels almost like we&amp;rsquo;ve gone back to automating vendor-specific CLIs with all their quirks and corner cases.&lt;/p&gt;

&lt;p&gt;Fourth, there&amp;rsquo;s still a lot of YANG&amp;lt;-&amp;gt;CLI translation going on under the hood, especially for the configuration part (less for telemetry), so always expect the unexpected.&lt;/p&gt;

&lt;p&gt;Finally, I was initially bemused by the gNMI message format. I didn&amp;rsquo;t understand why I can have multiple updates in a single notification message and what&amp;rsquo;s the purpose of &lt;a href=&#34;https://github.com/openconfig/reference/blob/master/rpc/gnmi/gnmi-specification.md#21-reusable-notification-message-format&#34; target=&#34;_blank&#34;&gt;duplicates&lt;/a&gt;. Until I realised that one of the primary use cases for gNMI was streaming telemetry and the protocol format was designed to work for both that and configuration updates. Some of these and other protocol-specific things still don&amp;rsquo;t make a lot of sense to me, and the &lt;a href=&#34;https://github.com/openconfig/reference/blob/master/rpc/gnmi/gnmi-specification.md#21-reusable-notification-message-format&#34; target=&#34;_blank&#34;&gt;GNMI specification&lt;/a&gt; doesn&amp;rsquo;t do a very good job explaining why (not sure if it&amp;rsquo;s even supposed to).&lt;/p&gt;

&lt;p&gt;But as I&amp;rsquo;ve said multiple times before, just having the gNMI support that we have today, is way, way much better than not having it and having to rely on vendor-specific CLIs.&lt;/p&gt;

&lt;h2 id=&#34;outro&#34;&gt;Outro&lt;/h2&gt;

&lt;p&gt;I always liked writing plugins. They may look like some serious piece of software but in reality, they&amp;rsquo;re just a bunch of for loops and conditionals, so writing them is really easy. Not only do you get all of the boilerplate code that exposes all the bells and whistles you might need, but you also have tons of production-grade examples of how to write this kind of stuff &lt;a href=&#34;https://github.com/terraform-providers&#34; target=&#34;_blank&#34;&gt;available on Github&lt;/a&gt;. So don&amp;rsquo;t treat &lt;a href=&#34;https://github.com/networkop/terraform-yang&#34; target=&#34;_blank&#34;&gt;terraform-yang&lt;/a&gt; as a serious project, this was just a proof-of-concept and a learning exercise. I&amp;rsquo;m not convinced this is the right way to configure your network, although I feel the same way about most of the other popular automation tools out there.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Multi-Vendor Network Simulations at Scale with meshnet-cni and vrnetlab</title>
      <link>https://networkop.co.uk/post/2019-01-k8s-vrnetlab/</link>
      <pubDate>Thu, 17 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>https://networkop.co.uk/post/2019-01-k8s-vrnetlab/</guid>
      <description>

&lt;p&gt;In the &lt;a href=&#34;https://networkop.co.uk/post/2018-11-k8s-topo-p2/&#34;&gt;previous post&lt;/a&gt; I&amp;rsquo;ve demonstrated how to build virtual network topologies on top of Kubernetes with the help of &lt;a href=&#34;https://github.com/networkop/meshnet-cni&#34; target=&#34;_blank&#34;&gt;meshnet-cni&lt;/a&gt; plugin. As an example, I&amp;rsquo;ve shown topologies with 50 cEOS instances and 250 Quagga nodes. In both of these examples virtual network devices were running natively inside Docker containers, meaning they were running as (a set of) processes directly attached to the TCP/IP stack of the network namespace provided by the k8s pod. This works well for the native docker images, however, the overwhelming majority of virtual network devices are still being released as VMs. In addition to that, some of them require more than one VM and some special bootstrapping before they can they can be used for the first time. This means that in order to perform true multi-vendor network simulations, we need to find a way to run VMs inside containers, which, despite the seeming absurdity, is quite a common thing to do.&lt;/p&gt;

&lt;h2 id=&#34;option-1-kubevirt&#34;&gt;Option 1 - kubevirt&lt;/h2&gt;

&lt;p&gt;Kubevirt is a very popular project that provides the ability to run VMs inside k8s. It uses the power of &lt;a href=&#34;https://kubernetes.io/docs/concepts/extend-kubernetes/api-extension/custom-resources/#customresourcedefinitions&#34; target=&#34;_blank&#34;&gt;Custom Resource Definitions&lt;/a&gt; to extend the native k8s API to allow the definition of VM parameters (libvirt domainxml) same as you would do for any other native k8s resource. It runs each VM inside the containerised KVM hypervisor, attaching them to libvirt-managed networking stack.&lt;/p&gt;

&lt;p&gt;However, since kubevirt is built for general-purpose VMs, making it work with virtual network devices requires a lot of work. Most of the bootstrapping tasks like startup configuration injection, disabling of ZTP and various OS-specific quirks like serial/video output selection for CSR or VCP reboot for VMX, would still need to be done after the pod is created. None of that is a major obstacle and hopefully virtual network OSs will also adopt standard server bootstrapping techniques like cloud-init, but until that happens we&amp;rsquo;d want to deal with those problems with as little effort as possible, which is where vrnetlab comes to the rescue.&lt;/p&gt;

&lt;h2 id=&#34;option-2-vrnetlab&#34;&gt;Option 2 - vrnetlab&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/plajjan/vrnetlab&#34; target=&#34;_blank&#34;&gt;vrnetlab&lt;/a&gt; is an open-source project that runs virtual network devices in Docker containers for &amp;ldquo;convenient labbing, development and testing&amp;rdquo;. At the time of writing, vrnetlab supported close to a dozen of virtual NOSs across most of the major vendors:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Cisco - CSR, NXOS and XRV&lt;/li&gt;
&lt;li&gt;Juniper - VMX and vQFX&lt;/li&gt;
&lt;li&gt;Arista - vEOS&lt;/li&gt;
&lt;li&gt;Nokia - VSR/SROS&lt;/li&gt;
&lt;li&gt;Huawei - VRP&lt;/li&gt;
&lt;li&gt;HP - VSR1000&lt;/li&gt;
&lt;li&gt;Mikrotik - ROS&lt;/li&gt;
&lt;li&gt;OpenWRT&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The way I see it, vrnetlab accomplishes two things:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Automates generation of Docker images from the original qcow2 or vmdk files&lt;/li&gt;
&lt;li&gt;Interconnect virtual routers based on the user-defined topology&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;The above two things are loosely coupled and although vrnetlab docker images are built to expose VM&amp;rsquo;s network interfaces as TCP sockets (stitched together by the topology machine later), it&amp;rsquo;s still possible to use them for other purposes. My specific interest was to try and run vrnetlab images inside the kubernetes cluster with networking orchestrated by meshnet-cni.&lt;/p&gt;

&lt;h2 id=&#34;patching-vrnetlab&#34;&gt;Patching vrnetlab&lt;/h2&gt;

&lt;p&gt;Making it work turned out to be easier than I thought. All that I had to do was introduce a flag to control how the network interfaces are connected and add a special case for meshnet. This is a high-level logic of how the patch works:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;vrnetlab images now accept an additional optional argument called &lt;code&gt;--meshnet&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;this argument controls whether to connect VM to native docker interfaces or use the default TCP socket option&lt;/li&gt;
&lt;li&gt;for every ethernet interface inside a container a bridge is created, enslaving this interface&lt;/li&gt;
&lt;li&gt;VM is now attached to each one of those bridges instead of the TCP sockets&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;This patch is still in a &lt;a href=&#34;https://github.com/plajjan/vrnetlab/pull/188&#34; target=&#34;_blank&#34;&gt;pull request&lt;/a&gt; waiting to be tested so for the rest of this post I&amp;rsquo;ll be using &lt;a href=&#34;https://github.com/networkop/vrnetlab&#34; target=&#34;_blank&#34;&gt;my fork&lt;/a&gt;, which has all of these changes already merged.&lt;/p&gt;

&lt;h2 id=&#34;demo&#34;&gt;Demo&lt;/h2&gt;

&lt;p&gt;I&amp;rsquo;ll assume that the Kubernetes cluster is already installed along with both &lt;a href=&#34;https://networkop.co.uk/post/2018-11-k8s-topo-p1/&#34;&gt;meshnet-cni&lt;/a&gt; and &lt;a href=&#34;https://networkop.co.uk/post/2018-11-k8s-topo-p2/&#34;&gt;k8s-topo&lt;/a&gt;. For demonstration purposes, I&amp;rsquo;ll use a random topology with a mix of Juniper vMX (v17.2R1.13) and Cisco CSR1000v (v16.04.01) devices, both built using vrnetlab.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://networkop.co.uk/img/k8s-vrnetlab.png&#34; alt=&#34;vrnetlab topology&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;building-images&#34;&gt;Building images&lt;/h3&gt;

&lt;p&gt;The first thing to do is download the patched version of vrnetlab:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;git clone --depth 1 https://github.com/networkop/vrnetlab.git
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Now copy both images into their respective directories and for each one of them run:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;make docker-image
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The expected result is to have two local images that look something like this:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;core@node1 ~ $ docker images | grep vrnetlab
vrnetlab/vr-csr   16.04.01    b701e7811221   2 days ago   1.76GB
vrnetlab/vr-vmx   17.2R1.13   9a6af68dde78   2 days ago   4.7GB
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;uploading-images-to-a-private-registry&#34;&gt;Uploading images to a private registry&lt;/h3&gt;

&lt;p&gt;Now we need to make these images available to all nodes in the cluster and the easiest way to do that is to upload them into a private docker registry. So from a node with cluster credentials, create a local registry:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;kubectl create -f https://raw.githubusercontent.com/networkop/k8s-topo/master/examples/docker-registry/docker-registry.yml
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Now use the service IP to create the registry URL variable:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;export REGISTRY=$(kubectl get service docker-registry -o json | jq -r &#39;.spec.clusterIP&#39;):5000
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Assuming both images are stored on the localhost do:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;docker tag vrnetlab/vr-csr:16.04.01 $REGISTRY/vr-csr:16.04.01
docker push $REGISTRY/vr-csr:16.04.01

docker tag vrnetlab/vr-vmx:17.2R1.13 $REGISTRY/vr-vmx:17.2R1.13
docker push $REGISTRY/vr-vmx:17.2R1.13
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Once uploaded, we can query the following registry URL to confirm that:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;curl -X GET http://$REGISTRY/v2/_catalog
{&amp;quot;repositories&amp;quot;:[&amp;quot;vr-csr&amp;quot;,&amp;quot;vr-vmx&amp;quot;]}
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;creating-the-network-topology&#34;&gt;Creating the network topology&lt;/h3&gt;

&lt;p&gt;First, connect to the k8s-topo pod:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;kubectl exec -it k8s-topo sh
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Create the image URL environment variables for both CSR and vMX. These will later be used by the &lt;code&gt;k8s-topo&lt;/code&gt; script.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;export REGISTRY=$(kubectl get service docker-registry -o json | jq -r &#39;.spec.clusterIP&#39;):5000
export CSR_IMAGE=$REGISTRY/vr-csr:16.04.01
export VMX_IMAGE=$REGISTRY/vr-vmx:17.2R1.13
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Generate a random spanning-tree topology with a mix of vmx and csr devices. The prefix argument accepts a list of one or more prefixes which determine the image to be used for the device.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;./examples/builder/builder 20 0 --prefix vmx csr
Total number of links generated: 19
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Now use the &lt;code&gt;k8s-topo&lt;/code&gt; script to create the topology and corresponding services:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;./bin/k8s-topo --create examples/builder/random.yml 
INFO:__main__:All data has been uploaded to etcd
INFO:__main__:All pods have been created successfully
INFO:__main__:
 alias csr-8=&#39;ssh -p 30010 vrnetlab@localhost&#39;
 alias vmx-15=&#39;ssh -p 30014 vrnetlab@localhost&#39;
 alias csr-4=&#39;ssh -p 30008 vrnetlab@localhost&#39;
 alias csr-14=&#39;ssh -p 30003 vrnetlab@localhost&#39;
 alias vmx-19=&#39;ssh -p 30016 vrnetlab@localhost&#39;
 alias vmx-11=&#39;ssh -p 30012 vrnetlab@localhost&#39;
 alias vmx-5=&#39;ssh -p 30018 vrnetlab@localhost&#39;
 alias csr-20=&#39;ssh -p 30007 vrnetlab@localhost&#39;
 alias csr-16=&#39;ssh -p 30004 vrnetlab@localhost&#39;
 alias csr-10=&#39;ssh -p 30001 vrnetlab@localhost&#39;
 alias vmx-1=&#39;ssh -p 30011 vrnetlab@localhost&#39;
 alias csr-2=&#39;ssh -p 30006 vrnetlab@localhost&#39;
 alias vmx-13=&#39;ssh -p 30013 vrnetlab@localhost&#39;
 alias vmx-17=&#39;ssh -p 30015 vrnetlab@localhost&#39;
 alias csr-12=&#39;ssh -p 30002 vrnetlab@localhost&#39;
 alias csr-18=&#39;ssh -p 30005 vrnetlab@localhost&#39;
 alias csr-6=&#39;ssh -p 30009 vrnetlab@localhost&#39;
 alias vmx-7=&#39;ssh -p 30019 vrnetlab@localhost&#39;
 alias vmx-9=&#39;ssh -p 30020 vrnetlab@localhost&#39;
 alias vmx-3=&#39;ssh -p 30017 vrnetlab@localhost&#39;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;If LLDP is required between nodes, it can be enabled with this command:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;./bin/k8s-topo --lldp examples/builder/random.yml 
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;verification&#34;&gt;Verification&lt;/h3&gt;

&lt;p&gt;Finally, it&amp;rsquo;s time to verify the connectivity between the nodes. Since all of the devices come up with minimal configuration, I&amp;rsquo;ll pick a random pair to demonstrate the LLDP and IP connectivity:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ vmx-11
Warning: Permanently added &#39;[localhost]:30012&#39; (ECDSA) to the list of known hosts.
Password:
--- JUNOS 17.2R1.13 Kernel 64-bit  JNPR-10.3-20170523.350481_build
vrnetlab&amp;gt; configure 
Entering configuration mode
vrnetlab# set interfaces ge-0/0/3 unit 0 family inet address 12.12.12.1/24 
vrnetlab# set protocols lldp interface all 
vrnetlab# set protocols lldp port-id-subtype interface-name 
vrnetlab# commit and-quit 
commit complete
Exiting configuration mode
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;And now configure the other side of the link:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ csr-6
Warning: Permanently added &#39;[localhost]:30009&#39; (RSA) to the list of known hosts.
Password: 

csr1000v#conf t
Enter configuration commands, one per line.  End with CNTL/Z.
csr1000v(config)#lldp run
csr1000v(config)#int gigabitEthernet 2
csr1000v(config-if)#ip address 12.12.12.2 255.255.255.0
csr1000v(config-if)#no shut
csr1000v(config-if)#exit
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;At this point, both devices should be able to ping and see each other as LLDP neighbors.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;csr1000v#sh lldp neighbors 
Capability codes:
    (R) Router, (B) Bridge, (T) Telephone, (C) DOCSIS Cable Device
    (W) WLAN Access Point, (P) Repeater, (S) Station, (O) Other

Device ID           Local Intf     Hold-time  Capability      Port ID
0005.86f0.f7c0      Gi2            120        B,R             ge-0/0/3

Total entries displayed: 1

csr1000v#ping 12.12.12.1
Type escape sequence to abort.
Sending 5, 100-byte ICMP Echos to 12.12.12.1, timeout is 2 seconds:
!!!!!
Success rate is 100 percent (5/5), round-trip min/avg/max = 2/8/18 ms
csr1000v#
&lt;/code&gt;&lt;/pre&gt;
</description>
    </item>
    
    <item>
      <title>Large-scale network simulations in Kubernetes, Part 2 - Network topology orchestration</title>
      <link>https://networkop.co.uk/post/2018-11-k8s-topo-p2/</link>
      <pubDate>Sat, 01 Dec 2018 00:00:00 +0000</pubDate>
      
      <guid>https://networkop.co.uk/post/2018-11-k8s-topo-p2/</guid>
      <description>

&lt;p&gt;In the &lt;a href=&#34;https://networkop.co.uk/post/2018-11-k8s-topo-p1/&#34;&gt;previous post&lt;/a&gt; I&amp;rsquo;ve demonstrated a special-purpose CNI plugin for network simulations inside kubernetes called &lt;a href=&#34;https://github.com/networkop/meshnet-cni&#34; target=&#34;_blank&#34;&gt;meshnet&lt;/a&gt;. I&amp;rsquo;ve shown how relatively easy it is to build a simple 3-node topology spread across multiple kubernetes nodes. However, when it comes to real-life large-scale topology simulations, using meshnet &amp;ldquo;as is&amp;rdquo; becomes problematic due to the following reasons:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Uploading topology information into etcd requires a lot of manual effort.&lt;/li&gt;
&lt;li&gt;Any customisation like startup configuration injection or exposure of internal ports is still a manual process.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;That is why I built &lt;a href=&#34;https://github.com/networkop/k8s-topo&#34; target=&#34;_blank&#34;&gt;k8s-topo&lt;/a&gt; - an orchestrator for network simulations inside kubernetes. It automates a lot of these manual steps and provides a simple and user-friendly interface to create networks of any size and configuration.&lt;/p&gt;

&lt;h1 id=&#34;k8s-topo-overview&#34;&gt;k8s-topo overview&lt;/h1&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/networkop/k8s-topo&#34; target=&#34;_blank&#34;&gt;k8s-topo&lt;/a&gt; is a Python script that creates network topologies inside k8s based on a simple YAML file. It uses syntax similar to &lt;a href=&#34;https://github.com/networkop/arista-ceos-topo&#34; target=&#34;_blank&#34;&gt;docker-topo&lt;/a&gt; with a few modifications to account for the specifics of kubernetes environment. For instance, the following file is all what&amp;rsquo;s required to create and configure a simple 3-node topology:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-yaml&#34;&gt;etcd_port: 32379
links:
  - endpoints: [&amp;quot;host-1:eth1:12.12.12.1/24&amp;quot;, &amp;quot;host-2:eth1:12.12.12.2/24&amp;quot;]
  - endpoints: [&amp;quot;host-1:eth2:13.13.13.1/24&amp;quot;, &amp;quot;host-3:eth1:13.13.13.3/24&amp;quot;]
  - endpoints: [&amp;quot;host-2:eth2:23.23.23.2/24&amp;quot;, &amp;quot;host-3:eth2:23.23.23.3/24&amp;quot;]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Behind the scenes it uses &lt;a href=&#34;https://github.com/kubernetes-client/python&#34; target=&#34;_blank&#34;&gt;kubernetes&lt;/a&gt; and &lt;a href=&#34;https://github.com/kragniz/python-etcd3&#34; target=&#34;_blank&#34;&gt;etcd&lt;/a&gt; python libraries to accomplish the following things:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Upload topology information into etcd&lt;/li&gt;
&lt;li&gt;Create a pod for each network device mentioned in the topology file&lt;/li&gt;
&lt;li&gt;If present, mount devices startup configuration as volumes inside pods&lt;/li&gt;
&lt;li&gt;Expose internal HTTPs port as a &lt;a href=&#34;https://kubernetes.io/docs/concepts/services-networking/service/#nodeport&#34; target=&#34;_blank&#34;&gt;NodePort&lt;/a&gt; service for every device&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&#34;https://networkop.co.uk/img/k8s-topo.png&#34; alt=&#34;k8s-topo&#34; /&gt;&lt;/p&gt;

&lt;p&gt;At the time of writing, k8s-topo supported three devices types, that get matched based on the device hostname prefix:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Host device - an Alpine image, matched by prefix &lt;code&gt;host&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;cEOS device - an Arista cEOS image, matched by prefix &lt;code&gt;sw&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Quagga device - an Alpine image with Quagga package installed, matched by prefix &lt;code&gt;qrtr&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;As an optional extra, k8s-topo can generate a &lt;a href=&#34;https://www.tutorialspoint.com/d3js/d3js_graphs.htm&#34; target=&#34;_blank&#34;&gt;D3.js&lt;/a&gt; graph that visualises the deployed network topology on an interactive web graph as will be shown later.&lt;/p&gt;

&lt;h1 id=&#34;installation&#34;&gt;Installation&lt;/h1&gt;

&lt;p&gt;There are two main ways to install k8s-topo. The more traditional way will install k8s-topo as a python script on a local machine:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;pip3 install git+https://github.com/networkop/k8s-topo.git
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Another option is to install k8s-topo as a pod on top of a kubernetes cluster (it could be the same cluster that will be used for network simulations). For this option, we first need to build a k8s-topo docker image:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;build.sh &amp;lt;dockerhub_username&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;And then create a pod and its associated service:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;kubectl create -f kube-k8s-topo.yml
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Technically, it doesn&amp;rsquo;t matter where the k8s-topo is installed as long as it can access the k8s cluster and meshnet&amp;rsquo;s etcd service. However, for the sake of simplicity, examples below will assume hosted k8s install, which means that we only need to specify the &lt;code&gt;etcd_port&lt;/code&gt; variable, leaving all others as default (e.g. &lt;code&gt;etcd_host = localhost&lt;/code&gt;).&lt;/p&gt;

&lt;h1 id=&#34;random-topology-examples&#34;&gt;Random topology examples&lt;/h1&gt;

&lt;p&gt;To demonstrate capabilities of our orchestrator, I&amp;rsquo;ve written a random topology &lt;a href=&#34;https://github.com/networkop/k8s-topo/blob/master/examples/builder/builder&#34; target=&#34;_blank&#34;&gt;builder script&lt;/a&gt; that generates a &lt;a href=&#34;https://en.wikipedia.org/wiki/Loop-erased_random_walk&#34; target=&#34;_blank&#34;&gt;uniform spanning tree&lt;/a&gt; graph, which is then used to create a topology definition YAML file along with a set of configuration files for each device. These configuration files accomplish two things:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Configure a unique Loopback IP address in the &lt;code&gt;198.51.100.0/24&lt;/code&gt; range&lt;/li&gt;
&lt;li&gt;Enable OSPF on all directly connected interfaces&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The goal of this script is to be able to generate random large-scale network topologies that would be easy to test by simply ping-sweeping the range of all configured loopback addresses.&lt;/p&gt;

&lt;p&gt;All following demos assume that meshnet CNI  plugin has already been installed, as described in the &lt;a href=&#34;https://networkop.co.uk/post/2018-11-k8s-topo-p1/&#34;&gt;previous post&lt;/a&gt;. Let&amp;rsquo;s start with a relatively small example of 50 cEOS containers.&lt;/p&gt;

&lt;h2 id=&#34;building-a-50-node-ceos-topology&#34;&gt;Building a 50-node cEOS topology&lt;/h2&gt;

&lt;blockquote&gt;
&lt;p&gt;Before we can start building cEOS topologies, we need to make the cEOS Docker image available in a private docker registry. Refer to the k8s-topo Github repository for a complete list of &lt;a href=&#34;https://github.com/networkop/k8s-topo#private-docker-registry-setup&#34; target=&#34;_blank&#34;&gt;instructions&lt;/a&gt;.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;First, we&amp;rsquo;ll generate a random 50-node topology. From inside the k8s-topo pod run:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;./examples/builder/builder --prefix sw 50 0
Total number of links generated: 49
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Prefix &lt;code&gt;sw&lt;/code&gt; ensures that configured devices will be based on Arista cEOS image.&lt;/p&gt;

&lt;p&gt;Next, we can use k8s-topo to create our random topology inside k8s:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;./bin/k8s-topo --create examples/builder/random.yml
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Some of the versions of cEOS don&amp;rsquo;t have the &lt;code&gt;net.ipv4.ip_forward&lt;/code&gt; bit set which means no transit traffic will be allowed. In order to fix that, we can run the following command which modifies this setting on all running cEOS devices:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;./bin/k8s-topo --eif examples/builder/random.yml
INFO:__main__:All pods are running, trying to enable ip forwarding for cEOS pods
INFO:__main__:All cEOS pods have IP forwarding enabled
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;To be able see the generated topology we can run the following command, which creates a D3 graph and prints the URL we can use to access it.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;/k8s-topo # ./bin/k8s-topo --graph examples/builder/random.yml
INFO:__main__:D3 graph created
INFO:__main__:URL: http://10.83.30.252:32080
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The built-in nginx server renders a simple interactive web page with each device coloured according to the k8s node they are running on (in my case there are 4 nodes in total):&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://networkop.co.uk/img/k8s-topo-20.png&#34; alt=&#34;20-node&#34; /&gt;&lt;/p&gt;

&lt;p&gt;At this point we can run the ping-sweep test from any device to verify that we have complete end-to-end reachability:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;# kubectl exec -it sw-1 bash
bash-4.3# for i in `seq 1 50`; do ping -c 1 -W 1 198.51.100.$i|grep from; done
64 bytes from 198.51.100.1: icmp_seq=1 ttl=64 time=0.061 ms
64 bytes from 198.51.100.2: icmp_seq=1 ttl=54 time=187 ms
64 bytes from 198.51.100.3: icmp_seq=1 ttl=56 time=139 ms
64 bytes from 198.51.100.4: icmp_seq=1 ttl=49 time=238 ms
64 bytes from 198.51.100.5: icmp_seq=1 ttl=53 time=189 ms
64 bytes from 198.51.100.6: icmp_seq=1 ttl=50 time=238 ms
64 bytes from 198.51.100.7: icmp_seq=1 ttl=61 time=71.6 ms
64 bytes from 198.51.100.8: icmp_seq=1 ttl=62 time=42.3 ms
64 bytes from 198.51.100.9: icmp_seq=1 ttl=59 time=91.0 ms
64 bytes from 198.51.100.10: icmp_seq=1 ttl=61 time=43.8 ms
64 bytes from 198.51.100.11: icmp_seq=1 ttl=60 time=60.8 ms
64 bytes from 198.51.100.12: icmp_seq=1 ttl=60 time=70.7 ms
64 bytes from 198.51.100.13: icmp_seq=1 ttl=57 time=134 ms
64 bytes from 198.51.100.14: icmp_seq=1 ttl=48 time=251 ms
64 bytes from 198.51.100.15: icmp_seq=1 ttl=63 time=27.8 ms
64 bytes from 198.51.100.16: icmp_seq=1 ttl=62 time=35.6 ms
64 bytes from 198.51.100.17: icmp_seq=1 ttl=54 time=182 ms
64 bytes from 198.51.100.18: icmp_seq=1 ttl=60 time=68.4 ms
64 bytes from 198.51.100.19: icmp_seq=1 ttl=59 time=97.9 ms
64 bytes from 198.51.100.20: icmp_seq=1 ttl=64 time=9.81 ms
64 bytes from 198.51.100.21: icmp_seq=1 ttl=58 time=114 ms
64 bytes from 198.51.100.22: icmp_seq=1 ttl=52 time=192 ms
64 bytes from 198.51.100.23: icmp_seq=1 ttl=59 time=102 ms
64 bytes from 198.51.100.24: icmp_seq=1 ttl=59 time=87.5 ms
64 bytes from 198.51.100.25: icmp_seq=1 ttl=61 time=66.7 ms
64 bytes from 198.51.100.26: icmp_seq=1 ttl=55 time=148 ms
64 bytes from 198.51.100.27: icmp_seq=1 ttl=61 time=60.6 ms
64 bytes from 198.51.100.28: icmp_seq=1 ttl=62 time=47.2 ms
64 bytes from 198.51.100.29: icmp_seq=1 ttl=63 time=18.8 ms
64 bytes from 198.51.100.30: icmp_seq=1 ttl=52 time=202 ms
64 bytes from 198.51.100.31: icmp_seq=1 ttl=61 time=49.2 ms
64 bytes from 198.51.100.32: icmp_seq=1 ttl=62 time=42.9 ms
64 bytes from 198.51.100.33: icmp_seq=1 ttl=49 time=252 ms
64 bytes from 198.51.100.34: icmp_seq=1 ttl=60 time=77.8 ms
64 bytes from 198.51.100.35: icmp_seq=1 ttl=49 time=217 ms
64 bytes from 198.51.100.36: icmp_seq=1 ttl=49 time=232 ms
64 bytes from 198.51.100.37: icmp_seq=1 ttl=50 time=218 ms
64 bytes from 198.51.100.38: icmp_seq=1 ttl=63 time=18.6 ms
64 bytes from 198.51.100.39: icmp_seq=1 ttl=63 time=24.6 ms
64 bytes from 198.51.100.40: icmp_seq=1 ttl=49 time=223 ms
64 bytes from 198.51.100.41: icmp_seq=1 ttl=61 time=48.4 ms
64 bytes from 198.51.100.42: icmp_seq=1 ttl=48 time=233 ms
64 bytes from 198.51.100.43: icmp_seq=1 ttl=64 time=11.0 ms
64 bytes from 198.51.100.44: icmp_seq=1 ttl=51 time=210 ms
64 bytes from 198.51.100.45: icmp_seq=1 ttl=62 time=51.6 ms
64 bytes from 198.51.100.46: icmp_seq=1 ttl=57 time=125 ms
64 bytes from 198.51.100.47: icmp_seq=1 ttl=51 time=222 ms
64 bytes from 198.51.100.48: icmp_seq=1 ttl=53 time=181 ms
64 bytes from 198.51.100.49: icmp_seq=1 ttl=63 time=33.8 ms
64 bytes from 198.51.100.50: icmp_seq=1 ttl=60 time=71.1 ms
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This test proves that &lt;code&gt;sw-1&lt;/code&gt; can reach the loopback IP of every other device in the topology and, since the topology does not have any redundant links, also proves that k8s-topo, together with meshnet, have interconnected all devices correctly. If we had incorrectly connected at least one of the links, the OSPF adjacency would not have formed (due to incorrect source IP in the OSPF hello on NBMA network) and some of the pings would have failed.&lt;/p&gt;

&lt;p&gt;To destroy the network topology and clean-up any state stored in etcd, we can run the following command:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;./bin/k8s-topo --destroy examples/builder/random.yml
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;building-a-250-node-quagga-topology&#34;&gt;Building a 250-node Quagga topology&lt;/h2&gt;

&lt;p&gt;Now let&amp;rsquo;s take this up a notch and test a 250-node topology built out of Quagga containers. Once again, we&amp;rsquo;ll use the builder script to generate a random spanning-tree graph and create all the required configuration files:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;./examples/builder/builder 250 0
Total number of links generated: 249
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Now we can spin-up our 250-node topology:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;./bin/k8s-topo --create examples/builder/random.yml
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The generated graph is not as neat anymore but can be very handy when troubleshooting connectivity issues between different parts of topology&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://networkop.co.uk/img/k8s-topo-200.png&#34; alt=&#34;200-node&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Finally, we can do a loopback ping-sweep test from any random node in our topology to prove that everything has been interconnected correctly:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;# kubectl exec -it qrtr-19 sh
/ # for i in `seq 1 250`; do ping -c 1 -W 1 198.51.100.$i|grep from; done
64 bytes from 198.51.100.1: seq=0 ttl=39 time=2.867 ms
64 bytes from 198.51.100.2: seq=0 ttl=42 time=1.979 ms
64 bytes from 198.51.100.3: seq=0 ttl=23 time=3.339 ms
64 bytes from 198.51.100.4: seq=0 ttl=37 time=2.348 ms
64 bytes from 198.51.100.5: seq=0 ttl=52 time=1.277 ms
64 bytes from 198.51.100.6: seq=0 ttl=33 time=2.662 ms
64 bytes from 198.51.100.7: seq=0 ttl=49 time=1.054 ms
64 bytes from 198.51.100.8: seq=0 ttl=40 time=2.320 ms
64 bytes from 198.51.100.9: seq=0 ttl=48 time=1.127 ms
64 bytes from 198.51.100.10: seq=0 ttl=61 time=0.425 ms
&amp;lt;...&amp;gt;
64 bytes from 198.51.100.240: seq=0 ttl=50 time=1.101 ms
64 bytes from 198.51.100.241: seq=0 ttl=62 time=0.254 ms
64 bytes from 198.51.100.242: seq=0 ttl=35 time=2.288 ms
64 bytes from 198.51.100.243: seq=0 ttl=51 time=0.939 ms
64 bytes from 198.51.100.244: seq=0 ttl=32 time=2.468 ms
64 bytes from 198.51.100.245: seq=0 ttl=64 time=0.523 ms
64 bytes from 198.51.100.246: seq=0 ttl=44 time=1.452 ms
64 bytes from 198.51.100.247: seq=0 ttl=41 time=1.705 ms
64 bytes from 198.51.100.248: seq=0 ttl=44 time=1.429 ms
64 bytes from 198.51.100.249: seq=0 ttl=42 time=1.722 ms
64 bytes from 198.51.100.250: seq=0 ttl=34 time=1.968 ms
&lt;/code&gt;&lt;/pre&gt;

&lt;h1 id=&#34;conclusion&#34;&gt;Conclusion&lt;/h1&gt;

&lt;p&gt;For a very long time, when building real-life virtual network topologies, we had to compromise on the number of real network devices that can be simulated. This led to topology simplification and often resulted in parts of the real network topologies either missed or collapsed into a single virtual device. With k8s-topo and meshnet CNI plugin, we can now build one-to-one replicas of physical network topologies of any size and complexity, without sacrificing the level of detail.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Large-scale network simulations in Kubernetes, Part 1 - Building a CNI plugin</title>
      <link>https://networkop.co.uk/post/2018-11-k8s-topo-p1/</link>
      <pubDate>Fri, 02 Nov 2018 00:00:00 +0000</pubDate>
      
      <guid>https://networkop.co.uk/post/2018-11-k8s-topo-p1/</guid>
      <description>

&lt;p&gt;Building virtualised network topologies has been one of the best ways to learn new technologies and to test new designs before implementing them on a production network. There are plenty of tools that can help build arbitrary network topologies, some with an interactive GUI (e.g. &lt;a href=&#34;https://www.gns3.com/&#34; target=&#34;_blank&#34;&gt;GNS3&lt;/a&gt; or &lt;a href=&#34;http://eve-ng.net/&#34; target=&#34;_blank&#34;&gt;EVE-NG/Unetlab&lt;/a&gt;) and some &amp;ldquo;headless&amp;rdquo;, with text-based configuration files (e.g. &lt;a href=&#34;https://github.com/plajjan/vrnetlab&#34; target=&#34;_blank&#34;&gt;vrnetlab&lt;/a&gt; or &lt;a href=&#34;https://github.com/CumulusNetworks/topology_converter&#34; target=&#34;_blank&#34;&gt;topology-converter&lt;/a&gt;). All of these tools work by spinning up multiple instances of virtual devices and interconnecting them according to a user-defined topology.&lt;/p&gt;

&lt;h1 id=&#34;problem-statement&#34;&gt;Problem statement&lt;/h1&gt;

&lt;p&gt;Most of these tools were primarily designed to work on a single host. This may work well for a relatively small topology but may become a problem as the number of virtual devices grows. Let&amp;rsquo;s take Juniper vMX as an example. From the official hardware requirements &lt;a href=&#34;https://www.juniper.net/documentation/en_US/vmx14.1/topics/reference/general/vmx-hw-sw-minimums.html&#34; target=&#34;_blank&#34;&gt;page&lt;/a&gt;, the smallest vMX instance will require:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;2 VMs - one for control and one for data plane&lt;/li&gt;
&lt;li&gt;2 vCPUs - one for each of the VMs&lt;/li&gt;
&lt;li&gt;8 GB of RAM - 2GB for VCP and 6GB for VFP&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;This does not include the resources consumed by the underlying hypervisor, which can easily eat up another vCPU + 2GB of RAM. It&amp;rsquo;s easy to imagine how quickly we can hit the upper limit of devices in a single topology if we can only use a single hypervisor host. Admittedly, vMX is one of the most resource-hungry virtual routers and using other vendor&amp;rsquo;s virtual devices may increase that upper limit. However, if the requirement is to simulate topologies with 100+ devices, no single server will be able to cope with the required load and a potential resource contention may lead to instabilities and various software bugs manifesting themselves in places we don&amp;rsquo;t expect.&lt;/p&gt;

&lt;h1 id=&#34;exploring-possible-solutions&#34;&gt;Exploring possible solutions&lt;/h1&gt;

&lt;p&gt;Ideally, in large-scale simulations, we&amp;rsquo;d want to spread the devices across multiple hosts and interconnect them so that, from the device perspective, it&amp;rsquo;d look like they are still running on the same host. To take it a step further, we&amp;rsquo;d want the virtual links to be simple point-to-point L2 segments, without any bridges in between, so that we don&amp;rsquo;t have to deal with issues when virtual bridges consume or block some of the &amp;ldquo;unexpected&amp;rdquo; traffic, e.g. LACP/STP on &lt;a href=&#34;https://patchwork.ozlabs.org/patch/819153/&#34; target=&#34;_blank&#34;&gt;Linux bridges&lt;/a&gt;.&lt;/p&gt;

&lt;h2 id=&#34;containers-vs-vms&#34;&gt;Containers vs VMs&lt;/h2&gt;

&lt;p&gt;It&amp;rsquo;s possible to build multi-host VM topologies on top of a private cloud like solution like OpenStack or VMware. The operational overhead involved would be minimal as all the scheduling and network plumbing should be taken care of by virtual infrastructure manager. However this approach has several disadvantages:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;In order to not depend on the underlay, all inter-VM links would need to be implemented as overlay (VMware would require NSX)&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;VMs would still be interconnected via virtual switches&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;Life-cycle management of virtual topologies is not trivial, e.g. VMware requires DRS, OpenStack requires masakari&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;Injecting of additional data into VMs (e.g. configuration files) requires guest OS awareness and configuration (e.g. locating and mounting of a new partition)&lt;br /&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;In contrast, containers provide an easy way to mount volumes inside a container&amp;rsquo;s filesystem, have plenty of options for resource scheduling and orchestrators and are substantially more lightweight and customizable. As a bonus, we get a unified way to package, distribute and manage lifecycle of our containers, independent from the underlying OS.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Note: AFAIK only Arista and Juniper build docker container images for their devices (cEOS and cSRX). However it is possible to run any VM-based network device inside a docker container, with many examples and makefiles available on &lt;a href=&#34;https://github.com/plajjan/vrnetlab&#34; target=&#34;_blank&#34;&gt;virtnetlab&lt;/a&gt;.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&#34;kubernetes-vs-swarm&#34;&gt;Kubernetes vs Swarm&lt;/h2&gt;

&lt;p&gt;If we focus on Docker, the two most popular options for container orchestration would be Kubernetes and Swarm. Swarm is a Docker&amp;rsquo;s native container orchestration tool, it requires less customisation out of the box and has a simpler data model. The primary disadvantages of using Swarm for network simulations are:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/moby/moby/issues/24862&#34; target=&#34;_blank&#34;&gt;Lack of support&lt;/a&gt; for privileged containers (network admin (CAP_NET_ADMIN) capabilities may be required by virtualised network devices)&lt;/li&gt;
&lt;li&gt;Unpredictable network interface &lt;a href=&#34;https://github.com/moby/moby/issues/25181&#34; target=&#34;_blank&#34;&gt;naming and order&lt;/a&gt; inside the container&lt;/li&gt;
&lt;li&gt;Docker&amp;rsquo;s main networking plugin libnetwork is &lt;a href=&#34;https://kubernetes.io/blog/2016/01/why-kubernetes-doesnt-use-libnetwork/&#34; target=&#34;_blank&#34;&gt;opinionated&lt;/a&gt; and difficult to extend or modify&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;On the other hand, the approach chosen by K8s provides an easier way to modify the default behaviour of a network plugin or to create a completely new implementation. However, K8s itself imposes several requirements on CNI plugins:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;All containers can communicate with all other containers without NAT&lt;/li&gt;
&lt;li&gt;All nodes can communicate with all containers (and vice-versa) without NAT&lt;/li&gt;
&lt;li&gt;The IP that a container sees itself as is the same IP that others see it as&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The above also implies that communication between the containers happens at L3, which means that no container should make any assumptions about the underlying L2 transport, i.e. not use any L2 protocols(apart from ARP). Another corollary of the above requirements is that every container only has a single IP and hence a single interface, which, together with the previous L2 limitation, makes network simulations in K8s nearly impossible.&lt;/p&gt;

&lt;h2 id=&#34;multus-vs-diy&#34;&gt;Multus vs DIY&lt;/h2&gt;

&lt;p&gt;There are multiple solutions that solve the problem of a single network interface per container/pod - CNI-Genie, Knitter and &lt;a href=&#34;https://github.com/intel/multus-cni&#34; target=&#34;_blank&#34;&gt;Multus&lt;/a&gt; CNI. All of them were primarily designed for containerised VNF use cases, with the assumption that connectivity would still be provided by one of the existing plugins, which still leaves us with a number of issues:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;We have to be transparent to the underlay, so we can&amp;rsquo;t use plugins that interact with the underlay (e.g. macvlan, calico)&lt;/li&gt;
&lt;li&gt;Most of the CNI plugins only provide L3 connectivity between pods (e.g. flannel, ovn, calico)&lt;/li&gt;
&lt;li&gt;The few plugins that do provide L2 overlays (e.g contiv, weave) do not support multiple interfaces and still use virtual bridges underneath&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Perhaps it would have been possible to hack one of the plugins to do what I wanted but I felt like it&amp;rsquo;d be easier to build a specialised CNI plugin to do just what I want and nothing more. As I&amp;rsquo;ve mentioned previously, developing a simple CNI plugin is not that difficult, especially if you have a clearly defined use case, which is why I&amp;rsquo;ve built &lt;a href=&#34;https://github.com/networkop/meshnet-cni&#34; target=&#34;_blank&#34;&gt;meshnet&lt;/a&gt; - a CNI plugin to build arbitrary network topologies out of point-to-point links.&lt;/p&gt;

&lt;h1 id=&#34;cni-plugin-overview&#34;&gt;CNI plugin overview&lt;/h1&gt;

&lt;p&gt;At a very high level, every CNI plugin is just a binary and a configuration file installed on K8s worker nodes. When a pod is scheduled to run on a particular node, a local node agent (kubelet) calls a CNI binary and passes all the necessary information to it. That CNI binary connects and configures network interfaces and returns the result back to kubelet. The information is passed to CNI binary in two ways - through environment variables and CNI configuration file. This is how a CNI &lt;strong&gt;ADD&lt;/strong&gt; call &lt;a href=&#34;https://www.cncf.io/wp-content/uploads/2017/11/Introduction-to-CNI-2.pdf#page=7&#34; target=&#34;_blank&#34;&gt;may&lt;/a&gt; look like:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;CNI_COMMAND=ADD \
CNI_CONTAINERID=$id \
CNI_NETNS=/proc/$pid/ns/net \
CNI_ARGS=K8S_POD_NAMESPACE=$namepsace;K8S_POD_NAME=$name
/opt/cni/bin/my-plugin &amp;lt; /etc/cni/net.d/my-config
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The runtime parameters get passed to the plugin as environment variables and CNI configuration file gets passed to stdin. The CNI binary runs to completion and is expected to return the configured network settings back to the caller. The format of input and output, as well as environment variables, are documented in a CNI &lt;a href=&#34;https://github.com/containernetworking/cni/blob/master/SPEC.md&#34; target=&#34;_blank&#34;&gt;specification document&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;There are plenty of other resources that cover CNI plugin development in much greater detail, I would recommend reading at least these four:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;a href=&#34;https://schd.ws/hosted_files/kccnceu18/64/Kubernetes-and-the-CNI-Kubecon-218.pdf&#34; target=&#34;_blank&#34;&gt;CNI plugins best practices&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.altoros.com/blog/kubernetes-networking-writing-your-own-simple-cni-plug-in-with-bash/&#34; target=&#34;_blank&#34;&gt;Writing a sample CNI plugin in bash&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://logingood.github.io/kubernetes/cni/2016/05/14/netns-and-cni.html&#34; target=&#34;_blank&#34;&gt;EVPN CNI plugin&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://dougbtv.com/nfvpe/2017/06/22/cni-tutorial/&#34; target=&#34;_blank&#34;&gt;Workflow for writing CNI plugins&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;h1 id=&#34;meshnet-cni-architecture&#34;&gt;Meshnet CNI architecture&lt;/h1&gt;

&lt;p&gt;The goal of &lt;a href=&#34;https://github.com/networkop/meshnet-cni&#34; target=&#34;_blank&#34;&gt;meshnet&lt;/a&gt; plugin is to interconnect pods via direct point-to-point links according to some user-defined topology.  To do that, the plugin uses two types of links:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;veth&lt;/strong&gt; - to interconnect pods running on the same node&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;vxlan&lt;/strong&gt; - to interconnect pods running on different nodes&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;One thing to note is that point-to-point links are connected directly between pods, without any software bridges in between, which makes the design a lot simpler and provides a cleaner abstraction of a physical connection between network devices.&lt;/p&gt;

&lt;p&gt;The plugin consists of three main components:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;etcd&lt;/strong&gt; - a private cluster storing topology information and runtime pod metadata (e.g. pod IP address and NetNS fd)&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;meshnet&lt;/strong&gt; - a CNI binary called by kubelet, responsible for pod&amp;rsquo;s network configuration&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;meshnetd&lt;/strong&gt; - a daemon responsible for Vxlan link configuration updates&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Just like Multus, meshnet has the concept of master/default plugin, which sets up the first interface of the pod. This interface is setup by one of the existing plugins (e.g. bridge or flannel) and is used for pod&amp;rsquo;s external connectivity. The rest of the interfaces are setup according to a topology information stored in etcd.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://networkop.co.uk/img/meshnet-arch.png&#34; alt=&#34;Meshnet Architecture&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Although the original idea of a CNI plugin was to have a single stateless binary, most of the time there&amp;rsquo;s a need to maintain some runtime state (e.g. ip routes, ip allocations etc.), which is why a lot of CNI plugins have daemons. In our case, daemon&amp;rsquo;s role is to ensure Vxlan link configurations are correct across different hosts. Using the above diagram as an example, if pod-2 comes up after pod-3, there must be a way of signalling the (node-1) VTEP IP to the remote node (node-2) and making sure that the Vxlan link on node-2 is moved into pod-3&amp;rsquo;s namespace. This is accomplished by meshnet binary issuing an HTTP PUT request to the remote node&amp;rsquo;s daemon with all the required Vxlan link attributes attached as a payload.&lt;/p&gt;

&lt;h1 id=&#34;meshnet-design-walkthrough&#34;&gt;Meshnet design walkthrough&lt;/h1&gt;

&lt;p&gt;One of the assumptions I made in the design is that topology information is uploaded into the etcd cluster before we spin up the first pod. I&amp;rsquo;ll focus on how exactly this can be done in the next post but for now, let&amp;rsquo;s assume that it&amp;rsquo;s is already there. This information needs to be structured in a very specific way and must cover every interface of every pod. The presence of this information in etcd tells meshnet binary what p2p interfaces (if any) need to be setup for the pod. Below is a sample definition of a link from pod2 to pod3:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;{ &amp;quot;uid&amp;quot;:          21,
  &amp;quot;peer_pod&amp;quot;:     &amp;quot;pod3&amp;quot;,
  &amp;quot;local_intf&amp;quot;:   &amp;quot;eth2&amp;quot;,
  &amp;quot;local_ip&amp;quot;:     &amp;quot;23.23.23.2/24&amp;quot;,
  &amp;quot;peer_intf&amp;quot;:    &amp;quot;eth2&amp;quot;,
  &amp;quot;peer_ip&amp;quot;:      &amp;quot;23.23.23.3/24&amp;quot; }
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Meshnet binary is written in go and, like many other CNI plugins, contains a common skeleton code which parses input arguments and variables. Most of the plugin logic goes into &lt;code&gt;cmdAdd&lt;/code&gt; and &lt;code&gt;cmdDel&lt;/code&gt; functions that get called automatically when CNI binary is invoked by kubelet.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;import (
    &amp;quot;github.com/containernetworking/cni/pkg/skel&amp;quot;
    &amp;quot;github.com/containernetworking/cni/pkg/types&amp;quot;
)
func cmdAdd(args *skel.CmdArgs) error {
    // Parsing cni .conf file
    n, err := loadConf(args.StdinData)
    // Parsing CNI_ARGS environment variable
    cniArgs := k8sArgs{}
    types.LoadArgs(args.Args, &amp;amp;cniArgs)
}
func main() {
	skel.PluginMain(cmdAdd, cmdGet, cmdDel, version.All, &amp;quot;TODO&amp;quot;)
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;One of the first things that happen in a &lt;code&gt;cmdAdd&lt;/code&gt; function is a &lt;code&gt;DelegateAdd&lt;/code&gt; call to let the master plugin setup the first interface of the pod. Master plugin configuration is extracted from the &lt;code&gt;delegate&lt;/code&gt; field of the meshnet CNI configuration file.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;func cmdAdd(args *skel.CmdArgs) error {
    ...
    r, err := delegateAdd(ctx, n.Delegate, args.IfName)
    ...
}
func delegateAdd(ctx context.Context, netconf map[string]interface{}, 
                  intfName string) 
                 (types.Result, error) {
	...
    result, err = invoke.DelegateAdd(ctx, netconf[&amp;quot;type&amp;quot;].(string), netconfBytes, nil)
    ...
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;When master plugin is finished, we upload current pod&amp;rsquo;s runtime metadata to etcd. This is required so that peer pods can find and connect to our pod when needed. Specifically, they would need VTEP IP for remote vxlan links and namespace file descriptor for local veth links.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;func (pod *podMeta) setPodAlive(ctx context.Context, kv clientv3.KV, 
                                 netNS, srcIP string) error {

	srcIPKey := fmt.Sprintf(&amp;quot;/%s/src_ip&amp;quot;, pod.Name)
	_, err := kv.Put(ctx, srcIPKey, srcIP)

	NetNSKey := fmt.Sprintf(&amp;quot;/%s/net_ns&amp;quot;, pod.Name)
	_, err = kv.Put(ctx, NetNSKey, netNS)
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;At this stage, we&amp;rsquo;re ready to setup pod&amp;rsquo;s links. Instead of manipulating netlink directly, I&amp;rsquo;m using &lt;a href=&#34;https://github.com/redhat-nfvpe/koko&#34; target=&#34;_blank&#34;&gt;koko&lt;/a&gt; - a high-level library that creates veth and vxlan links for containers. The simplified logic of what happens at this stage is summarised in the following code snippet:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt; // Iterate over each link of the local pod
for _, link := range *localPod.Links { 

    // Download peer pod&#39;s runtime metadata
    peerPod := &amp;amp;podMeta{Name: link.PeerPod}
    peerPod.getPodMetadata(ctx, kv)

    if peerPod.isAlive() { // If SrcIP and NetNS keys are set

        if peerPod.SrcIP == localPod.SrcIP { // If we&#39;re on the same host

            koko.MakeVeth(*myVeth, *peerVeth)

        } else  { // If we&#39;re on different hosts

            koko.MakeVxLan(*myVeth, *vxlan)
            putRequest(remoteUrl, bytes.NewBuffer(jsonPayload))

        }
    } else {
        // skip and continue
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;We start by downloading metadata for each pod that we have a link to and check if it has already come up. The value of &lt;code&gt;peerPod.SrcIP&lt;/code&gt; determines whether we&amp;rsquo;re on the same node and need to setup a veth link or on different nodes and we need to setup a vxlan tunnel between them. The latter is done in two steps - first, a local Vxlan link is setup and moved to a pod&amp;rsquo;s namespace, followed by an HTTP PUT sent to the remote node&amp;rsquo;s meshnet daemon to setup a similar link on the other end.&lt;/p&gt;

&lt;h1 id=&#34;meshnet-cni-demo&#34;&gt;Meshnet CNI demo&lt;/h1&gt;

&lt;p&gt;The easiest way to walk through this demo is by running it inside a docker:dind container, with a few additional packages installed on top of it:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;docker run --rm -it --privileged docker:dind sh
# /usr/local/bin/dockerd-entrypoint.sh &amp;amp;
# apk add --no-cache jq sudo wget git bash curl
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;https://networkop.co.uk/img/meshnet-demo.png&#34; alt=&#34;Meshnet Architecture&#34; /&gt;&lt;/p&gt;

&lt;p&gt;In this demo, we&amp;rsquo;ll build a simple triangle 3-node topology as shown in the figure above. We start by cloning the meshnet &lt;a href=&#34;https://github.com/networkop/meshnet-cni&#34; target=&#34;_blank&#34;&gt;Github repository&lt;/a&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;git clone https://github.com/networkop/meshnet-cni.git &amp;amp;&amp;amp; cd meshnet-cni
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Next, create a local 3-node K8s cluster using &lt;a href=&#34;https://github.com/kubernetes-sigs/kubeadm-dind-cluster&#34; target=&#34;_blank&#34;&gt;kubeadm-dind-cluster&lt;/a&gt;, which uses docker-in-docker to simulate individual k8s nodes.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;wget https://raw.githubusercontent.com/kubernetes-sigs/kubeadm-dind-cluster/master/fixed/dind-cluster-v1.11.sh 
chmod +x ./dind-cluster-v1.11.sh 
./dind-cluster-v1.11.sh up
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The last command may take a few minutes to download all the required images. Once the K8s cluster is ready, we can start by deploying the private etcd cluster&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;export PATH=&amp;quot;$HOME/.kubeadm-dind-cluster:$PATH&amp;quot;
kubectl create -f utils/etcd.yml
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The &lt;code&gt;./tests&lt;/code&gt; directory already contains link databases for our 3-node test topology, ready to be uploaded to etcd:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;ETCD_HOST=$(kubectl get service etcd-client -o json |  jq -r &#39;.spec.clusterIP&#39;)
ENDPOINTS=$ETCD_HOST:2379

echo &amp;quot;Copying JSON files to kube-master&amp;quot;
sudo cp tests/*.json /var/lib/docker/volumes/kubeadm-dind-kube-master/_data/

echo &amp;quot;Copying etcdctl to kube-master&amp;quot;
sudo cp utils/etcdctl /var/lib/docker/volumes/kubeadm-dind-kube-master/_data/
docker exec kube-master cp /dind/etcdctl /usr/local/bin/

for pod in pod1 pod2 pod3
do
    # First cleanup any existing state
    docker exec -it kube-master sh -c &amp;quot;ETCDCTL_API=3 etcdctl --endpoints=$ENDPOINTS del --prefix=true \&amp;quot;/$pod\&amp;quot;&amp;quot;

    # Next Update the links database
    docker exec -it kube-master sh -c &amp;quot;cat /dind/$pod.json | ETCDCTL_API=3 etcdctl --endpoints=$ENDPOINTS put /$pod/links&amp;quot;

    # Print the contents of links databse
    docker exec -it kube-master sh -c &amp;quot;ETCDCTL_API=3 etcdctl --endpoints=$ENDPOINTS get --prefix=true \&amp;quot;/$pod\&amp;quot;&amp;quot;

done
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The final missing piece is the meshnet daemonset, which installs the binary, configuration file and the meshnet daemon on every node.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;kubectl create -f kube-meshnet.yml
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The only thing that&amp;rsquo;s required now is the master plugin configuration update. Since different K8s clusters can use a different plugins, the configuration file installed by the daemonset contains a dummy value which needs to be overwritten. In our case, the kubeadm-dind-cluster we&amp;rsquo;ve installed should use a default &lt;code&gt;bridge&lt;/code&gt; plugin which can be merged into our meshnet configuration file like this:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;ETCD_HOST=$(kubectl get service etcd-client -o json |  jq -r &#39;.spec.clusterIP&#39;)
for container in kube-master kube-node-1 kube-node-2
do
    # Merge the default CNI plugin with meshnet
    docker exec $container bash -c &amp;quot;jq  -s &#39;.[1].delegate = (.[0]|del(.cniVersion))&#39; /etc/cni/net.d/cni.conf /etc/cni/net.d/meshnet.conf  | jq .[1] &amp;gt; /etc/cni/net.d/00-meshnet.conf&amp;quot;
    docker exec $container bash -c &amp;quot;sed -i &#39;s/ETCD_HOST/$ETCD_HOST/&#39; /etc/cni/net.d/00-meshnet.conf&amp;quot;
done
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Now meshnet CNI plugin is installed and configured and everything&amp;rsquo;s ready for us to create our test topology.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;cat tests/2node.yml | kubectl create -f -
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The following command will verify that the topology has been created and confirm that pods are scheduled to the correct nodes:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;kubectl --namespace=default get pods -o wide  |  grep pod
pod1    1/1 Running 0   1m  10.244.2.7  kube-node-1
pod2    1/1 Running 0   1m  10.244.2.6  kube-node-1
pod3    1/1 Running 0   1m  10.244.3.5  kube-node-2
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Finally, we can do a simple ping test to verify that we have connectivity between all 3 pods:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;kubectl exec pod1 -- sudo ping -c 1 12.12.12.2
kubectl exec pod2 -- sudo ping -c 1 23.23.23.3
kubectl exec pod3 -- sudo ping -c 1 13.13.13.1
&lt;/code&gt;&lt;/pre&gt;

&lt;h1 id=&#34;coming-up&#34;&gt;Coming up&lt;/h1&gt;

&lt;p&gt;The process demonstrated above is quite rigid and requires a lot of manual effort to create a required topology inside a K8s cluster. In the next post, we&amp;rsquo;ll have a look at &lt;a href=&#34;https://github.com/networkop/k8s-topo&#34; target=&#34;_blank&#34;&gt;k8s-topo&lt;/a&gt; - a simple tool that orchestrates most of the above steps - generates topology data and creates pods based on a simple YAML-based topology definition file.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Serverless SDN - Network Engineering Analysis of Appswitch</title>
      <link>https://networkop.co.uk/post/2018-05-29-appswitch-sdn/</link>
      <pubDate>Thu, 21 Jun 2018 00:00:00 +0000</pubDate>
      
      <guid>https://networkop.co.uk/post/2018-05-29-appswitch-sdn/</guid>
      <description>

&lt;p&gt;Virtual networking has been one of the hottest areas of research and development in recent years. Kubernetes alone has, at the time of writing, 20 different &lt;a href=&#34;https://kubernetes.io/docs/concepts/cluster-administration/networking/&#34; target=&#34;_blank&#34;&gt;networking plugins&lt;/a&gt;, some of which can be &lt;a href=&#34;https://github.com/projectcalico/canal&#34; target=&#34;_blank&#34;&gt;combined&lt;/a&gt; to build even more plugins. However, if we dig a bit deeper, most of these plugins and solutions are built out of two very simple constructs:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;a virtual switch - anything from a linux bridge through VPP and IOVisor to OVS&lt;/li&gt;
&lt;li&gt;ACL/NAT - most commonly implemented as iptables, with anything from netfilter to eBPF under the hood&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
&lt;p&gt;Note1: for the purpose of this article I won&amp;rsquo;t consider service meshes as a network solution, although it clearly is one, simply because it operates higher than TCP/IP and ultimately still requires network plumbing to be in place&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;If those look familiar, you&amp;rsquo;re not mistaken, they are the &lt;strong&gt;same exact&lt;/strong&gt; things that were used to connect VMs together and enforce network security policies at the dawn of SDN era almost a decade ago. Although some of these technologies have gone a long way in both features and performance, they still treat containers the same way they treated VMs. There are a few exceptions that don&amp;rsquo;t involve the above constructs, like SR-IOV, macvlan/ipvlan and running containers in host namespace, however they represent a small fraction of corner case solutions and can be safely ignored for the purpose of this discussion. That&amp;rsquo;s why for networking folk it won&amp;rsquo;t be too big a mistake to think of containers as VMs, let&amp;rsquo;s see why:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://networkop.co.uk/img/docker-vs-vm.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;At a high level both container and VM networking are exactly the same, doesn&amp;rsquo;t matter what plugin, what networking model (CNM/CNI), what vSwitch flavour or what offload technology you use. Any virtual workload must have a virtual patch cable connecting it to a vSwitch, which implements forwarding and security policies programmed by an SDN controller. These tenets have gone unchallenged since the early days of containers and this is how I, personally, always imagined a typical virtual networking solution would look like. Until I read about &lt;a href=&#34;https://apporbit.com/a-test-drive-of-appswitch-the-network-stack-from-the-future/&#34; target=&#34;_blank&#34;&gt;AppSwitch&lt;/a&gt; and got so excited I decided to sign up for a &lt;a href=&#34;https://apporbit.com/appswitch/&#34; target=&#34;_blank&#34;&gt;beta program&lt;/a&gt; just to take it apart and see how it works. But before I dive deep into its architecture, I need to provide some theoretical background and I&amp;rsquo;ll do that by zooming in on a part of the (Linux) networking stack that sits right above TCP/IP.&lt;/p&gt;

&lt;h1 id=&#34;network-socket-api&#34;&gt;Network Socket API&lt;/h1&gt;

&lt;p&gt;Let&amp;rsquo;s start our exploration by examining what happens when a TCP client wants to communicate with a TCP server on a remote host. The first thing that the client library does is it creates a socket by making a &lt;code&gt;socket()&lt;/code&gt; system call for a specific address family (local, IPv4, IPv6) and transport protocol (TCP, UDP). The returned value is a file descriptor that points to a socket. This file descriptor is used in all subsequent network calls.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;sockfd = socket(AF_INET, SOCK_STREAM, 0) /* Create an IPv4 TCP socket */
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Next the client issues a &lt;code&gt;connect()&lt;/code&gt; system call, where it passes the new socket file descriptor along with a pointer to &lt;code&gt;serv_addr&lt;/code&gt; data structures that contains the destination IP and port of the TCP server.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;connect(sockfd, &amp;amp;serv_addr, sizeof(serv_addr)) /* Returns 0 if connected */
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Behind the scenes the last call initiates a TCP 3-way handshake with the remote server and returns 0 if TCP sessions transitions to the &lt;strong&gt;Established&lt;/strong&gt; state.&lt;/p&gt;

&lt;p&gt;Finally, when TCP session is established, the client interacts with the socket the same way it does with any normal file by calling &lt;code&gt;read()&lt;/code&gt; and &lt;code&gt;write()&lt;/code&gt; to receive and send data to the remote server.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;read(sockfd, buffer, strlen(buffer))  /* Returns the number of bytes read */
write(sockfd, buffer, strlen(buffer)) /* Returns the number of bytes written */
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Below is a simplified diagram that shows the above syscalls and maps them to different stages of TCP connection. Note that only the layers relevant to the purpose of this discussion are shown. For a more comprehensive overview of Linux networking stack refer to &lt;a href=&#34;http://140.120.7.21/LinuxRef/Network/LinuxNetworkStack.html&#34; target=&#34;_blank&#34;&gt;1&lt;/a&gt;, &lt;a href=&#34;http://www.microhowto.info/howto/listen_for_and_accept_tcp_connections_in_c.html&#34; target=&#34;_blank&#34;&gt;2&lt;/a&gt; and &lt;a href=&#34;https://www.ibm.com/developerworks/aix/library/au-tcpsystemcalls/index.html&#34; target=&#34;_blank&#34;&gt;3&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://networkop.co.uk/img/tcp-syscalls.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;On the server side the sequence of system calls is a little different. After a server creates a socket with the &lt;code&gt;socket()&lt;/code&gt; call, it tries to &lt;code&gt;bind()&lt;/code&gt; to a particular IP and port number of the host:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;bind(sockfd, &amp;amp;serv_addr, sizeof(serv_addr)) /* Returns 0 if successful */
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;In order to start accepting incoming TCP SYN requests, the socket needs to be marked as &lt;strong&gt;passive&lt;/strong&gt; by making a &lt;code&gt;listen()&lt;/code&gt; call, which also specifies the maximum size of a queue for pending TCP connections:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;listen(sockfd, SOMAXCONN) /* Returns 0 if successful */
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Once the TCP 3-way handshake with the client is complete and the connection transitions to the &lt;strong&gt;Established&lt;/strong&gt; state, it will be pulled off the queue by an &lt;code&gt;accept()&lt;/code&gt; call, running in an infinite loop, which returns a new &lt;strong&gt;connected&lt;/strong&gt; socket file descriptor back to the server.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;newsockfd = accept(sockfd, &amp;amp;client_addr, &amp;amp;client_len) /* Create a new socket */
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The server application now proceeds to read and write data similar to the client side.&lt;/p&gt;

&lt;h1 id=&#34;appswitch-high-level-architecture&#34;&gt;Appswitch high-level architecture&lt;/h1&gt;

&lt;p&gt;Appswitch is a distributed virtual networking solution that intercepts application&amp;rsquo;s network events at the system call interface level, before they get to the TCP/IP stack of the host. This allows it to make routing decisions and enforce security policies without the need for vSwitches or iptables. The way it abstracts host&amp;rsquo;s TCP/IP stack (underlay) from the Appswitch-managed application IP address space (overlay) is not too much dissimilar from the way traditional routing protocols operate.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://networkop.co.uk/img/ax-overview.png&#34; alt=&#34;Appswitch architecture&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Just like a typical distributed routing protocol, Appswitch builds a database of all known local endpoint addresses at each node, distributes it to other members of a cluster with itself as the next-hop, calculates how to forward connection setup calls between local and remote endpoints and uses those results to steer network traffic between them. Sounds very much like something BGP/OSPF/IS-IS would do, doesn&amp;rsquo;t it? Let&amp;rsquo;s have a closer look at the actual elements involved, using the diagram from the original Appswitch &lt;a href=&#34;http://hci.stanford.edu/cstr/reports/2017-01.pdf&#34; target=&#34;_blank&#34;&gt;research paper&lt;/a&gt;:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://networkop.co.uk/img/ax-highlevel.png&#34; alt=&#34;Appswitch architecture&#34; /&gt;&lt;/p&gt;

&lt;p&gt;The first thing Appswitch does when it starts is neighbor discovery. The element responsible for this is a &lt;strong&gt;Service Router&lt;/strong&gt; which uses &lt;a href=&#34;https://www.serf.io/docs/internals/gossip.html&#34; target=&#34;_blank&#34;&gt;Serf&lt;/a&gt; to efficiently discover and disseminate information in a cluster of Appswitch nodes. Serf is Hashicorp&amp;rsquo;s implementation of a &lt;a href=&#34;https://pdfs.semanticscholar.org/8712/3307869ac84fc16122043a4a313604bd948f.pdf&#34; target=&#34;_blank&#34;&gt;gossip protocol&lt;/a&gt; - a cluster membership and communication protocol. Serf should be very easy to understand for those familiar with flood-and-learn behaviour of OSPF and IS-IS on broadcast multiaccess links, with the biggest distinction being that designated routers are chosen randomly and independently by each node of the link.&lt;/p&gt;

&lt;p&gt;Whenever a new application is launched inside Appswitch, it gets moved to a dedicated network namespace, where a &lt;strong&gt;Trap Generator&lt;/strong&gt; listens for network system calls and forwards them to a &lt;strong&gt;Trap Handler&lt;/strong&gt; over a shared Unix domain socket. Together these two elements form the forwarding plane for network system calls. Every time an application issues a &lt;code&gt;socket()&lt;/code&gt; syscall, the trap generator forwards it to the trap handler, which in turn creates a socket in the host namespace and passes its reference all the way back to the calling application. Once the connection is established, all &lt;code&gt;read()&lt;/code&gt; and &lt;code&gt;write()&lt;/code&gt; syscalls will be made using the returned &lt;code&gt;sockfd&lt;/code&gt;, effectively achieving the same performance as if our application was running directly on host OS.&lt;/p&gt;

&lt;p&gt;The central element in Appswitch architecture is a &lt;strong&gt;Service Table&lt;/strong&gt; - a distributed, eventually consistent database which stores mappings between running applications and their next-hop transport addresses. This information is used by the Trap Handler in &lt;code&gt;connect()&lt;/code&gt; syscall to build the &lt;code&gt;serv_addr&lt;/code&gt; data structure with the real IP and port of the target application. In a steady state each node in an Appswitch cluster will have the same view of this database and all updates to this database will be gossiped to other members of a cluster by a Service Router.&lt;/p&gt;

&lt;h1 id=&#34;appswitch-detailed-overview&#34;&gt;Appswitch detailed overview&lt;/h1&gt;

&lt;p&gt;Let&amp;rsquo;s have a closer look at what happens at different stages of Appswitch lifecycle.&lt;/p&gt;

&lt;h2 id=&#34;1-installation-and-startup&#34;&gt;1. Installation and Startup&lt;/h2&gt;

&lt;p&gt;At the time of writing Appswitch is being distributed as a docker container hosted in a private docker repository on docker hub (access provided based on request). It contains a single binary executable called &lt;code&gt;ax&lt;/code&gt; which needs to be started in PID and network namespaces of the host in order to be able to talk to host&amp;rsquo;s syscall interface and track application threads. By default, Appswitch attaches to the TCP/IP stack of the host in two ways:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;It starts management REST API and Serf processes that bind to ports 6664 and 7946.&lt;/li&gt;
&lt;li&gt;It selects one of the host&amp;rsquo;s IP addresses and reserves a pool of ports (e.g. 40000-60000) that will be dynamically allocated to applications in response to &lt;code&gt;bind()&lt;/code&gt; and &lt;code&gt;connect()&lt;/code&gt; system calls.&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&#34;2-joining-a-cluster&#34;&gt;2. Joining a cluster&lt;/h2&gt;

&lt;p&gt;One of the first things a running Appswitch instance has to do is discover all members of a cluster. This is accomplished by providing an IP address of at least one node of an existing cluster as a startup parameter, which is then used to discover all other members. The information exchanged during neighbor discovery phase, which includes host IPs, names and roles, gets recorded in the Service Table and can be viewed with &lt;code&gt;ax get nodes&lt;/code&gt; command. The mechanism of neighbor discovery and monitoring inside a cluster is not Appswitch-specific so I won&amp;rsquo;t spend much time on it here, however I highly recommend reading at least the protocol overview on the official &lt;a href=&#34;https://www.serf.io/docs/internals/gossip.html&#34; target=&#34;_blank&#34;&gt;Serf website&lt;/a&gt;, as this is a very common approach in modern-day eventually consistent cluster architectures.&lt;/p&gt;

&lt;h2 id=&#34;3-cluster-scale-out&#34;&gt;3. Cluster scale-out&lt;/h2&gt;

&lt;p&gt;A cluster is a set of nodes running Appswitch daemons that can directly communicate with one another and all use Serf to monitor state of other cluster members. Like any other cluster protocol, Serf has its limitations and Appswitch has a very neat mechanism to allow services to scale beyond a single cluster boundary, e.g. between a LAN and a WAN, called Federation. In principle, it&amp;rsquo;s somewhat similar to hierarchical BGP RR design with route reflectors doing &lt;code&gt;next-hop self&lt;/code&gt;. A set of Appswitch nodes can be designated as Federation gateways, which allows them to propagate information about running applications between two different clusters. When doing so they change the IP/port information to point to themselves, which forces all inter-cluster traffic to go via one of these nodes.&lt;/p&gt;

&lt;h2 id=&#34;4-registering-a-server-application&#34;&gt;4. Registering a server application&lt;/h2&gt;

&lt;p&gt;Once Appswitch instance has joined a cluster, it&amp;rsquo;s ready to onboard its first application. Let&amp;rsquo;s start with a web server that needs to be accessible from other Appswitch-managed applications (East-West) and externally (North-South). When starting a server application, we need to provide a unique identifier that will be used by other endpoints to reach it. That identifier can be either an IP address (provided with &lt;code&gt;--ip&lt;/code&gt; argument) or a hostname (provided with &lt;code&gt;--name&lt;/code&gt; argument). If only hostname is specified, IP address will still be allocated behind the scenes and Appswitch will program its embedded DNS to make sure all other applications can reach our web server by its name.&lt;/p&gt;

&lt;p&gt;Moments after it&amp;rsquo;s been started, the web server issues a &lt;code&gt;bind()&lt;/code&gt; syscall, specifying the IP/port it wants to bind to, which gets intercepted by the trap generator and forwarded to the trap handler. The latter generates another &lt;code&gt;bind()&lt;/code&gt; syscall, however the new &lt;code&gt;bind()&lt;/code&gt; has two notable differences:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;It contains the host IP and one of the reserved ports (40000 - 60000) specified at the startup&lt;/li&gt;
&lt;li&gt;It&amp;rsquo;s destined towards a host&amp;rsquo;s syscall interface&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The resulting mappings between the internal socket address of the web server, the overlay IP address assigned to it by the Appswitch and the &amp;ldquo;real&amp;rdquo; or underlay address of the host get recorded in the Service Table and gossiped to all other members of the cluster.&lt;/p&gt;

&lt;h2 id=&#34;3-processing-client-requests&#34;&gt;3. Processing client requests&lt;/h2&gt;

&lt;p&gt;Now let&amp;rsquo;s see what happens when another Appswitch application tries to connect to the previously started web server. The client may try to connect to the web server by its hostname, assuming the server was configured with one, in which case the DNS request will get handled by an embedded DNS server running on all Appswitch nodes, as a part of the same binary that runs service table and service router, and the client library will receive the overlay IP address of the web server.&lt;/p&gt;

&lt;p&gt;As soon as the &lt;code&gt;connect()&lt;/code&gt; syscall gets intercepted by the Trap Generator and forwarded to the Trap Handler, the latter consults the local Service Table and finds an entry for the web server, which was previously broadcasted to all members of the cluster. This is also a point at which Appswitch performs security isolation and load balancing:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;It checks whether security zone of a client matches the one of the server and only proceeds if they are the same. This allows users to split application into different security groups and enforce isolation between them without the need for any dataplane ACLs&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;It also determines which exact server to include in the &lt;code&gt;connect()&lt;/code&gt; syscall, in case multiple servers have registered with the same IP or hostname. This provides a fully-distributed client-side load-balancing solution without the need for any middleware.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Once all the checks have passed and a destination server has been determined, Trap Handler issues a &lt;code&gt;connect()&lt;/code&gt; syscall with the underlay IP and port of that server app. At the end of the 3-way TCP handshake the &lt;code&gt;connect()&lt;/code&gt; call returns 0 and the two applications continue to &lt;code&gt;read()&lt;/code&gt; and &lt;code&gt;write()&lt;/code&gt; using the sockfd provided by Appswitch, as if they were running directly in host network namespace.&lt;/p&gt;

&lt;h2 id=&#34;4-ingress-forwarding&#34;&gt;4. Ingress forwarding&lt;/h2&gt;

&lt;p&gt;When starting a server-side application, we have an option to make it available externally to clients outside of an Appswitch cluster, by mapping a server port to an arbitrary port of the host. This is accomplished with an &lt;code&gt;--expose INSIDE:OUTSIDE&lt;/code&gt; argument, which will map the &lt;strong&gt;INSIDE&lt;/strong&gt; application port to a specified &lt;strong&gt;OUTSIDE&lt;/strong&gt; port on the host. We can also simulate the behaviour of k8s &lt;strong&gt;NodePort&lt;/strong&gt; by changing this argument to &lt;code&gt;--expose INSIDE:0.0.0.0:OUTSIDE&lt;/code&gt;, which will expose the same port on ALL members of an Appswitch cluster.&lt;/p&gt;

&lt;h2 id=&#34;5-egress-forwarding&#34;&gt;5. Egress forwarding&lt;/h2&gt;

&lt;p&gt;All outbound client-side syscalls that don&amp;rsquo;t find a match in the local Service Table, will be forwarded to one of the Egress Gateway nodes. Any number of Appswitch instances can be designated as Egress Gateway nodes at startup, which makes them pick a random port from a reserved pool, broadcast their presence to the rest of the cluster and start listening for incoming connections from other members. When the client-side Trap Handler intercepts the &lt;code&gt;connect()&lt;/code&gt; syscall to an external service, it tweaks the address and sends it to one of the egress gateways instead. At the same time it communicates the real external service address to the egress gateway out-of-band. When the egress gateway receives the external service address, it will splice the two TCP sessions together connecting the Appswitch application to its intended external destination.&lt;/p&gt;

&lt;h1 id=&#34;demo&#34;&gt;Demo&lt;/h1&gt;

&lt;p&gt;Finally, the time has come for the proof of the pudding. To demonstrate how Appswitch works in real life I&amp;rsquo;ll use the famous Docker &lt;a href=&#34;https://github.com/dockersamples/example-voting-app&#34; target=&#34;_blank&#34;&gt;voting app&lt;/a&gt; - a simple application comprised of 5 (micro)services that all interact over standard APIs. To make it more realistic, I&amp;rsquo;ll split the voting app between two Docker hosts to demonstrate how different parts of the same application are able to communicate remotely, assisted by Appswitch. The following diagram shows how different application components are mapped to a pair docker hosts.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://networkop.co.uk/img/ax-voting.png&#34; alt=&#34;Appswitch demo&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Unlike the original voting app &lt;a href=&#34;https://github.com/dockersamples/example-voting-app/blob/master/architecture.png&#34; target=&#34;_blank&#34;&gt;diagram&lt;/a&gt; which shows the flow of data within the app, the arrows in the diagram above show the direction and destination of the initial TCP SYN, which will be important for the following explanation.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Note that in the demo we&amp;rsquo;ll deploy all necessary components manually, using &lt;code&gt;docker-compose&lt;/code&gt; and &lt;code&gt;docker run&lt;/code&gt; commands, which doesn&amp;rsquo;t mean the same can&amp;rsquo;t be done by an orchestrator. One of the goals of this demo is to be easy to reproduce and understand and I felt like using k8s would make it more confusing and distract the reader from the main point. For demonstration of how to use Appswitch inside k8s environment refer to the official &lt;a href=&#34;http://appswitch.readthedocs.io/en/latest/integrations.html&#34; target=&#34;_blank&#34;&gt;integration manual&lt;/a&gt;.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&#34;1-installation&#34;&gt;1. Installation&lt;/h2&gt;

&lt;p&gt;In order to deploy all 5 components of this app, I&amp;rsquo;ll use two docker-compose files, which are based on the original &lt;a href=&#34;https://github.com/dockersamples/example-voting-app/blob/master/docker-compose.yml&#34; target=&#34;_blank&#34;&gt;docker-compose file&lt;/a&gt;, with a few modifications to make them work with Appswitch:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;The command argument is now prepended with &lt;code&gt;/usr/bin/ax run&lt;/code&gt;, which is an Appswitch wrapper that containts the Trap Generator to tracks the network system calls&lt;/li&gt;
&lt;li&gt;Network mode is set to none - we won&amp;rsquo;t need &lt;strong&gt;any&lt;/strong&gt; network interface inside a Docker container whatsoever&lt;/li&gt;
&lt;li&gt;Volumes now include three additional items:

&lt;ul&gt;
&lt;li&gt;/var/run/appswitch - a communication channel between a trap generator running inside a container and a trap handler running in the host namespace&lt;/li&gt;
&lt;li&gt;/usr/bin/ax - an Appswitch binary made available inside a container&lt;/li&gt;
&lt;li&gt;/etc/resolv.conf - overrides container DNS settings to redirect queries to an embedded Appswitch DNS service.&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;These two docker-compose files are stored in my personal fork of the voting app and are the only thing that is different between my fork and the original repo. So the first step is to download the voting app:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;git clone https://github.com/networkop/example-voting-app.git ax; cd ax
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;To be able to run everything on a single laptop, I simulate docker hosts by running Docker daemon inside a Docker container, a pattern commonly known as docker-in-docker or &lt;a href=&#34;https://github.com/jpetazzo/dind&#34; target=&#34;_blank&#34;&gt;dind&lt;/a&gt;. Additionally I expose the Docker API ports of the two dind containers to be able to manage them from my host OS.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;docker run -d --privileged --name worker-1 --hostname=worker-1 \
-p 5000:5000 -p 12375:2375 \
-v /usr/local/bin/docker-compose:/usr/local/bin/docker-compose \
-v $(pwd):$(pwd) \
docker:stable-dind

docker run -d --privileged --name worker-2 --hostname=worker-2 \
-p 5001:5001 -p 22375:2375 \
-v /usr/local/bin/docker-compose:/usr/local/bin/docker-compose \
-v $(pwd):$(pwd) \
docker:stable-dind
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;These two commands will create a simple two-node topology as shown below:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://networkop.co.uk/img/ax-dind.png&#34; alt=&#34;Appswitch dind&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Each docker host will have its own unique IP assigned to interface &lt;code&gt;eth0&lt;/code&gt; and will most likely have the same IP assigned to internal &lt;code&gt;docker0&lt;/code&gt; bridge. We can safely ignore the latter since docker bridge is not used by Appswitch, however we would need to know the IPs assigned to &lt;code&gt;eth0&lt;/code&gt; in order to be able to bootstrap the Serf cluster.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;export IP_1=$(docker inspect worker-1 -f &amp;quot;{{ .NetworkSettings.Networks.bridge.IPAddress }}&amp;quot;)
export IP_2=$(docker inspect worker-2 -f &amp;quot;{{ .NetworkSettings.Networks.bridge.IPAddress }}&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Next, on each node we need to start an Appswitch daemon and pass the above IPs as input parameters.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;docker --host=localhost:12375 run -d --name=ax \
--pid=host `# To identify and track application threads from host namespace` \
--net=host `# To make host network available for the application` \
--privileged `# To set seccomp filter` \
-v /usr/bin:/hostbin `# To install ax to /hostbin/` \
-v /var/run/appswitch:/var/run/appswitch `# To share the UNIX socket between app and ax daemon` \
-e AX_NODE_INTERFACE=${IP_1} `# Make sure the right IP is selected`\
-e AX_NEIGHBORS=${IP_2} `# IP of peer container`\
docker.io/appswitch/ax `# Starting the main process`

docker --host=localhost:22375 run -d --name=ax \
--pid=host `# To identify and track application threads from host namespace` \
--net=host `# To make host network available for the application` \
--privileged `# To set seccomp filter` \
-v /usr/bin:/hostbin `# To install ax to /hostbin/` \
-v /var/run/appswitch:/var/run/appswitch `# To share the UNIX socket between app and ax daemon` \
-e AX_NODE_INTERFACE=${IP_2} `# Make sure the right IP is selected`\
-e AX_NEIGHBORS=${IP_1} `# IP of peer container`\
docker.io/appswitch/ax `# Starting the main process`
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;At this point our Appswitch cluster should be bootstrapped and fully functional, which we can verify by listing its members from either one of the worker nodes:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;docker exec -it worker-1 ax get nodes
    NAME     CLUSTER       IP      EXTERNALIP    ROLE     APPCOUNT  
------------------------------------------------------------------
  worker-1  appswitch  172.17.0.2              [compute]  0         
  worker-2  appswitch  172.17.0.3              [compute]  0         

&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Now the only thing that is left is to deploy our voting app using docker compose:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;docker-compose --host localhost:12375 --file ./docker-compose-1.yml up -d
docker-compose --host localhost:22375 --file ./docker-compose-2.yml up -d
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;A few minutes later the voting side of the app should become available on &lt;a href=&#34;http://localhost:5000/&#34; target=&#34;_blank&#34;&gt;localhost:5000&lt;/a&gt;, while the results can be viewed on &lt;a href=&#34;http://localhost:5001/&#34; target=&#34;_blank&#34;&gt;localhost:5001&lt;/a&gt;.You can put in more votes for cats or dogs by using &amp;ldquo;a&amp;rdquo; or &amp;ldquo;b&amp;rdquo; in the following command:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;curl -sS -X POST --data &amp;quot;vote=a&amp;quot; http://localhost:5000 &amp;gt; /dev/null
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;2-verification&#34;&gt;2. Verification&lt;/h2&gt;

&lt;p&gt;Now let&amp;rsquo;s examine how Appswitch has managed to establish connectivity between all components of our voting app. The two internal server-side components are DB and Redis, and all client-side apps (vote, worker and result) are expecting to connect to them  by using their respective hostnames - &lt;code&gt;db&lt;/code&gt; and &lt;code&gt;redis&lt;/code&gt;. Appswitch enables that by running an embedded DNS server which gets programmed with hostnames based on the &lt;code&gt;--name&lt;/code&gt; argument of &lt;code&gt;ax run&lt;/code&gt; command, as shown in the following snippet from the Redis service in docker-compose-1.yml:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-yaml&#34;&gt;command: /usr/bin/ax run --name redis redis-server
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Embedded DNS server returns the overlay IP assigned to Redis, which will be used later by client-side apps in their syscalls. In our case we didn&amp;rsquo;t specify this IP explicitly, so Appswitch picked a random IP address which can be viewed with &lt;code&gt;ax get apps&lt;/code&gt; command:&lt;/p&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Name&lt;/th&gt;
&lt;th&gt;APPID&lt;/th&gt;
&lt;th&gt;NODEID&lt;/th&gt;
&lt;th&gt;CLUSTER&lt;/th&gt;
&lt;th&gt;APPIP&lt;/th&gt;
&lt;th&gt;DRIVER&lt;/th&gt;
&lt;th&gt;LABELS&lt;/th&gt;
&lt;th&gt;ZONES&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;redis&lt;/td&gt;
&lt;td&gt;f00005bb&lt;/td&gt;
&lt;td&gt;worker-2&lt;/td&gt;
&lt;td&gt;appswitch&lt;/td&gt;
&lt;td&gt;10.244.17.175&lt;/td&gt;
&lt;td&gt;user&lt;/td&gt;
&lt;td&gt;zone=default&lt;/td&gt;
&lt;td&gt;[zone==default]&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;db&lt;/td&gt;
&lt;td&gt;f00004cd&lt;/td&gt;
&lt;td&gt;worker-1&lt;/td&gt;
&lt;td&gt;appswitch&lt;/td&gt;
&lt;td&gt;10.12.33.253&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;zone=default&lt;/td&gt;
&lt;td&gt;[zone==default]&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;As soon as DB and Redis are fully initialised and issue a &lt;code&gt;listen()&lt;/code&gt; syscall, Appswitch broadcasts the overlay-underlay address mapping to all other members of a cluster, so that each node ends up with an identical view of this table:&lt;/p&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Name&lt;/th&gt;
&lt;th&gt;CLUSTER&lt;/th&gt;
&lt;th&gt;APPID&lt;/th&gt;
&lt;th&gt;PROTO&lt;/th&gt;
&lt;th&gt;SERVICEADDR&lt;/th&gt;
&lt;th&gt;IPV4ADDR&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;worker-2&lt;/td&gt;
&lt;td&gt;appswitch&lt;/td&gt;
&lt;td&gt;f00005b9&lt;/td&gt;
&lt;td&gt;tcp&lt;/td&gt;
&lt;td&gt;redis:6379&lt;/td&gt;
&lt;td&gt;172.17.0.3:40000&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;worker-1&lt;/td&gt;
&lt;td&gt;appswitch&lt;/td&gt;
&lt;td&gt;f000056d&lt;/td&gt;
&lt;td&gt;tcp&lt;/td&gt;
&lt;td&gt;db:5432&lt;/td&gt;
&lt;td&gt;172.17.0.2:40001&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;Now, when a client-side app decides to establish a TCP session with &lt;code&gt;redis&lt;/code&gt; on port 6379, it tries to &lt;code&gt;connect()&lt;/code&gt; to &lt;code&gt;10.244.17.175:6379&lt;/code&gt;, which makes the Trap Handler issue a new &lt;code&gt;connect()&lt;/code&gt; to &lt;code&gt;172.17.0.3:40000&lt;/code&gt;, the real/underlay address of redis on worker-2 node.&lt;/p&gt;

&lt;p&gt;At the same time we have two client-side apps that act as server-side apps for external connections - vote and result. Both of these apps were started with their internal http ports exposed, like in the following example from the vote service:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-yaml&#34;&gt;command: /usr/bin/ax run --expose 80:5000 python app.py
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;When they attempt to &lt;code&gt;bind()&lt;/code&gt; to port 80, Appswitch will not try to use the dynamic port range and will try to bind to the port specified in the expose command instead:&lt;/p&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Name&lt;/th&gt;
&lt;th&gt;CLUSTER&lt;/th&gt;
&lt;th&gt;APPID&lt;/th&gt;
&lt;th&gt;PROTO&lt;/th&gt;
&lt;th&gt;SERVICEADDR&lt;/th&gt;
&lt;th&gt;IPV4ADDR&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;worker-1&lt;/td&gt;
&lt;td&gt;appswitch&lt;/td&gt;
&lt;td&gt;f00004cc&lt;/td&gt;
&lt;td&gt;tcp&lt;/td&gt;
&lt;td&gt;172.17.0.2:80&lt;/td&gt;
&lt;td&gt;172.17.0.2:5000&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;worker-2&lt;/td&gt;
&lt;td&gt;appswitch&lt;/td&gt;
&lt;td&gt;f0000627&lt;/td&gt;
&lt;td&gt;tcp&lt;/td&gt;
&lt;td&gt;172.17.0.3:80&lt;/td&gt;
&lt;td&gt;172.17.0.3:5001&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;This port mapping will only make these ports available inside their respective docker hosts, which is why we&amp;rsquo;ve exposed ports 5000 and 5001 when starting dind containers earlier.&lt;/p&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;CONTAINER ID&lt;/th&gt;
&lt;th&gt;IMAGE&lt;/th&gt;
&lt;th&gt;COMMAND&lt;/th&gt;
&lt;th&gt;CREATED&lt;/th&gt;
&lt;th&gt;STATUS&lt;/th&gt;
&lt;th&gt;PORTS&lt;/th&gt;
&lt;th&gt;NAMES&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;303d5ae4d63d&lt;/td&gt;
&lt;td&gt;docker:stable-dind&lt;/td&gt;
&lt;td&gt;&amp;ldquo;dockerd-entrypoint.…&amp;rdquo;&lt;/td&gt;
&lt;td&gt;12 hours ago&lt;/td&gt;
&lt;td&gt;Up 7 hours&lt;/td&gt;
&lt;td&gt;0.0.0.0:5001-&amp;gt;5001/tcp, 0.0.0.0:22375-&amp;gt;2375/tcp&lt;/td&gt;
&lt;td&gt;worker-2&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;2421e7556bc1&lt;/td&gt;
&lt;td&gt;docker:stable-dind&lt;/td&gt;
&lt;td&gt;&amp;ldquo;dockerd-entrypoint.…&amp;rdquo;&lt;/td&gt;
&lt;td&gt;12 hours ago&lt;/td&gt;
&lt;td&gt;Up 7 hours&lt;/td&gt;
&lt;td&gt;0.0.0.0:5000-&amp;gt;5000/tcp, 0.0.0.0:12375-&amp;gt;2375/tcp&lt;/td&gt;
&lt;td&gt;worker-1&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;So a TCP SYN towards localhost:5000 will get PAT&amp;rsquo;ed by Docker-managed iptables of the Docker host, will hit the TCP/IP stack of the worker-1 node, which, once the handshake is complete, will issue an accept() syscall towards a Trap Handler and ultimately towards port 80 of the vote app.&lt;/p&gt;

&lt;h1 id=&#34;outro&#34;&gt;Outro&lt;/h1&gt;

&lt;p&gt;The reason why I called this article &amp;ldquo;Serverless SDN&amp;rdquo; is because I find this to be a rather fitting description of what Appswitch is. Just like serverless computing, which abstracts away the underlying OS and server management, Appswitch abstracts away the networking stack of the host and provides networking abstractions at a well-defined socket layer. Reading through the &lt;a href=&#34;https://appswitch.readthedocs.io/en/latest/index.html&#34; target=&#34;_blank&#34;&gt;official documentation&lt;/a&gt; and Appswitch &lt;a href=&#34;http://hci.stanford.edu/cstr/reports/2017-01.pdf&#34; target=&#34;_blank&#34;&gt;research paper&lt;/a&gt;, I can&amp;rsquo;t get rid of the thought that this is what container networking should have looked like in the first place - not linux bridges and veth pairs and not even macvlan and ipvlan devices. The original goal of containers was to encapsulate a single process and in majority of cases that single process does not need to have a full TCP/IP stack with its own interface, IP address, MAC address - all what it cares about is sending and receiving data - and this is exactly what Appswitch provides.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>The problem of unpredictable interface order in multi-network Docker containers</title>
      <link>https://networkop.co.uk/post/2018-03-03-docker-multinet/</link>
      <pubDate>Sat, 03 Mar 2018 00:00:00 +0000</pubDate>
      
      <guid>https://networkop.co.uk/post/2018-03-03-docker-multinet/</guid>
      <description>

&lt;p&gt;Whether we like it or not, the era of DevOps is upon us, fellow network engineers, and with it come opportunities to approach and solve common networking problems
in new, innovative ways. One such problem is automated network change validation and testing in virtual environments, something I&amp;rsquo;ve already &lt;a href=&#34;https://networkop.co.uk/blog/2016/02/19/network-ci-intro/&#34;&gt;written about&lt;/a&gt; a few years ago. The biggest problem with my original approach was that I had to create a custom &lt;a href=&#34;https://networkop.co.uk/blog/2016/01/01/rest-for-neteng/&#34;&gt;REST API SDK&lt;/a&gt; to work with a network simulation environment (UnetLab) that was never designed to be interacted with in a programmatic way. On the other hand, technologies like Docker have been very interesting since they were built around the idea of non-interactive lifecycle management and came with all &lt;a href=&#34;http://docker-py.readthedocs.io/en/stable/containers.html&#34; target=&#34;_blank&#34;&gt;API batteries&lt;/a&gt; already included. However, Docker was never intended to be used for network simulations and its support for multiple network interfaces is&amp;hellip; somewhat problematic.&lt;/p&gt;

&lt;h1 id=&#34;problem-demonstration&#34;&gt;Problem demonstration&lt;/h1&gt;

&lt;p&gt;The easiest way to understand the problem is to see it. Let&amp;rsquo;s start with a blank Docker host and create a few networks:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;docker network create net1
docker network create net2
docker network create net3
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Now let&amp;rsquo;s see what prefixes have been allocated to those networks:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;docker network inspect -f &amp;quot;{{range .IPAM.Config }}{{.Subnet}}{{end}}&amp;quot; net1
172.17.0.0/16
docker network inspect -f &amp;quot;{{range .IPAM.Config }}{{.Subnet}}{{end}}&amp;quot; net2
172.18.0.0/16
docker network inspect -f &amp;quot;{{range .IPAM.Config }}{{.Subnet}}{{end}}&amp;quot; net3
172.19.0.0/16
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Finally, let&amp;rsquo;s create a container and attach it to these networks:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;docker create --name test -it alpine sh
docker network connect net1 test
docker network connect net2 test
docker network connect net3 test
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Now obviously you would expect for networks to appear in the same order as they were attached, right? Let&amp;rsquo;s see if it&amp;rsquo;s true:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;docker start test
docker exec -it test sh -c &amp;quot;ip a | grep &#39;inet&#39;&amp;quot;
inet 127.0.0.1/8 scope host lo
inet 172.26.0.2/16 brd 172.26.255.255 scope global eth0
inet 172.17.0.2/16 brd 172.17.255.255 scope global eth1
inet 172.18.0.2/16 brd 172.18.255.255 scope global eth2
inet 172.19.0.2/16 brd 172.19.255.255 scope global eth3
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Looks good so far. The first interface (172.26.0.2/16) is the docker bridge that was attached by default in &lt;code&gt;docker create&lt;/code&gt; command. Now let&amp;rsquo;s add another network.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;docker network create net4
docker stop test
docker network connect net4 test
docker start test
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Let&amp;rsquo;s examine our interfaces again:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;docker exec -it test sh -c &amp;quot;ip a | grep &#39;inet&#39;&amp;quot;
inet 127.0.0.1/8 scope host lo
inet 172.26.0.2/16 brd 172.26.255.255 scope global eth0
inet 172.20.0.2/16 brd 172.20.255.255 scope global eth3
inet 172.17.0.2/16 brd 172.17.255.255 scope global eth2
inet 172.18.0.2/16 brd 172.18.255.255 scope global eth1
inet 172.19.0.2/16 brd 172.19.255.255 scope global eth4
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Now we&amp;rsquo;re seeing that networks are in a completely different order. Looks like net1 is connected to eth2, net2 to eth1, net3 to eth4 and net4 to eth3. In fact, this issue should manifest itself even with 2 or 3 networks, however, I&amp;rsquo;ve found that it doesn&amp;rsquo;t always reorder them in that case.&lt;/p&gt;

&lt;h1 id=&#34;cnm-and-libnetwork-architecture&#34;&gt;CNM and libnetwork architecture&lt;/h1&gt;

&lt;p&gt;In order to better understand the issue, it helps to know the CNM terminology and network lifecycle events which are explained in libnetwork&amp;rsquo;s &lt;a href=&#34;https://github.com/docker/libnetwork/blob/master/docs/design.md&#34; target=&#34;_blank&#34;&gt;design document&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://github.com/docker/libnetwork/raw/master/docs/cnm-model.jpg?raw=true&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Each time we run a &lt;code&gt;docker network create&lt;/code&gt; command a new &lt;strong&gt;CNM network&lt;/strong&gt; object is created. This object has a specific network type (&lt;code&gt;bridge&lt;/code&gt; by default) which identifies the driver to be used for the actual network implementation.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;network, err := controller.NewNetwork(&amp;quot;bridge&amp;quot;, &amp;quot;net1&amp;quot;, &amp;quot;&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;When container gets attached to its networks, first time in &lt;code&gt;docker create&lt;/code&gt; and subsequently in &lt;code&gt;docket network connect&lt;/code&gt; commands, an &lt;strong&gt;endpoint object&lt;/strong&gt; is created on each of the networks being connected. This endpoint object represents container&amp;rsquo;s point of attachment (similar to a switch port) to docker networks and may allocate IP settings for a future network interface.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;ep, err := network.CreateEndpoint(&amp;quot;ep1&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;At the time when container gets attached to its first network, a &lt;strong&gt;sandbox object&lt;/strong&gt; is created. This object represents a container inside CNM object model and stores pointers to all attached network endpoints.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;sbx, err := controller.NewSandbox(&amp;quot;test&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Finally, when we start a container using &lt;code&gt;docker start&lt;/code&gt; command, the corresponding &lt;strong&gt;sandbox gets attached&lt;/strong&gt; to all associated network endpoints using the &lt;code&gt;ep.Join(sandbox)&lt;/code&gt; call:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;for _, ep := range epList {
	if err := ep.Join(sb); err != nil {
		logrus.Warnf(&amp;quot;Failed attach sandbox %s to endpoint %s: %v\n&amp;quot;, sb.ID(), ep.ID(), err)
	}
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h1 id=&#34;going-down-the-rabbit-hole&#34;&gt;Going down the rabbit hole&lt;/h1&gt;

&lt;p&gt;Looking at the above snippet from &lt;code&gt;sandbox.go&lt;/code&gt;, we can assume that the order in which networks will be attached to a container will depend on the order of elements inside the &lt;code&gt;epList&lt;/code&gt; array, which gets built earlier in the function:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;epList := sb.getConnectedEndpoints()
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Now let&amp;rsquo;s see what happens inside that method call:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;func (sb *sandbox) getConnectedEndpoints() []*endpoint {
	sb.Lock()
	defer sb.Unlock()

	eps := make([]*endpoint, len(sb.endpoints))
	for i, ep := range sb.endpoints {
		eps[i] = ep
	}

	return eps
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;So &lt;code&gt;epList&lt;/code&gt; is just an array of endpoints that gets built by copying values from &lt;code&gt;sb.endoints&lt;/code&gt;, which itself is an attribute (or field) inside the &lt;code&gt;sb&lt;/code&gt; struct.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;type epHeap []*endpoint

type sandbox struct {
  id                 string
  containerID        string
...
  endpoints          epHeap
...
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;At this point it looks like &lt;code&gt;endpoints&lt;/code&gt; is just an array of pointers to endpoint objects, which still doesn&amp;rsquo;t explain the issue we&amp;rsquo;re investigating. Perhaps it would make more sense if we saw how a sandbox object gets created.&lt;/p&gt;

&lt;p&gt;Since sandbox object gets created by calling &lt;code&gt;controller.NewSandbox()&lt;/code&gt; method, let&amp;rsquo;s see exactly how this is done by looking at the code inside the &lt;code&gt;controller.go&lt;/code&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;func (c *controller) NewSandbox(containerID string, options ...SandboxOption) (Sandbox, error) {
...
  // Create sandbox and process options first. Key generation depends on an option
  if sb == nil {
    sb = &amp;amp;sandbox{
      id:                 sandboxID,
      containerID:        containerID,
      endpoints:          epHeap{},
...
    }
  }

  heap.Init(&amp;amp;sb.endpoints)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The last statement explains why sandbox connects networks in random order. The &lt;code&gt;endpoints&lt;/code&gt; array is, in fact, a &lt;a href=&#34;https://golang.org/pkg/container/heap/&#34; target=&#34;_blank&#34;&gt;heap&lt;/a&gt; - an ordered tree, where parent node is always smaller than (or equal to) its children (minheap). Heap is used to implement a priority queue, which should be familiar to every network engineer who knows QoS. One of heap&amp;rsquo;s properties is that it re-orders elements every time an element gets added or removed, in order to maintain the heap invariant (parent &amp;lt;= child).&lt;/p&gt;

&lt;h1 id=&#34;problem-solution&#34;&gt;Problem solution&lt;/h1&gt;

&lt;p&gt;It turns out the problem demonstrated above is a very well-known problem with multiple opened issues on Github [&lt;a href=&#34;https://github.com/moby/moby/issues/25181&#34; target=&#34;_blank&#34;&gt;1&lt;/a&gt;,&lt;a href=&#34;https://github.com/moby/moby/issues/23742&#34; target=&#34;_blank&#34;&gt;2&lt;/a&gt;,&lt;a href=&#34;https://github.com/moby/moby/issues/35221&#34; target=&#34;_blank&#34;&gt;3&lt;/a&gt;]. I was lucky enough to have discovered this problem right after &lt;a href=&#34;https://github.com/docker/libnetwork/issues/2093&#34; target=&#34;_blank&#34;&gt;this pull request&lt;/a&gt; got submitted, which is what helped me understand what the issue was in the first place. This pull request reference a &lt;a href=&#34;https://github.com/cziebuhr/libnetwork/commit/d047825d4d156bc4cf01bfe410cb61b3bc33f572&#34; target=&#34;_blank&#34;&gt;patch&lt;/a&gt; that swaps the heapified array with a normal one. Below I&amp;rsquo;ll show how to build a custom docker daemon binary using this patch. We&amp;rsquo;ll start with a privileged centos-based Docker container:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Update 2018-04-28&lt;/strong&gt;: Much easier procedure is documented &lt;a href=&#34;https://github.com/networkop/libnetwork-multinet.git&#34; target=&#34;_blank&#34;&gt;here&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;docker run --privileged -it centos bash
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Inside this container we need to install all the dependencies along with Docker. Yes, you need Docker to build Docker:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;yum install -y git iptables \
            make &amp;quot;Development Tools&amp;quot; \
            yum-utils device-mapper-persistent-data \
            lvm2

yum-config-manager --add-repo \
    https://download.docker.com/linux/centos/docker-ce.repo

yum install docker-ce -y

# Start docker in the background
/usr/bin/dockerd &amp;gt;/dev/null &amp;amp;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Next let&amp;rsquo;s clone the Docker master branch and the patched fork of libnetwork:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;git clone --depth=1 https://github.com/docker/docker.git /tmp/docker-repo
git clone https://github.com/cziebuhr/libnetwork.git /tmp/libnetwork-patch
cd /tmp/libnetwork-patch
git checkout d047825d4d156bc4cf01bfe410cb61b3bc33f572
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;I tried using &lt;a href=&#34;https://github.com/LK4D4/vndr&#34; target=&#34;_blank&#34;&gt;VNDR&lt;/a&gt; to update the libnetwork files inside the Docker repository, however I ran into problems with incompatible git options on CentOS. So instead I&amp;rsquo;ll update libnetwork manually, with just the files that are different from the original repo:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;cd /tmp/libnetwork-patch
/usr/bin/cp controller.go endpoint.go sandbox.go sandbox_store.go /tmp/docker-repo/vendor/github.com/docker/libnetwork/
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Final step is to build docker binaries. This step may require up to 100G of free disk space and may take up to 60 minutes depending on your network speed.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;cd /tmp/docker-repo
make build
make binary
...
Created binary: bundles/binary-daemon/dockerd-dev
&lt;/code&gt;&lt;/pre&gt;

&lt;h1 id=&#34;verification&#34;&gt;Verification&lt;/h1&gt;

&lt;p&gt;Once done, we can retrieve the binaries outside of the build container:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;find /var/lib/docker -name dockerd
/var/lib/docker/overlay2/ac310ef5172acac7e8cb748092a9c9d1ddc3c25a91e636ab581cfde0869f5d76/diff/tmp/docker-repo/bundles/binary-daemon/dockerd
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Now we can swap the current docker daemon with the patched one:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;yum install which -y
systemctl stop docker.service
DOCKERD=$(which dockerd)
mv $DOCKERD $DOCKERD-old
cp /tmp/docker-repo/bundles/latest/binary-daemon/dockerd $DOCKERD
systemctl start docker.service
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Make sure that SELinux security context on both $DOCKERD and $DOCKERD-old are the same&lt;/p&gt;

&lt;p&gt;If we re-run our tests now, the interfaces are returned in the same exact order they were added:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;docker start test
docker exec -it test sh -c &amp;quot;ip a | grep &#39;inet&#39;&amp;quot;
inet 127.0.0.1/8 scope host lo
inet 172.26.0.2/16 brd 172.26.255.255 scope global eth0
inet 172.17.0.2/16 brd 172.17.255.255 scope global eth1
inet 172.18.0.2/16 brd 172.18.255.255 scope global eth2
inet 172.19.0.2/16 brd 172.19.255.255 scope global eth3
inet 172.20.0.2/16 brd 172.20.255.255 scope global eth4
&lt;/code&gt;&lt;/pre&gt;

&lt;hr /&gt;

&lt;p&gt;Huge kudos to the original &lt;a href=&#34;https://github.com/cziebuhr&#34; target=&#34;_blank&#34;&gt;author&lt;/a&gt; of the &lt;a href=&#34;https://github.com/cziebuhr/libnetwork/commit/d047825d4d156bc4cf01bfe410cb61b3bc33f572&#34; target=&#34;_blank&#34;&gt;libnetwork patch&lt;/a&gt; which is the sole reason this blogpost exists. I really hope that this issue will get resolved, in this form or another (could it be possible to keep track of the order in which endpoints are added to a sandbox and use that as a criteria for heap sort?), as this will make automated network testing much more approachable.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>OpenStack SDN</title>
      <link>https://networkop.co.uk/tags/openstack-sdn/</link>
      <pubDate>Tue, 02 Jan 2018 00:00:00 +0000</pubDate>
      
      <guid>https://networkop.co.uk/tags/openstack-sdn/</guid>
      <description>

&lt;h2 id=&#34;openstack-sdn-tags-openstack-sdn-learn-through-hands-on-experience-everything-you-need-to-know-about-vanilla-openstack-neutron-implementation-of-virtual-networks-including-custom-sdn-controllers-like-ovn-opendaylight-and-opencontrail&#34;&gt;&lt;a href=&#34;https://networkop.co.uk/tags/openstack-sdn/&#34;&gt;OpenStack SDN&lt;/a&gt; - Learn through hands-on experience everything you need to know about vanilla OpenStack Neutron implementation of virtual networks, including custom SDN controllers like OVN, OpenDaylight and OpenContrail&lt;/h2&gt;
</description>
    </item>
    
    <item>
      <title>OpenStack SDN - OpenContrail With BGP VPN</title>
      <link>https://networkop.co.uk/blog/2018/01/02/os-contrail/</link>
      <pubDate>Tue, 02 Jan 2018 00:00:00 +0000</pubDate>
      
      <guid>https://networkop.co.uk/blog/2018/01/02/os-contrail/</guid>
      <description>

&lt;p&gt;Continuing on the trend started in my &lt;a href=&#34;https://networkop.co.uk/blog/2017/12/15/os-odl-netvirt/&#34;&gt;previous post about OpenDaylight&lt;/a&gt;, I&amp;rsquo;ll move on to the next open-source product that uses BGP VPNs for optimal North-South traffic forwarding. OpenContrail is one of the most popular SDN solutions for OpenStack. It was one of the first hybrid SDN solutions, offering both pure overlay and overlay/underlay integration. It is the default SDN platform of choice for Mirantis Cloud Platform, it has multiple large-scale deployments in companies like Workday and AT&amp;amp;T. I, personally, don&amp;rsquo;t have any production experience with OpenContrail, however my impression, based on what I&amp;rsquo;ve heard and seen in the last 2-3 years that I&amp;rsquo;ve been following Telco SDN space, is that OpenContrail is the most mature SDN platform for Telco NFVs not least because of its unique feature set.&lt;/p&gt;

&lt;p&gt;During the time of production deployment at AT&amp;amp;T, Contrail has added a lot of features required by Telco NFVs like QoS, VLAN trunking and BGP-as-a-service. My first acquaintance with BGPaaS took place when I started working on Telco DCs and I remember being genuinely shocked when I first saw the requirement for dynamic routing exchange with VNFs. To me this seemed to break one of the main rules of cloud networking - a VM is not to have any knowledge or interaction with the underlay. I gradually went though all stages of grief, all the way to acceptance and although it still feels &amp;ldquo;wrong&amp;rdquo; now, I can at least understand why it&amp;rsquo;s needed and what are the pros/cons of different BGPaaS solutions.&lt;/p&gt;

&lt;h1 id=&#34;bgp-as-a-service&#34;&gt;BGP-as-a-Service&lt;/h1&gt;

&lt;p&gt;There&amp;rsquo;s a certain range of VNFs that may require to advertise a set of IP addresses into the existing VPNs inside Telco network. The most notable example is PGW inside EPC. I won&amp;rsquo;t pretend to be an expert in this field, but based on my limited understanding PGW needs to advertise IP networks into various customer VPNs, for example to connect private APNs to existing customer L3VPNs. Obviously, when this kind of network function gets virtualised, it still retains this requirement which now needs to be fulfilled by DC SDN.&lt;/p&gt;

&lt;p&gt;This requirement catches a lot of big SDN vendors off guard and the best they come up with is connecting those VNFs, through VLANs, directly to underlay TOR switches. Although this solution is easy to implement, it has an incredible amount of drawbacks since a single VNF can now affect the stability of the whole POD or even the whole DC network. Some VNFs vendors also require BFD to monitor liveliness of those BGP sessions which, in case a L3 boundary is higher than the TOR, may create even a bigger number of issues on a POD spine.&lt;/p&gt;

&lt;p&gt;There&amp;rsquo;s a small range of SDN platforms that run a full routing stack on each compute node (e.g. Cumulus, Calico). These solutions are the best fit for this kind of scenarios since they allow BGP sessions to be established over a single hop (VNF &amp;lt;-&amp;gt; virtual switch). However they represent a small fraction of total SDN solutions space with majority of vendors implementing a much simpler OpenFlow or XMPP-based flow push model.&lt;/p&gt;

&lt;p&gt;OpenContrail, as far as I know, is the only SDN controller that doesn&amp;rsquo;t run a full routing stack on compute nodes but still fulfills this requirement in a very elegant way. When &lt;a href=&#34;https://www.juniper.net/documentation/en_US/contrail3.2/topics/concept/bgp-as-a-service-overview.html&#34; target=&#34;_blank&#34;&gt;BGPaaS&lt;/a&gt; is enabled for a particular VM&amp;rsquo;s interface, controller programs vRouter to proxy BGP TCP connections coming to virtual network&amp;rsquo;s default gateway IP and forward them to the controller. This way VNF thinks it peers with a next hop IP, however all BGP state and path computations still happen on the controller.&lt;/p&gt;

&lt;p&gt;The diagram below depicts a sample implementation of BGPaaS using OpenContrail. VNF is connected to a vRouter using a dot1Q trunk interface (to allow multiple VRFs over a single vEth link). Each VRF has its own BGPaaS session setup to advertise network ranges (NET1-3) into customer VPNs. These BGP sessions get proxied to the controller which injects those prefixes into their respective VPNs. These updates are then sent to DC gateways using either a VPNv4/6 or EVPN and the traffic is forwarded through DC underlay with VPN segregation preserved by either an MPLS tag (for MPLSoGRE or MPLSoUDL encapsulation) or a VXLAN VNI.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://networkop.co.uk/img/contrail-bgpaas.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Now let me briefly go over the lab that I&amp;rsquo;ve built to showcase the BGPaaS and DC-GW integration features.&lt;/p&gt;

&lt;h1 id=&#34;lab-setup-overview&#34;&gt;Lab setup overview&lt;/h1&gt;

&lt;p&gt;OpenContrail follows a familiar pattern of DC SDN architecture with central controller orchestrating the work of multiple virtual switches. In case of OpenContrail, these switches are called vRouters and they communicate with controller using XMPP-based extension of BGP as described in &lt;a href=&#34;https://www.ietf.org/archive/id/draft-ietf-l3vpn-end-system-06.txt&#34; target=&#34;_blank&#34;&gt;this RFC draft&lt;/a&gt;. A very detailed description of its internal architecture is available on &lt;a href=&#34;http://www.opencontrail.org/opencontrail-architecture-documentation/&#34; target=&#34;_blank&#34;&gt;OpenContrail&amp;rsquo;s website&lt;/a&gt; so it would be pointless to repeat all of this information here. That&amp;rsquo;s why I&amp;rsquo;ll concentrate on how to get things done rather then on the architectural aspects. However to get things started, I always like to have a clear picture of what I&amp;rsquo;m trying to achieve. The below diagram depicts a high-level architecture of my lab setup. Although OpenContrail supports BGP VPNv4/6 with multiple dataplane encapsulations, in this post I&amp;rsquo;ll use EVPN as the only control plane protocol to communicate with MX80 and use VXLAN encapsulation in the dataplane.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://networkop.co.uk/img/contrail-lab.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;EVPN as a DC-GW integration protocol is relatively new to OpenContrail and comes with a few limitations. One of them is the absence of EVPN type-5 routes, which means I can&amp;rsquo;t use it in the same way I did in &lt;a href=&#34;https://networkop.co.uk/blog/2017/12/15/os-odl-netvirt/&#34;&gt;OpenDaylight&amp;rsquo;s case&lt;/a&gt;. Instead I&amp;rsquo;ll demonstrate a DC-GW IRB scenario, which extends the existing virtual network to a DC-GW and makes IRB/SVI interface on that DC-GW act as a default gateway for this network. This is a very common scenario for L2 DCI and active-active DC deployment models. To demonstrate this scenario I&amp;rsquo;m going to setup a single OpenStack virtual network with a couple of VMs whose gateway will reside on MX80. Since I only have a single OpenStack instance and a single MX80, I&amp;rsquo;ll setup one half of L2 DCI and setup a mutual redistribution to make our overlay network reachable from MX80&amp;rsquo;s global routing table.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://networkop.co.uk/img/contrail-overlay.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h1 id=&#34;all-in-one-vm-setup&#34;&gt;All-in-one VM setup&lt;/h1&gt;

&lt;p&gt;Physically, my lab will consist of a single hypervisor running an all-in-one VM with &lt;a href=&#34;https://docs.openstack.org/kolla/latest/&#34; target=&#34;_blank&#34;&gt;kolla-openstack&lt;/a&gt; and &lt;a href=&#34;https://github.com/Juniper/contrail-docker/wiki/OpenContrail-Kolla&#34; target=&#34;_blank&#34;&gt;kolla-contrail&lt;/a&gt; and a physical Juniper MX80 playing the role of a DC-GW.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://networkop.co.uk/img/contrail-setup.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;OpenContrail&amp;rsquo;s &lt;a href=&#34;https://github.com/Juniper/contrail-docker/wiki/OpenContrail-Kolla&#34; target=&#34;_blank&#34;&gt;kolla github page&lt;/a&gt; contains a set of instructions to setup the environment. As usual, I have automated all of these steps which can be setup from a hypervisor with the following commands:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;git clone https://github.com/networkop/kolla-odl-bgpvpn &amp;amp;&amp;amp; cd kolla-odl-bgpvpn
./1-create.sh do 
./2-contrail.sh do
&lt;/code&gt;&lt;/pre&gt;

&lt;h1 id=&#34;openstack-setup&#34;&gt;OpenStack setup&lt;/h1&gt;

&lt;p&gt;Once installation is complete and all docker containers are up and running, we can setup the OpenStack side of our test environment. The script below will do the following:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Download cirros and CumulusVX images and upload them to Glance&lt;/li&gt;
&lt;li&gt;Create a virtual network&lt;/li&gt;
&lt;li&gt;Update security rules to allow inbound ICMP and SSH connections&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Create a pair of VMs - one based on cirros and one based on CumulusVX image&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;curl -L -o ./cirros http://download.cirros-cloud.net/0.3.5/cirros-0.3.5-x86_64-disk.img
curl -L -o ./cumulusVX http://cumulusfiles.s3.amazonaws.com/cumulus-linux-3.5.0-vx-amd64.qcow2

openstack image create --disk-format qcow2 --container-format bare --public \
--property os_type=linux --file ./cirros cirros
rm ./cirros

openstack image create --disk-format qcow2 --container-format bare --public \
--property os_type=linux --file ./cumulusVX cumulus
rm ./cumulusVX

openstack network create --provider-network-type vxlan irb-net

openstack subnet create --subnet-range 10.0.100.160/27 --network irb-net \
  --host-route destination=0.0.0.0/0,gateway=10.0.100.190 \
  --gateway 10.0.100.161 --dns-nameserver 8.8.8.8 irb-subnet

openstack flavor create --id 1 --ram 256 --disk 1 --vcpus 1 m1.nano
openstack flavor create --id 2 --ram 512 --disk 10 --vcpus 1 m1.tiny

ADMIN_PROJECT_ID=$(openstack project show &#39;admin&#39; -f value -c id)
ADMIN_SEC_GROUP=$(openstack security group list --project ${ADMIN_PROJECT_ID} | awk &#39;/ default / {print $2}&#39;)
openstack security group rule create --ingress --ethertype IPv4 \
--protocol icmp ${ADMIN_SEC_GROUP}
openstack security group rule create --ingress --ethertype IPv4 \
--protocol tcp --dst-port 22 ${ADMIN_SEC_GROUP}

openstack server create --image cirros --flavor m1.nano --net irb-net VM1
openstack server create --image cumulus --flavor m1.tiny --net irb-net VR1
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;The only thing worth noting in the above script is that a default gateway &lt;code&gt;10.0.100.161&lt;/code&gt; gets overridden by a default host route pointing to &lt;code&gt;10.0.100.190&lt;/code&gt;. Normally, to demonstrate DC-GW IRB scenario, I would have setup a gateway-less L2 only subnet, however in that case I wouldn&amp;rsquo;t have been able to demonstrate BGPaaS on the same network, since this feature relies on having a gateway IP setup (which later acts as a BGP session termination endpoint). So instead of setting up two separate networks I&amp;rsquo;ve decided to implement this hack to minimise the required configuration.&lt;/p&gt;

&lt;h1 id=&#34;evpn-integration-with-mx80&#34;&gt;EVPN integration with MX80&lt;/h1&gt;

&lt;p&gt;DC-GW integration procedure is very simple and requires only a few simple steps:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Make sure VXLAN VNI is matched on both ends&lt;/li&gt;
&lt;li&gt;Configure import/export route targets&lt;/li&gt;
&lt;li&gt;Setup BGP peering with DC-GW&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;All of these steps can be done very easily through OpenContrail&amp;rsquo;s GUI. However as I&amp;rsquo;ve mentioned before, I always prefer to use API when I have a chance and in this case I even have a python library for OpenContrail&amp;rsquo;s REST API available on Juniper&amp;rsquo;s &lt;a href=&#34;https://github.com/Juniper/contrail-python-api&#34; target=&#34;_blank&#34;&gt;github page&lt;/a&gt;, which I&amp;rsquo;m going to use below to implement the above three steps.&lt;/p&gt;

&lt;h2 id=&#34;configuration&#34;&gt;Configuration&lt;/h2&gt;

&lt;p&gt;Before we can begin working with OpenContrail&amp;rsquo;s API, we need to authenticate with the controller and get a REST API connection handler.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import pycontrail.client as client
CONTRAIL_API = &#39;http://10.0.100.140:8082&#39;
AUTH_URL = &#39;http://10.0.100.140:5000/v2.0&#39;
AUTH_PARAMS = {
    &#39;type&#39;: &#39;keystone&#39;,
    &#39;username&#39;: &#39;admin&#39;,
    &#39;password&#39;: &#39;mypassword&#39;,
    &#39;tenant_name&#39;: &#39;admin&#39;,
    &#39;auth_url&#39;: AUTH_URL
}
conn = client.Client(url=CONTRAIL_API,auth_params=AUTH_PARAMS)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The first thing I&amp;rsquo;m going to do is override the default VNI setup by OpenContrail for &lt;code&gt;irb-net&lt;/code&gt; to a pre-defined value of &lt;code&gt;5001&lt;/code&gt;. To do that I first need to get a handler for &lt;code&gt;irb-net&lt;/code&gt; object and extract the &lt;code&gt;virtual_network_properties&lt;/code&gt; object containing a &lt;code&gt;vxlan_network_identifier&lt;/code&gt; property. Once it&amp;rsquo;s overridden, I just need to update the parent &lt;code&gt;irb-net&lt;/code&gt; object to apply the change to the running configuration on the controller.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;irb_net = conn.virtual_network_read(fq_name = [ &#39;default-domain&#39;, &#39;admin&#39; ,&#39;irb-net&#39;] )
vni_props=irb_net.get_virtual_network_properties()
vni_props.set_vxlan_network_identifier(5001)
irb_net.set_virtual_network_properties(vni_props)
conn.virtual_network_update(irb_net)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The next thing I need to do is explicitly set the import/export route-target properties for the &lt;code&gt;irb-net&lt;/code&gt; object. This will require a new &lt;code&gt;RouteTargetList&lt;/code&gt; object which then gets referenced by a &lt;code&gt;route_target_list&lt;/code&gt; property of the &lt;code&gt;irb-net&lt;/code&gt; object.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from pycontrail import types as t
new_rtl = t.RouteTargetList([&#39;target:200:200&#39;])
irb_net.set_route_target_list(new_rtl)
conn.virtual_network_update(irb_net)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The final step is setting up a peering with MX80. The main object that needs to be created is &lt;code&gt;BgpRouter&lt;/code&gt;, which contains a pointer to BGP session parameters object with session-specific values like ASN and remote peer IP. BGP router is defined in a global context (default domain and default project) which will make it available to all configured virtual networks.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from pycontrail import types as t
ctx = [&#39;default-domain&#39;, &#39;default-project&#39;, &#39;ip-fabric&#39;, &#39;__default__&#39;]
af = t.AddressFamilies(family=[&#39;inet-vpn&#39;, &#39;e-vpn&#39;])
bgp_params = t.BgpRouterParams(vendor=&#39;Juniper&#39;, \
                               autonomous_system=65411, \
                               address=&#39;10.0.101.15&#39;, \
                               address_families=af)
vrf = conn.routing_instance_read(fq_name = ctx)
bgp_router = t.BgpRouter(name=&#39;MX80&#39;, display_name=&#39;MX80&#39;, \
                         bgp_router_parameters=bgp_params,
                         parent_obj=vrf)
contrail = conn.bgp_router_read(fq_name = ctx + [&#39;controller-1&#39;])
bgp_router.set_bgp_router(contrail,t.BgpPeeringAttributes())
conn.bgp_router_create(bgp_router)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;For the sake of brevity, I will not cover MX80&amp;rsquo;s configuration in details and simply include it here for reference with some minor explanatory comments.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;# Interface and global settings configuration
set interfaces irb unit 5001 family inet address 10.0.100.190/27
set interfaces lo0 unit 0 family inet address 10.0.101.15/32
set routing-options router-id 10.0.101.15
set routing-options autonomous-system 65411

# Setup BGP peering with OpenContrail
set protocols bgp group CONTRAIL multihop
set protocols bgp group CONTRAIL local-address 10.0.101.15
set protocols bgp group CONTRAIL family inet-vpn unicast
set protocols bgp group CONTRAIL family evpn signaling
set protocols bgp group CONTRAIL peer-as 64512
set protocols bgp group CONTRAIL neighbor 10.0.100.140

# Setup EVPN instance type with IRB interface and matching RT and VNI
set routing-instances EVPN-L2-IRB vtep-source-interface lo0.0
set routing-instances EVPN-L2-IRB instance-type evpn
set routing-instances EVPN-L2-IRB vlan-id 501
set routing-instances EVPN-L2-IRB routing-interface irb.5001
set routing-instances EVPN-L2-IRB vxlan vni 5001
set routing-instances EVPN-L2-IRB route-distinguisher 200:200
set routing-instances EVPN-L2-IRB vrf-target target:200:200
set routing-instances EVPN-L2-IRB protocols evpn encapsulation vxlan

# Setup VRF instance with IRB interface
set routing-instances EVPN-L3-IRB instance-type vrf
set routing-instances EVPN-L3-IRB interface irb.5001
set routing-instances EVPN-L3-IRB route-distinguisher 201:200
set routing-instances EVPN-L3-IRB vrf-target target:200:200

# Setup route redistribution between EVPN and Global VRFs
set routing-options rib-groups CONTRAIL-TO-GLOBAL import-rib EVPN-L3-IRB.inet.0
set routing-options rib-groups CONTRAIL-TO-GLOBAL import-rib inet.0
set routing-options rib-groups GLOBAL-TO-CONTRAIL import-rib inet.0
set routing-options rib-groups GLOBAL-TO-CONTRAIL import-rib EVPN-L3-IRB.inet.0
set routing-options interface-routes rib-group inet CONTRAIL-TO-GLOBAL
set routing-instances EVPN-L3-IRB routing-options interface-routes rib-group inet CONTRAIL-TO-GLOBAL
set protocols bgp group EXTERNAL-BGP family inet unicast rib-group GLOBAL-TO-CONTRAIL
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;verification&#34;&gt;Verification&lt;/h2&gt;

&lt;p&gt;The easiest way to verify that BGP peering has been established is to query OpenContrail&amp;rsquo;s introspection API:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ curl  -s http://10.0.100.140:8083/Snh_BgpNeighborReq?ip_address=10.0.101.15 | \
  xmllint --xpath &#39;/BgpNeighborListResp/neighbors[1]/list/BgpNeighborResp/state&#39; -
&amp;lt;state type=&amp;quot;string&amp;quot; identifier=&amp;quot;8&amp;quot;&amp;gt;Established&amp;lt;/state&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Datapath verification can be done from either side, in this case I&amp;rsquo;m showing a ping from MX80&amp;rsquo;s global VRF towards one of the OpenStack VMs:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;admin@MX80&amp;gt; ping 10.0.100.164 count 2 
PING 10.0.100.164 (10.0.100.164): 56 data bytes
64 bytes from 10.0.100.164: icmp_seq=0 ttl=64 time=3.836 ms
64 bytes from 10.0.100.164: icmp_seq=1 ttl=64 time=3.907 ms

--- 10.0.100.164 ping statistics ---
2 packets transmitted, 2 packets received, 0% packet loss
round-trip min/avg/max/stddev = 3.836/3.872/3.907/0.035 ms
&lt;/code&gt;&lt;/pre&gt;

&lt;h1 id=&#34;bgp-as-a-service-1&#34;&gt;BGP-as-a-Service&lt;/h1&gt;

&lt;p&gt;To keep things simple I will not use multiple dot1Q interfaces and setup a BGP peering with CumulusVX over a normal, non-trunk interface. From CumulusVX I will inject a loopback IP &lt;code&gt;1.1.1.1/32&lt;/code&gt; into the &lt;code&gt;irb-net&lt;/code&gt; network. Since REST API python library I&amp;rsquo;ve used above is two major releases behind the current version of OpenContrail, it cannot be used to setup BGPaaS feature. Instead I will demonstrate how to use REST API directly from the command line of all-in-one VM using cURL.&lt;/p&gt;

&lt;h2 id=&#34;configuration-1&#34;&gt;Configuration&lt;/h2&gt;

&lt;p&gt;In order to start working with OpenContrail&amp;rsquo;s API, I first need to obtain an authentication token from OpenStack&amp;rsquo;s keystone. With that token I can now query the list of IPs assigned to all OpenStack instances and pick the one assigned to CumulusVX. I need the UUID of that particular IP address in order to extract the ID of the VM interface this IP is assigned to.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;source /etc/kolla/admin-openrc.sh 
TOKEN=$(openstack token issue -f value -c id)
CONTRAIL_AUTH=&amp;quot;X-AUTH-TOKEN: $TOKEN&amp;quot;
CTYPE=&amp;quot;Content-Type: application/json; charset=UTF-8&amp;quot;
curl -H &amp;quot;$CONTRAIL_AUTH&amp;quot; http://10.0.100.140:8082/instance-ips | jq
VMI_ID=$(curl -H &amp;quot;$CONTRAIL_AUTH&amp;quot; http://10.0.100.140:8082/instance-ip/2e7987be-3f53-4296-905a-0c64793307a9 | \
         jq &#39;.[&amp;quot;instance-ip&amp;quot;] .virtual_machine_interface_refs[0].uuid&#39;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;With VM interface ID saved in a &lt;code&gt;VMI_ID&lt;/code&gt; variable I can create a BGPaaS service and link it to that particular VM interface.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;cat &amp;lt;&amp;lt; EOF &amp;gt; ./bgpaas.json
{
    &amp;quot;bgp-as-a-service&amp;quot;:
    {
        &amp;quot;fq_name&amp;quot;: [&amp;quot;default-domain&amp;quot;, &amp;quot;admin&amp;quot;, &amp;quot;cumulusVX-bgp&amp;quot; ],
        &amp;quot;autonomous_system&amp;quot;: 321,
        &amp;quot;bgpaas_session_attributes&amp;quot;: {
            &amp;quot;address_families&amp;quot;: {&amp;quot;family&amp;quot;: [&amp;quot;inet&amp;quot;] }
            },
        &amp;quot;parent_type&amp;quot;: &amp;quot;project&amp;quot;,
        &amp;quot;virtual_machine_interface_refs&amp;quot;: [{
            &amp;quot;attr&amp;quot;: null,
            &amp;quot;to&amp;quot;: [&amp;quot;default-domain&amp;quot;, &amp;quot;admin&amp;quot;, ${VMI_ID}]
            }],
        &amp;quot;bgpaas-shared&amp;quot;: false,
        &amp;quot;bgpaas-ip-address&amp;quot;: &amp;quot;10.0.100.164&amp;quot;
    }
}
EOF

curl -X POST -H &amp;quot;$CONTRAIL_AUTH&amp;quot; -H &amp;quot;$CTYPE&amp;quot; -d @bgpaas.json http://10.0.100.140:8082/bgp-as-a-services
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The final step is setting up a BGP peering on the CumulusVX side. CumulusVX configuration is very simple and self-explanatory. The BGP neighbor IP is the IP of virtual network&amp;rsquo;s default gateway located on local vRouter.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;!
interface lo
 ip address 1.1.1.1/32
!
router bgp 321
 neighbor 10.0.100.161 remote-as 64512
 !
 address-family ipv4 unicast
  network 1.1.1.1/32
 exit-address-family
!
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;verification-1&#34;&gt;Verification&lt;/h2&gt;

&lt;p&gt;Here&amp;rsquo;s where we come across another limitation of EVPN. The loopback prefix &lt;code&gt;1.1.1.1/32&lt;/code&gt; does not get injected into EVPN address family, however it does show up automatically in the VPNv4 address family which can be verified from the MX80:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;admin@MX80&amp;gt; show route table bgp.l3vpn.0 hidden 1.1.1.1/32 extensive    

bgp.l3vpn.0: 6 destinations, 6 routes (3 active, 0 holddown, 3 hidden)
10.0.100.140:2:1.1.1.1/32 (1 entry, 0 announced)
         BGP    Preference: 170/-101
                Route Distinguisher: 10.0.100.140:2
                Next hop type: Unusable, Next hop index: 0
                Next-hop reference count: 6
                State: &amp;lt;Hidden Ext ProtectionPath ProtectionCand&amp;gt;
                Local AS: 65411 Peer AS: 64512
                Age: 37:44 
                Validation State: unverified 
                Task: BGP_64512.10.0.100.140
                AS path: 64512 321 I
                Communities: target:200:200 target:64512:8000003 encapsulation:unknown(0x2) encapsulation:mpls-in-udp(0xd) unknown type 8004 value fc00:7a1201 unknown type 8071 value fc00:1389
                Import Accepted
                VPN Label: 31
                Localpref: 100
                Router ID: 10.0.100.140
                Secondary Tables: EVPN-L3-IRB.inet.0
                Indirect next hops: 1
                        Protocol next hop: 10.0.100.140
                        Label operation: Push 31
                        Label TTL action: prop-ttl
                        Load balance label: Label 31: None; 
                        Indirect next hop: 0x0 - INH Session ID: 0x0
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;It&amp;rsquo;s hidden since I haven&amp;rsquo;t configured MPLSoUDP &lt;a href=&#34;https://www.juniper.net/documentation/en_US/junos/topics/example/example-next-hop-based-dynamic-mpls-udp-tunnel-configuring.html&#34; target=&#34;_blank&#34;&gt;dynamic tunnels&lt;/a&gt; on MX80. However this proves that the prefix does get injected into customer VPNs and become available on all devices with the matching import route-target communities.&lt;/p&gt;

&lt;h1 id=&#34;outro&#34;&gt;Outro&lt;/h1&gt;

&lt;p&gt;This post concludes Series 2 of my OpenStack SDN saga. I&amp;rsquo;ve covered quite an extensive range of topics in my two-part series, however, OpenStack networking landscape is so big, it&amp;rsquo;s simply impossible to cover everything I find interesting. I started writing about OpenStack SDN when I first learned I got a job with Nokia. Back then I knew little about VMware NSX and even less about OpenStack. That&amp;rsquo;s why I started researching topics that I found interesting and branching out into adjacent areas as I went along. Almost 2 years later, looking back I can say I&amp;rsquo;ve learned a lot about the internals of SDN in general and hopefully so have my readers. Now I&amp;rsquo;m leaving Nokia to rediscover my networking roots at Arista. I&amp;rsquo;ll dive into DC networking from a different perspective now and it may be awhile before I accumulate a critical mass of interesting material to start spilling it out in my blog again. I still may come back to OpenStack some day but for now I&amp;rsquo;m gonna take a little break, maybe do some house keeping (e.g. move my blog from Jekyll to &lt;a href=&#34;https://gohugo.io/&#34; target=&#34;_blank&#34;&gt;Hugo&lt;/a&gt;, add TLS support) and enjoy my time being a farther.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>OpenStack SDN - OpenDaylight With BGP VPN</title>
      <link>https://networkop.co.uk/blog/2017/12/15/os-odl-netvirt/</link>
      <pubDate>Fri, 15 Dec 2017 00:00:00 +0000</pubDate>
      
      <guid>https://networkop.co.uk/blog/2017/12/15/os-odl-netvirt/</guid>
      <description>

&lt;p&gt;For the last 5 years OpenStack has been the training ground for a lot of emerging DC SDN solutions. OpenStack integration use case was one of the most compelling and easiest to implement thanks to the limited and suboptimal implementation of the native networking stack. Today, in 2017, features like &lt;a href=&#34;https://networkop.co.uk/blog/2016/05/06/neutron-l2pop/&#34;&gt;L2 population&lt;/a&gt;, local &lt;a href=&#34;https://networkop.co.uk/blog/2016/05/06/neutron-l2pop/&#34;&gt;ARP responder&lt;/a&gt;, &lt;a href=&#34;https://networkop.co.uk/blog/2016/05/21/neutron-l2gw/&#34;&gt;L2 gateway integration&lt;/a&gt;, &lt;a href=&#34;https://networkop.co.uk/blog/2016/10/13/os-dvr/&#34;&gt;distributed routing&lt;/a&gt; and &lt;a href=&#34;https://networkop.co.uk/blog/2017/09/15/os-sfc-skydive/&#34;&gt;service function chaining&lt;/a&gt; have all become available in vanilla OpenStack and don&amp;rsquo;t require a proprietary SDN controller anymore. Admittedly, some of the features are still not (and may never be) implemented in the most optimal way (e.g. DVR). This is where new opensource SDN controllers, the likes of &lt;a href=&#34;https://networkop.co.uk/blog/2016/12/10/ovn-part2/&#34;&gt;OVN&lt;/a&gt; and &lt;a href=&#34;https://docs.openstack.org/developer/dragonflow/distributed_dragonflow.html&#34; target=&#34;_blank&#34;&gt;Dragonflow&lt;/a&gt;, step in to provide scalable, elegant and efficient implementation of these advanced networking features. However one major feature still remains outside of the scope of a lot of these new opensource SDN projects, and that is data centre gateway (DC-GW) integration. Let me start by explain why you would need this feature in the first place.&lt;/p&gt;

&lt;h1 id=&#34;optimal-forwarding-of-north-south-traffic&#34;&gt;Optimal forwarding of North-South traffic&lt;/h1&gt;

&lt;p&gt;OpenStack Neutron and VMware NSX, both being pure software solutions, rely on a special type of node to forward traffic between VMs and hosts outside of the data centre. This node acts as a L2/L3 gateway for all North-South traffic and is often implemented as either a VM or a network namespace. This kind of solution gives software developers greater independence from the underlying networking infrastructure which makes it easier for them to innovate and introduce new features.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://networkop.co.uk/img/sdn-ns.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;However, from the traffic forwarding point of view, having a gateway/network node is not a good solution at all. There is no technological reason for a packet to have to go through this node when after all it ends up on a DC-GW anyway. In fact, this solution introduces additional complexity which needs to be properly managed (e.g. designed, configured and troubleshooted) and a potential bottleneck for high-throughput traffic flows.&lt;/p&gt;

&lt;p&gt;It&amp;rsquo;s clear that the most optimal way to forward traffic is directly from a compute node to a DC-GW. The only question is how can this optimal forwarding be achieved? SDN controller needs to be able to exchange reachability information with DC-GW using a common protocol understood by most of the existing routing stacks. One such protocol, becoming very common in DC environments, is BGP, which has two address families we can potentially use:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;VPNv4/6 will allow routes to be exchanged and the dataplance to use MPLSoGRE encapsulation. This should be considered a &amp;ldquo;legacy&amp;rdquo; approach since for a very long time DC-GWs did not have the VXLAN ecap/decap capabilities.&lt;/li&gt;
&lt;li&gt;EVPN with VXLAN-based overlays. EVPN makes it possible to exchange both L2 and L3 information under the same AF, which means we have the flexibility of doing not only a L3 WAN integration, but also a L2 data centre interconnect with just a single protocol.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;In OpenStack specifically, BGPVPN project was created to provide a pluggable driver framework for 3rd party BGP implementations. Apart from a reference BaGPipe driver (BaGPipe is an ExaBGP fork with lightweight implementation of BGP VPNs), which relies on a default &lt;code&gt;openvswitch&lt;/code&gt; ML2 mechanism driver, only Nuage, OpenDaylight and OpenContrail have contributed their drivers to this project. In this post I will focus on OpenDaylight and show how to install containerised OpenStack with OpenDaylight and integrate it with Cisco CSR using EVPN.&lt;/p&gt;

&lt;h1 id=&#34;opendaylight-integration-with-openstack&#34;&gt;OpenDaylight integration with OpenStack&lt;/h1&gt;

&lt;p&gt;Historically, OpenDaylight has had multiple projects implementing custom OpenStack networking drivers:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;VTN&lt;/strong&gt; (Virtual Tenant Networking) - spearheaded by NEC was the first project to provide OpenStack networking implementation&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;GBP&lt;/strong&gt; (Group Based Policy) - a project led by Cisco, one of the first (if not THE first) commercial implementation of Intent-based networking&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;NetVirt&lt;/strong&gt; - currently a default Neutron plugin from ODL, developed jointly by Brocade (RIP), RedHat, Ericsson, Intel and many others.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;NetVirt provides several common Neutron services including L2 and L3 forwarding, ACL and NAT, as well as advanced services like L2 gateway, QoS and SFC. To do that it assumes full control over an OVS switch inside each compute node and implements the above services inside a single &lt;code&gt;br-int&lt;/code&gt; OVS bridge. L2/L3 forwarding tables are built based on tenant IP/MAC addresses that have been allocated by Neutron and the current network topology. For high-level overview of NetVirt&amp;rsquo;s forwarding pipeline you can refer to &lt;a href=&#34;https://docs.google.com/presentation/d/15h4ZjPxblI5Pz9VWIYnzfyRcQrXYxA1uUoqJsgA53KM/edit#slide=id.g1c73ae9953_2_0&#34; target=&#34;_blank&#34;&gt;this document&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;It helps to think of an ODL-managed OpenStack as a big chassis switch. NetVirt plays the role of a supervisor by managing control plane and compiling RIB based on the information received from Neutron. Each compute node running an OVS is a linecard with VMs connected to its ports. Unlike the distributed architecture of &lt;a href=&#34;https://networkop.co.uk/blog/2016/12/10/ovn-part2/&#34;&gt;OVN&lt;/a&gt; and Dragonflow, compute nodes do not contain any control plane elements and each OVS gets its FIB programmed directly by the supervisor. DC underlay is a backplane, interconnecting all linecards and a supervisor.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://networkop.co.uk/img/odl-netvirt-chassis.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h1 id=&#34;opendaylight-bgp-vpn-service-architecture&#34;&gt;OpenDaylight BGP VPN service architecture&lt;/h1&gt;

&lt;p&gt;In order to provide BGP VPN functionality, NetVirt employs the use of three service components:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;FIB service&lt;/strong&gt; - maintains L2/L3 forwarding tables and reacts to topology changes&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;BGP manager&lt;/strong&gt; - provides a translation of information sent to and received from an external BGP stack (Quagga BGP)&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;VPN Manager&lt;/strong&gt; - ties together the above two components, creates VRFs and keeps track of RD/RT values&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;In order to exchange BGP updates with external DC-GW, NetVirt requires a BGP stack with EVPN and VPNV4/6 capabilities. Ideally, internal ODL BGP stack could have been used for that, however it didn&amp;rsquo;t meet all the performance requirements (injecting/withdrawing thousand of prefixes at the same time). Instead, an external &lt;a href=&#34;https://github.com/6WIND/quagga/tree/qthrift_mpbgp_evpn&#34; target=&#34;_blank&#34;&gt;Quagga fork&lt;/a&gt; with EVPN add-ons is connected to BGP manager via a high-speed Apache Thrift interface. This interface defines the &lt;a href=&#34;https://github.com/6WIND/quagga/blob/qthrift_mpbgp_evpn/qthriftd/vpnservice.thrift&#34; target=&#34;_blank&#34;&gt;format&lt;/a&gt; of data to be exchanged between Quagga (a.k.a QBGP) and NetVirt&amp;rsquo;s BGP Manager in order to do two things:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Configure BGP settings like ASN and BGP neighbors&lt;/li&gt;
&lt;li&gt;Read/Write RIB entries inside QBGP&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;BGP session is established between QBGP and external DC-GW, however next-hop values installed by NetVirt and advertised by QBGP have IPs of the respective compute nodes, so that traffic is sent directly via the most optimal path.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://networkop.co.uk/img/odl-netvirt.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h1 id=&#34;demo&#34;&gt;Demo&lt;/h1&gt;

&lt;p&gt;Enough of the theory, let&amp;rsquo;s have a look at how to configure a L3VPN between QBGP (advertising ODL&amp;rsquo;s distributed router subnets) and IOS-XE DC-GW using EVPN route type 5 or, more specifically, &lt;a href=&#34;https://tools.ietf.org/html/draft-ietf-bess-evpn-prefix-advertisement-09#section-4.4.1&#34; target=&#34;_blank&#34;&gt;Interface-less IP-VRF-to-IP-VRF model&lt;/a&gt;:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://networkop.co.uk/img/odl-evpn-topo.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h2 id=&#34;installation&#34;&gt;Installation&lt;/h2&gt;

&lt;p&gt;My lab environment is still based on a pair of nested VMs running containerised Kolla OpenStack I&amp;rsquo;ve described in my &lt;a href=&#34;https://networkop.co.uk/blog/2017/09/08/os-lab-docker/&#34;&gt;earlier post&lt;/a&gt;. A few months ago OpenDaylight role has been added to kolla-ansible so now it is possible to install OpenDaylight-intergrated OpenStack automatically. However, there is no option to install QBGP so I had to augment the default &lt;a href=&#34;https://github.com/openstack/kolla&#34; target=&#34;_blank&#34;&gt;Kolla&lt;/a&gt; and &lt;a href=&#34;https://github.com/openstack/kolla-ansible&#34; target=&#34;_blank&#34;&gt;Kolla-ansible&lt;/a&gt; repositories to include the QBGP &lt;a href=&#34;https://github.com/networkop/kolla-odl-bgpvpn/blob/master/roles/kolla_build/templates/quagga-Dockerfile.j2&#34; target=&#34;_blank&#34;&gt;Dockerfile template&lt;/a&gt; and QBGP &lt;a href=&#34;https://github.com/networkop/kolla-odl-bgpvpn/blob/master/roles/kolla_deploy/tasks/create.yml#L90-L120&#34; target=&#34;_blank&#34;&gt;ansible role&lt;/a&gt;. So the first step is to download my latest automated installer and make sure &lt;code&gt;enable_opendaylight&lt;/code&gt; global variable is set to &lt;code&gt;yes&lt;/code&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;git clone https://github.com/networkop/kolla-odl-bgpvpn.git &amp;amp;&amp;amp; cd kolla-odl-bgpvpn
mkdir group_vars
echo &amp;quot;enable_opendaylight: \&amp;quot;yes\&amp;quot;&amp;quot; &amp;gt;&amp;gt; group_vars/all.yaml
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;At the time of writing I was relying on a couple of latest bug fixes inside OpenDaylight, so I had to modify the default ODL role to install the latest master-branch ODL build. Make sure the link below is pointing to the latest &lt;code&gt;zip&lt;/code&gt; file in &lt;code&gt;0.8.0-SNAPSHOT&lt;/code&gt; directory.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;cat &amp;lt;&amp;lt; EOF &amp;gt;&amp;gt; group_vars/all.yaml
odl_latest_enabled: true
odl_latest_url: https://nexus.opendaylight.org/content/repositories/opendaylight.snapshot/org/opendaylight/integration/netvirt/karaf/0.8.0-SNAPSHOT/karaf-0.8.0-20171106.102232-1767.zip
EOF
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The next few steps are similar to what I&amp;rsquo;ve described in my &lt;a href=&#34;https://networkop.co.uk/blog/2017/09/08/os-lab-docker/&#34;&gt;Kolla lab post&lt;/a&gt;, will create a pair of VMs, build all Kolla containers, push them to a local Docker repo and finally deploy OpenStack using Kolla-ansible playbooks:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;./1-create.sh do
./2-bootstrap.sh do
./3-build.sh do 
./4-deploy.sh do
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The final &lt;code&gt;4-deploy.sh&lt;/code&gt; script will also create a simple &lt;code&gt;init.sh&lt;/code&gt; script inside the controller VM that can be used to setup a test topology with a single VM connected to a &lt;code&gt;10.0.0.0/24&lt;/code&gt; subnet:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;ssh kolla-controller
source /etc/kolla/admin-openrc.sh
./init.sh
&lt;/code&gt;&lt;/pre&gt;

&lt;blockquote&gt;
&lt;p&gt;Of course, another option to build a lab is to follow the official &lt;a href=&#34;https://docs.openstack.org/kolla-ansible/latest/user/quickstart.html&#34; target=&#34;_blank&#34;&gt;Kolla documentation&lt;/a&gt; to create your own custom test environment.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&#34;configuration&#34;&gt;Configuration&lt;/h2&gt;

&lt;p&gt;Assuming the test topology was setup with no issues and a test VM can ping its default gateway &lt;code&gt;10.0.0.1&lt;/code&gt;, we can start configuring BGP VPNs. Unfortunately, we won&amp;rsquo;t be able to use OpenStack BGPVPN API/CLI, since ODL requires an extra parameter (L3 VNI for symmetric IRB) which is not available in OpenStack BGPVPN API, but we still can configure everything directly through ODL&amp;rsquo;s API. My interface of choice is always REST, since it&amp;rsquo;s easier to build it into a fully programmatic plugin, so even though all of the below steps can be accomplished through karaf console CLI, I&amp;rsquo;ll be using cURL to send and retrieve data from ODL&amp;rsquo;s REST API.&lt;/p&gt;

&lt;h3 id=&#34;1-source-admin-credentials-and-setup-odl-s-rest-variables&#34;&gt;1. Source admin credentials and setup ODL&amp;rsquo;s REST variables&lt;/h3&gt;

&lt;pre&gt;&lt;code&gt;source /etc/kolla/admin-openrc.sh
export ODL_URL=&#39;http://192.168.133.100:8181/restconf&#39;
export CT_JSON=&amp;quot;Content-Type: application/json&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;2-configure-local-bgp-settings-and-bgp-peering-with-dc-gw&#34;&gt;2. Configure local BGP settings and BGP peering with DC-GW&lt;/h3&gt;

&lt;pre&gt;&lt;code&gt;cat &amp;lt;&amp;lt; EOF &amp;gt; ./bgp-full.json
{
    &amp;quot;bgp&amp;quot;: {
        &amp;quot;as-id&amp;quot;: {
            &amp;quot;announce-fbit&amp;quot;: false,
            &amp;quot;local-as&amp;quot;: 100,
            &amp;quot;router-id&amp;quot;: &amp;quot;192.168.133.100&amp;quot;,
            &amp;quot;stalepath-time&amp;quot;: 0
        },
        &amp;quot;logging&amp;quot;: {
            &amp;quot;file&amp;quot;: &amp;quot;/var/log/bgp_debug.log&amp;quot;,
            &amp;quot;level&amp;quot;: &amp;quot;errors&amp;quot;
        },
        &amp;quot;neighbors&amp;quot;: [
            {
                &amp;quot;address&amp;quot;: &amp;quot;192.168.133.50&amp;quot;,
                &amp;quot;remote-as&amp;quot;: 100,
                &amp;quot;address-families&amp;quot;: [
                   {
                     &amp;quot;ebgp:afi&amp;quot;: &amp;quot;3&amp;quot;,
                     &amp;quot;ebgp:peer-ip&amp;quot;: &amp;quot;192.168.133.50&amp;quot;,
                     &amp;quot;ebgp:safi&amp;quot;: &amp;quot;6&amp;quot;
                   }
                ]
            }
        ]
    }
}
EOF

curl -X PUT -u admin:admin -k -v -H &amp;quot;$CT_JSON&amp;quot;  \
     $ODL_URL/config/ebgp:bgp -d @bgp-full.json
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;3-define-l3vpn-instance-and-associate-it-with-openstack-admin-tenant&#34;&gt;3. Define L3VPN instance and associate it with OpenStack &lt;code&gt;admin&lt;/code&gt; tenant&lt;/h3&gt;

&lt;pre&gt;&lt;code&gt;TENANT_UUID=$(openstack project show admin -f value -c id | \
            sed &#39;s/\(........\)\(....\)\(....\)\(....\)\(.*\)/\1-\2-\3-\4-\5/&#39;)

cat &amp;lt;&amp;lt; EOF &amp;gt; ./l3vpn-full.json
{
   &amp;quot;input&amp;quot;: {
      &amp;quot;l3vpn&amp;quot;:[
         {
            &amp;quot;id&amp;quot;:&amp;quot;f503fcb0-3fd9-4dee-8c3a-5034cf707fd9&amp;quot;,
            &amp;quot;name&amp;quot;:&amp;quot;L3EVPN&amp;quot;,
            &amp;quot;route-distinguisher&amp;quot;: [&amp;quot;100:100&amp;quot;],
            &amp;quot;export-RT&amp;quot;: [&amp;quot;100:100&amp;quot;],
            &amp;quot;import-RT&amp;quot;: [&amp;quot;100:100&amp;quot;],
            &amp;quot;l3vni&amp;quot;: &amp;quot;5000&amp;quot;,
            &amp;quot;tenant-id&amp;quot;:&amp;quot;${TENANT_UUID}&amp;quot;
         }
      ]
   }
}
EOF

curl -X POST -u admin:admin -k -v -H &amp;quot;$CT_JSON&amp;quot;  \
      $ODL_URL/operations/neutronvpn:createL3VPN -d @l3vpn-full.json
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;4-inject-prefixes-into-l3vpn-by-associating-the-previously-created-l3vpn-with-a-demo-router&#34;&gt;4. Inject prefixes into L3VPN by associating the previously created L3VPN with a &lt;code&gt;demo-router&lt;/code&gt;&lt;/h3&gt;

&lt;pre&gt;&lt;code&gt;ROUTER_UUID=$(openstack router show demo-router -f value -c id)

cat &amp;lt;&amp;lt; EOF &amp;gt; ./l3vpn-assoc.json
{
  &amp;quot;input&amp;quot;:{
     &amp;quot;vpn-id&amp;quot;:&amp;quot;f503fcb0-3fd9-4dee-8c3a-5034cf707fd9&amp;quot;,
     &amp;quot;router-id&amp;quot;:[ &amp;quot;${ROUTER_UUID}&amp;quot; ]
   }
}
EOF

curl -X POST -u admin:admin -k -v -H &amp;quot;$CT_JSON&amp;quot;  \
     $ODL_URL/operations/neutronvpn:associateRouter -d @l3vpn-assoc.json
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;5-configure-dc-gw-vtep-ip&#34;&gt;5. Configure DC-GW VTEP IP&lt;/h3&gt;

&lt;p&gt;ODL cannot automatically extract VTEP IP from updates received from DC-GW, so we need to explicitly configure it:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;cat &amp;lt;&amp;lt; EOF &amp;gt; ./tep.json
{
  &amp;quot;input&amp;quot;: {
    &amp;quot;destination-ip&amp;quot;: &amp;quot;1.1.1.1&amp;quot;,
    &amp;quot;tunnel-type&amp;quot;: &amp;quot;odl-interface:tunnel-type-vxlan&amp;quot;
  }
}
EOF
curl -X POST -u admin:admin -k -v -H &amp;quot;$CT_JSON&amp;quot;  \
     $ODL_URL/operations/itm-rpc:add-external-tunnel-endpoint -d @tep.json
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;6-dc-gw-configuration&#34;&gt;6. DC-GW configuration&lt;/h3&gt;

&lt;p&gt;That is all what needs to be configured on ODL. Although I would consider this to be outside of the scope of the current post, for the sake of completeness I&amp;rsquo;m including the relevant configuration from the DC-GW:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;!
vrf definition ODL
 rd 100:100
 route-target export 100:100
 route-target import 100:100
 !        
 address-family ipv4
  route-target export 100:100 stitching
  route-target import 100:100 stitching
 exit-address-family
!
bridge-domain 5000 
 member vni 5000
!
interface Loopback0
 ip address 1.1.1.1 255.255.255.255
!
interface GigabitEthernet1
 ip address 192.168.133.50 255.255.255.0
!
interface nve1
 no ip address
 source-interface Loopback0
 host-reachability protocol bgp
 member vni 5000 vrf ODL
!
interface BDI5000
 vrf forwarding ODL
 ip address 8.8.8.8 255.255.255.0
 encapsulation dot1Q 500
!
router bgp 100
 bgp log-neighbor-changes
 no bgp default ipv4-unicast
 neighbor 192.168.133.100 remote-as 100
 !
 address-family l2vpn evpn
  import vpnv4 unicast
  neighbor 192.168.133.100 activate
 exit-address-family
 !
 address-family ipv4 vrf ODL
  advertise l2vpn evpn
  redistribute connected
 exit-address-family
!
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;For detailed explanation of how EVPN RT5 is configured on Cisco CSR refer to the &lt;a href=&#34;https://www.cisco.com/c/en/us/td/docs/ios-xml/ios/cether/configuration/xe-16/ce-xe-16-book/evpn-vxlan-l3.html&#34; target=&#34;_blank&#34;&gt;following guide&lt;/a&gt;.&lt;/p&gt;

&lt;h2 id=&#34;verification&#34;&gt;Verification&lt;/h2&gt;

&lt;p&gt;There are several things that can be checked to verify that the DC-GW integration is working. One of the first steps would be to check if BGP session with CSR is up.
This can be done from the CSR side, however it&amp;rsquo;s also possible to check this from the QBGP side. First we need to get into the QBGP&amp;rsquo;s interactive shell from the controller node:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;[centos@controller-1 ~]$ sudo docker exec -it quagga /opt/quagga/bin/vtysh
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;From here, we can check that the BGP session has been established:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;controller-1# sh bgp neighbors 192.168.133.50     
BGP neighbor is 192.168.133.50, remote AS 100, local AS 100, internal link
  BGP version 4, remote router ID 1.1.1.1
  BGP state = Established, up for 00:03:05
&amp;lt;snip&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;We can also check the contents of EVPN RIB compiled by QBGP&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;controller-1# sh bgp evpn rd 100:100
BGP table version is 0, local router ID is 192.168.133.100
Status codes: s suppressed, d damped, h history, * valid, &amp;gt; best, i - internal
Origin codes: i - IGP, e - EGP, ? - incomplete

   Network          Next Hop            Metric LocPrf Weight Path
Route Distinguisher: as2 100:100
*&amp;gt; [0][fa:16:3e:37:42:d8/48][10.0.0.2/32]
                    192.168.133.100         0          32768 i
*&amp;gt; [0][fa:16:3e:dc:77:65/48][10.0.0.3/32]
                    192.168.133.101         0          32768 i
*&amp;gt;i8.8.8.0/24       1.1.1.1         0     100       0 ?
*&amp;gt; 10.0.0.0/24      192.168.133.100         0          32768 i
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Finally, we can verify that the prefix &lt;code&gt;8.8.8.0/24&lt;/code&gt; advertised from DC-GW is being passed by QBGP and accepted by NetVirt&amp;rsquo;s FIB Manager:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ curl -u admin:admin -k -v  $ODL_URL/config/odl-fib:fibEntries/\
  vrfTables/100%3A100/vrfEntry/8.8.8.0%2F24 | python -m json.tool
{
    &amp;quot;vrfEntry&amp;quot;: [
        {
            &amp;quot;destPrefix&amp;quot;: &amp;quot;8.8.8.0/24&amp;quot;,
            &amp;quot;encap-type&amp;quot;: &amp;quot;vxlan&amp;quot;,
            &amp;quot;gateway_mac_address&amp;quot;: &amp;quot;00:1e:49:69:24:bf&amp;quot;,
            &amp;quot;l3vni&amp;quot;: 5000,
            &amp;quot;origin&amp;quot;: &amp;quot;b&amp;quot;,
            &amp;quot;route-paths&amp;quot;: [
                {
                    &amp;quot;nexthop-address&amp;quot;: &amp;quot;1.1.1.1&amp;quot;
                }
            ]
        }
    ]
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The last output confirms that the prefix is being received and accepted by ODL. To do a similar check on CSR side we can run the following command:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;CSR1k#show bgp l2vpn evpn 
&amp;lt;snip&amp;gt;
     Network          Next Hop            Metric LocPrf Weight Path
Route Distinguisher: 100:100 (default for vrf ODL)
 *&amp;gt;i  [2][100:100][0][48][FA163E3742D8][32][10.0.0.2]/24
                      192.168.133.100          0    100      0 i
 *&amp;gt;i  [2][100:100][0][48][FA163EDC7765][32][10.0.0.3]/24
                      192.168.133.101          0    100      0 i
 *&amp;gt;   [5][100:100][0][24][8.8.8.0]/17
                      0.0.0.0                  0         32768 ?
 *&amp;gt;i  [5][100:100][0][24][10.0.0.0]/17
                      192.168.133.100          0    100      0 i
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This confirms that the control plane information has been successfully exchanged between NetVirt and Cisco CSR.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;At the time of writing, there was an &lt;a href=&#34;https://git.opendaylight.org/gerrit/#/c/63324/&#34; target=&#34;_blank&#34;&gt;open bug&lt;/a&gt; in ODL master branch that prevented the forwarding entries from being installed in OVS datapath. Once the bug is fixed I will update this post with the dataplance verification, a.k.a ping&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h1 id=&#34;conclusion&#34;&gt;Conclusion&lt;/h1&gt;

&lt;p&gt;OpenDaylight is a pretty advanced OpenStack SDN platform. Its functionality includes clustering, site-to-site federation (without EVPN) and L2/L3 EVPN DC-GW integration for both IPv4 and IPv6. It is yet another example of how an open-source platform can match even the most advanced proprietary SDN solutions from incumbent vendors. This is all thanks to the companies involved in OpenDaylight development. I also want to say special thanks to Vyshakh Krishnan, Kiran N Upadhyaya and Dayavanti Gopal Kamath from Ericsson for helping me clear up some of the questions I posted on netvirt-dev mailing list.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>OpenStack SDN - NFV Management and Orchestration</title>
      <link>https://networkop.co.uk/blog/2017/11/23/os-nfv-mano/</link>
      <pubDate>Thu, 23 Nov 2017 00:00:00 +0000</pubDate>
      
      <guid>https://networkop.co.uk/blog/2017/11/23/os-nfv-mano/</guid>
      <description>

&lt;p&gt;In the ongoing hysteria surrounding all things SDN, one important thing gets often overlooked. You don&amp;rsquo;t build SDN for its own sake. SDN is just a little cog in a big machine called &amp;ldquo;cloud&amp;rdquo;. To take it even further, I would argue that the best SDN solution is the one that you don&amp;rsquo;t know even exists. Despite what the big vendors tell you, operators are not supposed to interact with SDN interface, be it GUI or CLI. If you dig up some of the earliest presentation about Cisco ACI, when the people talking about it were the actual people who designed the product, you&amp;rsquo;ll notice one common motif being repeated over and over again. That is that ACI was never designed for direct human interaction, but rather was supposed to be configured by a higher level orchestrating system. In data center environments such orchestrating system may glue together services of virtualization layer and SDN layer to provide a seamless &amp;ldquo;cloud&amp;rdquo; experience to the end users. The focus of this post will be one incarnation of such orchestration system, specific to SP/Telco world, commonly known as NFV MANO.&lt;/p&gt;

&lt;hr /&gt;

&lt;h1 id=&#34;nfv-mano-for-telco-sdn&#34;&gt;NFV MANO for Telco SDN&lt;/h1&gt;

&lt;p&gt;At the early dawn of SDN/NFV era a lot of people got very excited by &lt;strong&gt;&amp;ldquo;the promise&amp;rdquo;&lt;/strong&gt; and started applying the disaggregation and virtualization paradigms to all areas of networking. For Telcos that meant virtualizing network functions that built the service core of their networks - EPC, IMS, RAN. Traditionally those network functions were a collection of vertically-integrated baremetal appliances that took a long time to commission and had to be overprovisioned to cope with the peak-hour demand. Virtualizing them would have made it possible to achieve quicker time-to-market, elasticity to cope with a changing network demand and hardware/software disaggregation.&lt;/p&gt;

&lt;p&gt;As expected however, such fundamental change has to come at price. Not only do Telcos get a new virtualization platform to manage but they also need to worry about lifecycle management and end-to-end orchestration (MANO) of VNFs. Since any such change presents an opportunity for new streams of revenue, it didn&amp;rsquo;t take long for vendors to jump on the bandwagon and start working on a new architecture designed to address those issues.&lt;/p&gt;

&lt;p&gt;The first problem was the easiest to solve since VMware and OpenStack already existed at that stage and could be used to host VNFs with very little modifications. The management and orchestration problem, however, was only partially solved by existing orchestration solutions. There were a lot of gaps between the current operational model and the new VNF world and although these problems could have been solved by Telcos engaging themselves with the open-source community, this proved to be too big of a change for them and they&amp;rsquo;ve turned to the only thing they could trust - the standards bodies.&lt;/p&gt;

&lt;h1 id=&#34;etsi-mano&#34;&gt;ETSI MANO&lt;/h1&gt;

&lt;p&gt;ETSI NFV MANO working group has set out to define a reference architecture for management and orchestration of virtualized resources in Telco data centers. The goal of NFV MANO initiative was to do a research into what&amp;rsquo;s required to manage and orchestrate VNFs, what&amp;rsquo;s currently available and identify potential gaps for other standards bodies to fill. Initial ETSI NFV Release 1 (2014) defined a base framework through relatively weak requirements and recommendations and was followed by Release 2 (2016) that made them more concrete by locking down the interfaces and data model specifications. For a very long time Release 1 was the only available NFV MANO standard, which led to a lot of inconsistencies in each vendors&amp;rsquo; implementations of it. This was very frustrating for Telcos since it required a lot of integration effort to build a multi-vendor MANO stack. Another potential issue with ETSI MANO standard is its limited scope - a lot of critical components like OSS and EMS are left outside of it which created a lot of confusion for Telcos and resulted in other standardisation efforts addressing those gaps.&lt;/p&gt;

&lt;p&gt;On the below diagram I have shown an adbridged version of the original ETSI MANO &lt;a href=&#34;https://www.ietf.org/proceedings/88/slides/slides-88-opsawg-6.pdf&#34; target=&#34;_blank&#34;&gt;reference architecture diagram&lt;/a&gt; adapted to the use case I&amp;rsquo;ll be demonstrating in this post.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://networkop.co.uk/img/etsi-mano.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;This architecture consists of the following building blocks:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;NFVI&lt;/strong&gt; (NFV Infrastructure) - OpenStacks compute or VMware&amp;rsquo;s ESXI nodes&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;VIM&lt;/strong&gt; (Virtual Infrastructure Manager) - OpenStack&amp;rsquo;s controller/API or VMware&amp;rsquo;s vCenter nodes&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;VNFM&lt;/strong&gt; (VNF Manager) - an element responsible for lifecycle management (create,delete,scale) and monitoring of VNFs&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;NFVO&lt;/strong&gt; (NFV Orchestrator) - an element responsible for lifecyle management of Network Services (described below)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;All these elements are working together towards a single goal - managing and orchestrating a Network Service (NS), which itself is comprised of multiple VNFs, Virtual Links (VLs), VNF Forwarding Graphs (VNFFGs) and Physical Network Functions (PNFs). In this post I create a NS for a simple virtual IDS use case, described in my previous &lt;a href=&#34;https://networkop.co.uk/blog/2017/09/15/os-sfc-skydive/&#34;&gt;SFC post&lt;/a&gt;. The goal is to steer all ICMP traffic coming from VM1 through a vIDS VNF which will forward the traffic to its original destination.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://networkop.co.uk/img/vids-created.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Before I get to the implementation, let me give a quick overview of how a Network Service is build from its constituent parts, in the context of our vIDS use case.&lt;/p&gt;

&lt;h1 id=&#34;relationship-between-ns-vnf-and-vnffg&#34;&gt;Relationship between NS, VNF and VNFFG&lt;/h1&gt;

&lt;p&gt;According to ETSI MANO, a &lt;strong&gt;Network Service&lt;/strong&gt; (NS) is a subset of end-to-end service implemented by VNFs and instantiated on the NFVI. As I&amp;rsquo;ve mentioned before, some examples of a NS would be vEPC, vIMS or vCPE. NS can be described in either a YANG or a Tosca template called NS Descriptor (NSD). The main goal of a NSD is to tie together VNFs, VLs, VNFFGs and PNFs by defining relationship between various templates describing those objects (VNFDs, VLDs, VNFFGDs). Once NSD is onboarded (uploaded), it can be instantiated by NFVO, which communicates with VIM and VNFM to create the constituent components and stitch them together as described in a template. NSD normally does not contain VNFD or VNFFGD templates, but imports them through their names, which means that in order to instantiate a NSD, the corresponding VNFDs and VNFFGDs should already be onboarded.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://networkop.co.uk/img/vids-nsd.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;VNF Descriptor&lt;/strong&gt; is a template describing the compute and network parameters of a single VNF. Each VNF consists of one or more VNF components (VNFCs), represented in Tosca as Virtual Deployment Units (VDUs). A VDU is the smallest part of a VNF and can be implemented as either a container or, as it is in our case, a VM. Apart from the usual set of parameters like CPU, RAM and disk, VNFD also describes all the virtual networks required for internal communication between VNFCs, called internal VLs. VNFM can ask VIM to create those networks when the VNF is being instantiated. VNFD also contains a reference to external networks, which are supposed to be created by NFVO. Those networks are used to connect different VNFs together or to connect VNFs to PNFs and other elements outside of NFVI platform. If external VLs are defined in a VNFD, VNFM will need to source them externally, either as input parameters to VNFM or from NFVO. In fact, VNF instantiation by VNFM, as described in Tacker &lt;a href=&#34;https://docs.openstack.org/tacker/latest/user/vnfm_usage_guide.html&#34; target=&#34;_blank&#34;&gt;documentation&lt;/a&gt;, is only used for testing purposes and since a VNF only makes sense as a part of a Network Service, the intended way is to use a NSD to instantiate all VNFs in production environment.&lt;/p&gt;

&lt;p&gt;The final component that we&amp;rsquo;re going to use is VNF Forwarding Graph. &lt;strong&gt;VNFFG Descriptor&lt;/strong&gt; is an optional component that describes how different VNFs are supposed to be chained together to form a Network Service. In the absence of VNFFG, VNFs will fall back to the default destination-based forwarding, when the IPs of VNFs forming a NS are either automatically discovered (e.g. through DNS) or provisioned statically. Tacker&amp;rsquo;s implementation of VNFFG is not fully integrated with NSD yet and VNFFGD has to be instantiated separately and, as will be shown below, linked to an already running instance of a Network Service through its ID.&lt;/p&gt;

&lt;h1 id=&#34;using-tacker-to-orchestrate-a-network-service&#34;&gt;Using Tacker to orchestrate a Network Service&lt;/h1&gt;

&lt;p&gt;Tacker is an OpenStack project implementing a generic VNFM and NFVO. At the input it consumes Tosca-based templates, converts them to Heat templates which are then used to spin up VMs on OpenStack. This diagram from Brocade, the biggest Tacker contributor (at least until its acquisition), is the best overview of internal Tacker architecture.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://networkop.co.uk/img/brocade-tacker.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;For this demo environment I&amp;rsquo;ll keep using my OpenStack Kolla lab environment described in my &lt;a href=&#34;https://networkop.co.uk/blog/2017/09/08/os-lab-docker/&#34;&gt;previous post&lt;/a&gt;.&lt;/p&gt;

&lt;h2 id=&#34;step-1-vim-registration&#34;&gt;Step 1 - VIM registration&lt;/h2&gt;

&lt;p&gt;Before we can start using Tacker, it needs to know how to reach the OpenStack environment, so the first step in the workflow is OpenStack or VIM registration. We need to provide the address of the keystone endpoint along with the admin credentials to give Tacker enough rights to create and delete VMs and SFC objects:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;cat &amp;lt;&amp;lt; EOF &amp;gt; ./vim.yaml
auth_url: &#39;http://192.168.133.254:35357/v3&#39;
username: &#39;admin&#39;
password: &#39;admin&#39;
project_name: &#39;admin&#39;
project_domain_name: &#39;Default&#39;
user_domain_name: &#39;Default&#39;
EOF

tacker vim-register --is-default --config-file vim.yaml --description MYVIM KOLLA-OPENSTACK
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The successful result can be checked with &lt;code&gt;tacker vim-list&lt;/code&gt; which should report that registered VIM is now reachable.&lt;/p&gt;

&lt;h2 id=&#34;step-2-onboarding-a-vnfd&#34;&gt;Step 2 - Onboarding a VNFD&lt;/h2&gt;

&lt;p&gt;VNFD defines a set of VMs (VNFCs), network ports (CPs) and networks (VLs) and their relationship. In our case we have a single cirros-based VM with a pair of ingress/egress ports. In this template we also define a special node type &lt;code&gt;tosca.nodes.nfv.vIDS&lt;/code&gt; which will be used by NSD to pass the required parameters for ingress and egress VLs. These parameters are going to be used by VNFD to attach network ports (CPs) to virtual networks (VLs) as defined in the &lt;code&gt;substitution_mappings&lt;/code&gt; section.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;cat &amp;lt;&amp;lt; EOF &amp;gt; ./vnfd.yaml
tosca_definitions_version: tosca_simple_profile_for_nfv_1_0_0
description = Cirros vIDS example

node_types:
  tosca.nodes.nfv.vIDS:
    requirements:
      - INGRESS_VL:
          type: tosca.nodes.nfv.VL
          required: true
      - EGRESS_VL:
          type: tosca.nodes.nfv.VL
          required: true

topology_template:
  substitution_mappings:
    node_type: tosca.nodes.nfv.vIDS
    requirements:
      INGRESS_VL: [CP1, virtualLink]
      EGRESS_VL:  [CP2, virtualLink]

  node_templates:
    VDU1:
      type: tosca.nodes.nfv.VDU.Tacker
      properties:
        availability_zone: nova
        flavor: m1.nano
        image: cirros
        mgmt_driver: noop
        user_data_format: RAW
        user_data: |
          #!/bin/sh
          sudo cirros-dhcpc up eth1
          sudo ip rule add iif eth0 table default
          sudo ip route add default via 10.0.0.1 dev eth1 table default
          sudo sysctl -w net.ipv4.ip_forward=1

    CP1:
      type: tosca.nodes.nfv.CP.Tacker
      properties:
        anti_spoofing_protection: false
      requirements:
        - virtualBinding:
            node: VDU1

    CP2:
      type: tosca.nodes.nfv.CP.Tacker
      properties:
        anti_spoofing_protection: false
      requirements:
        - virtualBinding:
            node: VDU1
EOF

tacker vnfd-create --vnfd-file vnfd.yaml vIDS-TEMPLATE
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;step-4-onboarding-a-nsd&#34;&gt;Step 4 - Onboarding a NSD&lt;/h2&gt;

&lt;p&gt;In our use case the NSD template is going to really small. All what we need to define is a single VNF of the &lt;code&gt;tosca.nodes.nfv.vIDS&lt;/code&gt; type that was defined previously in the VNFD. We also define a VL node which points to the pre-existing &lt;code&gt;demo-net&lt;/code&gt; virtual network and pass this VL to both INGRESS_VL and EGRESS_VL parameters of the VNFD.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;cat &amp;lt;&amp;lt; EOF &amp;gt; ./nsd.yaml
tosca_definitions_version: tosca_simple_profile_for_nfv_1_0_0
imports:
  - vIDS-TEMPLATE

topology_template:
  node_templates:
    vIDS:
      type: tosca.nodes.nfv.vIDS
      requirements:
        - INGRESS_VL: VL1
        - EGRESS_VL: VL1
    VL1:
      type: tosca.nodes.nfv.VL
      properties:
          network_name: demo-net
          vendor: tacker
EOF

tacker nsd-create --nsd-file nsd.yaml NSD-vIDS-TEMPLATE
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;step-5-instantiating-a-nsd&#34;&gt;Step 5 - Instantiating a NSD&lt;/h2&gt;

&lt;p&gt;As I&amp;rsquo;ve mentioned before, VNFFG is not integrated with NSD yet, so we&amp;rsquo;ll add it later. For now, we have provided enough information to instantiate our NSD.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;tacker ns-create --nsd-name NSD-vIDS-TEMPLATE NS-vIDS-1
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This last command creates a cirros-based VM with two interfaces and connects them to &lt;code&gt;demo-net&lt;/code&gt; virtual network. All ICMP traffic from VM1 still goes directly to its default gateway so the last thing we need to do is create a VNFFG.&lt;/p&gt;

&lt;h2 id=&#34;step-6-onboarding-and-instantiating-a-vnffg&#34;&gt;Step 6 - Onboarding and Instantiating a VNFFG&lt;/h2&gt;

&lt;p&gt;VNFFG consists of two two types of nodes. The first type defines a Forwarding Path (FP) as a set of virtual ports (CPs) and a flow classifier to build an equivalent service function chain inside the VIM. The second type groups multiple forwarding paths to build a complex service chain graphs, however only one FP is supported by Tacker at the time of writing.&lt;/p&gt;

&lt;p&gt;The following template demonstrates another important feature - template parametrization. Instead of defining all parameters statically in a template, they can be provided as inputs during instantiation, which allows to keep templates generic. In this case I&amp;rsquo;ve replaced the network port id parameter with &lt;code&gt;PORT_ID&lt;/code&gt; variable which will be provided during VNFFGD instantiation.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;cat &amp;lt;&amp;lt; EOF &amp;gt; ./vnffg.yaml
tosca_definitions_version: tosca_simple_profile_for_nfv_1_0_0

description = vIDS VNFFG tosca

topology_template:
  inputs:
    PORT_ID:
      type: string
description = Port ID of the target VM

  node_templates:

    Forwarding_Path-1:
      type: tosca.nodes.nfv.FP.Tacker
description = creates path (CP1-&amp;gt;CP2)
      properties:
        id: 51
        policy:
          type: ACL
          criteria:
            - network_src_port_id: { get_input: PORT_ID }
            - ip_proto: 1
        path:
          - forwarder: vIDS-TEMPLATE
            capability: CP1
          - forwarder: vIDS-TEMPLATE
            capability: CP2


  groups:
    VNFFG1:
      type: tosca.groups.nfv.VNFFG
description = Set of Forwarding Paths
      properties:
        vendor: tacker
        version: 1.0
        number_of_endpoints: 1
        dependent_virtual_link: [VL1]
        connection_point: [CP1]
        constituent_vnfs: [vIDS-TEMPLATE]
      members: [Forwarding_Path-1]
EOF

tacker vnffgd-create --vnffgd-file vnffgd.yaml VNFFG-TEMPLATE
&lt;/code&gt;&lt;/pre&gt;

&lt;blockquote&gt;
&lt;p&gt;Note that the VNFFGD has been updated to support multiple flow classifiers which means you many need to update the above template as per the &lt;a href=&#34;https://github.com/openstack/tacker/blob/master/samples/tosca-templates/vnffgd/tosca-vnffgd-multiple-classifiers-sample.yaml&#34; target=&#34;_blank&#34;&gt;sample VNFFGD template&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;In order to instantiate a VNFFGD we need to provide two runtime parameters:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;OpenStack port ID of VM1 for forwarding path flow classifier&lt;/li&gt;
&lt;li&gt;ID of the VNF created by the Network Service&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;All these parameters can be obtained using the CLI commands as shown below:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;CLIENT_IP=$(openstack server list | grep VM1 | grep -Eo &#39;[0-9]+\.[0-9]+\.[0-9]+\.[0-9]+&#39;)
PORT_ID=$(openstack port list | grep $CLIENT_IP | awk &#39;{print $2}&#39;)
echo &amp;quot;PORT_ID: $PORT_ID&amp;quot; &amp;gt; params-vnffg.yaml
vIDS_ID=$(tacker ns-show NS-vIDS-1 -f value -c vnf_ids | sed &amp;quot;s/&#39;/\&amp;quot;/g&amp;quot; | jq &#39;.vIDS&#39; | sed &amp;quot;s/\&amp;quot;//g&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The following command creates a VNFFG and an equivalent SFC to steer all ICMP traffic from VM1 through vIDS VNF. The result can be verified using Skydive following the procedure described in my &lt;a href=&#34;https://networkop.co.uk/blog/2017/09/15/os-sfc-skydive/&#34;&gt;previous post&lt;/a&gt;.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;tacker vnffg-create --vnffgd-name VNFFG-TEMPLATE \
                    --vnf-mapping vIDS-TEMPLATE:$vIDS_ID \
                    --param-file params-vnffg.yaml VNFFG-1
&lt;/code&gt;&lt;/pre&gt;

&lt;h1 id=&#34;other-tacker-features&#34;&gt;Other Tacker features&lt;/h1&gt;

&lt;p&gt;This post only scratches the surface of what&amp;rsquo;s available in Tacker with a lot of other salient features left out of scope, including:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;VNF monitoring - through monitoring driver its possible to do VNF monitoring from VNFM using various methods ranging from a single ICMP/HTTP ping to Alarm-based monitoring using OpenStack&amp;rsquo;s &lt;a href=&#34;https://wiki.openstack.org/wiki/Telemetry&#34; target=&#34;_blank&#34;&gt;Telemetry framework&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Enhanced Placement Awareness - VNFD Tosca template extensions that allow the definition of required performance features like NUMA topology mapping, SR-IOV and CPU pinning.&lt;/li&gt;
&lt;li&gt;Mistral workflows - ability to drive Tacker workflows through Mistral&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&#34;conclusion&#34;&gt;Conclusion&lt;/h1&gt;

&lt;p&gt;Tacker is one of &lt;a href=&#34;https://thenewstack.io/opensource-nfv-part-4-opensource-mano/&#34; target=&#34;_blank&#34;&gt;many&lt;/a&gt; NFV orchestration platforms in a very competitive environment. Other &lt;a href=&#34;https://www.mirantis.com/blog/which-nfv-orchestration-platform-best-review-osm-open-o-cord-cloudify/&#34; target=&#34;_blank&#34;&gt;open-source initiatives&lt;/a&gt; have been created in response to the shortcomings of the original ETSI Release 1 reference architecture. The fact the some of the biggest Telcos have finally realised that the only way to achieve the goal of NFV orchestration is to get involved with open-source and do it themselves, may be a good sign for the industry and maybe not so good for the ETSI NFV MANO working group. Whether ONAP with its broader scope becomes a new de-facto standard for NFV orchestration, still remains to be seen, until then ETSI MANO remains the only viable standard for NFV lifecycle management and orchestration.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>OpenStack SDN - Skydiving Into Service Function Chaining</title>
      <link>https://networkop.co.uk/blog/2017/09/15/os-sfc-skydive/</link>
      <pubDate>Fri, 15 Sep 2017 00:00:00 +0000</pubDate>
      
      <guid>https://networkop.co.uk/blog/2017/09/15/os-sfc-skydive/</guid>
      <description>

&lt;p&gt;&lt;a href=&#34;abbr:Service Function Chaining&#34; target=&#34;_blank&#34;&gt;SFC&lt;/a&gt; is another SDN feature that for a long time only used to be available in proprietary SDN solutions and that has recently become available in vanilla OpenStack. It serves as another proof that proprietary SDN solutions are losing the competitive edge, especially for Telco SDN/NFV use cases. Hopefully, by the end of this series of posts I&amp;rsquo;ll manage do demonstrate how to build a complete open-source solution that has feature parity (in terms of major networking features) with all the major proprietary data centre SDN platforms. But for now, let&amp;rsquo;s just focus on SFC.&lt;/p&gt;

&lt;h1 id=&#34;sfc-high-level-overview&#34;&gt;SFC High-level overview&lt;/h1&gt;

&lt;p&gt;In most general terms, SFC refers to packet forwarding technique that uses more than just destination IP address to decide how to forward packets. In more specific terms, SFC refers to &amp;ldquo;steering&amp;rdquo; of traffic through a specific set of endpoints (a.k.a Service Functions), overriding the default destination-based forwarding. For those coming from a traditional networking background, think of SFC as a set of policy-based routing instances orchestrated from a central element (SDN controller). Typical use cases for SFC would be things like firewalling, IDS/IPS, proxying, NAT&amp;rsquo;ing, monitoring.&lt;/p&gt;

&lt;p&gt;SFC is usually modelled as a directed (acyclic) graph, where the first and the last elements are the source and destination respectively and each vertex inside the graph represents a SF to be chained. IETF RFC7665 defines the reference architecture for SFC implementations and establishes some of the basic terminology. A simplified SFC architecture consists of the following main components:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Classifier - a network element that matches and redirects traffic flows to a chain&lt;/li&gt;
&lt;li&gt;Service Function - an element responsible for packet processing&lt;/li&gt;
&lt;li&gt;Service Function Forwarder - a network element that forwards traffic to and from a directly connected SF&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&#34;https://networkop.co.uk/img/sfc-overview.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;One important property of a SF is elasticity. More instances of the same type can be added to a pool of SF and SFF will load-balance the traffic between them. This is the reason why, as we&amp;rsquo;ll see in the next section, SFF treats connections to a SF as a group of ports rather than just a single port.&lt;/p&gt;

&lt;h1 id=&#34;insertion-modes-and-implementation-models&#34;&gt;Insertion modes and implementation models&lt;/h1&gt;

&lt;p&gt;In legacy, pre-SDN environments SFs had no idea if they were a part of a service chain and network devices (routers and switches) had to &amp;ldquo;insert&amp;rdquo; the interesting traffic into the service function using one of the following two modes:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;L2 mode&lt;/strong&gt; is when SF is physically inserted between the source and destination inside a single broadcast domain, so traffic flows through a SF without any intervention from a switch. Example of this mode could be a firewall in transparent mode, physically connected between a switch and a default gateway router. All packets entering a SF have their original source and destination MAC addresses, which requires SF to be in promiscuous mode.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;strong&gt;L3 mode&lt;/strong&gt; is when a router overrides its default destination-based forwarding and redirects the interesting traffic to a SF. In legacy networks this could have been achieved with PBR or WCCP. In this case SF needs to be L2-attached to a router and all redirected packets have their destination MAC updated to that of a SF&amp;rsquo;s ingress interface.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Modern SDN networks make it really easy to modify forwarding behaviour of network elements, both physical and virtual. There is no need for policy-based routing or bump-in-the-wire designs anymore. When flow needs to be redirected to a SF on a virtual switch, all what&amp;rsquo;s required is a matching OpenFlow entry with a high enough priority. However redirecting traffic to a SF is just one part of the problem. Another part is how to make SFs smarter, to provide greater visibility of end-to-end service function path.&lt;/p&gt;

&lt;p&gt;So far SFs have only been able to extract metadata from the packet itself. This limited the flexibility of SF logic and became computationally expensive in case many SFs need to access some L7 header information. Ideal way would be to have an additional header which can be used to read and write arbitrary information and pass it along the service function chain. RFC7665 defines requirements for &amp;ldquo;SFC Encapsulation&amp;rdquo; header which can be used to uniquely identify an instance of a chain as well as share metadata between all its elements. Neutron API refers to SFC encapsulation as &lt;em&gt;correlation&lt;/em&gt; since its primary function is to identify a particular service function path. There are two implementations of SFC encapsulation in use today:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;MPLS&lt;/strong&gt; - used by current OVS agent driver (as of Pike). This method does not provide any means to share metadata and serves only for SFP identification. It is intended as an interim solution until NSH becomes available upstream in OVS.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;NSH&lt;/strong&gt; - complete implementation of SFC encapsulation defined in RFC7665. This method is currently implemented in Opendaylight where NSH is used as a shim between VXLAN-GPE and the encapsulated packet&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;It should be noted that the new approach with SFC encapsulation still allows for legacy, non-SFC-aware SFs to be chained. In this case SFC encapsulation is stripped off the packet by an &amp;ldquo;SFC proxy&amp;rdquo; before the packet is sent to the ingress port of a service function. All logical elements forming an SFC forwarding pipeline, including SFC proxy, Classifier and Forwarder, are implemented inside the same OVS bridges (br-int and br-tun) used by vanilla OVS-agent driver.&lt;/p&gt;

&lt;h1 id=&#34;configuring-neutron-sfc&#34;&gt;Configuring Neutron SFC&lt;/h1&gt;

&lt;p&gt;We&amp;rsquo;ll pick up where we left off in the &lt;a href=&#34;https://networkop.co.uk/blog/2017/09/08/os-lab-docker/&#34;&gt;previous post&lt;/a&gt;. All Neutron and ML2 configuration files have already been updated thanks to the &lt;code&gt;enable_sfc=&amp;quot;yes&amp;quot;&lt;/code&gt; setting in the global Kolla-Ansible configuration file. If not, you can change it in &lt;code&gt;/etc/kolla/globals.yaml&lt;/code&gt; and re-run kolla-ansible deployment script.&lt;/p&gt;

&lt;p&gt;First, let&amp;rsquo;s generate OpenStack credentials using a post-deployment script. We later can use a default bootstrap script to downloads the cirros image and set up some basic networking and security rules.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;kolla-ansible post-deploy
source /etc/kolla/admin-openrc.sh
/usr/share/kolla-ansible/init-runonce
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The goal for this post is to create a simple uni-directional SFC to steer the ICMP requests from VM1 to its default gateway through another VM that will be playing the role of a firewall.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://networkop.co.uk/img/sfc-example.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;The network was already created by the bootstrap script so all what we have to do is create a test VM. I&amp;rsquo;m creating a port in a separate step simply so that I can refer to it by name instead of UUID.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;openstack port create --network demo-net P0
openstack server create --image cirros --flavor m1.tiny --port P0 VM1
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;I&amp;rsquo;ll go over all the necessary steps to setup SFC, but will only provide a brief explanation. Refer to the official OpenStack &lt;a href=&#34;https://docs.openstack.org/newton/networking-guide/config-sfc.html&#34; target=&#34;_blank&#34;&gt;Networking Guide&lt;/a&gt; for a complete SFC configuration guide.&lt;/p&gt;

&lt;p&gt;First, let&amp;rsquo;s create a FW VM with two ports - P1 and P2.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;openstack port create --network demo-net P1
openstack port create --network demo-net P2
openstack server create --image cirros --flavor m1.tiny --port P1 --port P2 FW
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Next, we need create an ingress/egress port pair and assign it to a port pair group. The default setting for &lt;strong&gt;correlation&lt;/strong&gt; in a port pair (not shown) is &lt;code&gt;none&lt;/code&gt;. That means that SFC encapsulation header (MPLS) will get stripped before the packet is sent to P1.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;openstack sfc port pair create --ingress P1 --egress P2 PPAIR
openstack sfc port pair group create --port-pair PPAIR PPGROUP
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Port pair group also allows to specify the L2-L4 headers which to use for load-balancing in OpenFlow groups, overriding the default behaviour described in the next section.&lt;/p&gt;

&lt;p&gt;Another required element is a flow classifier. We will be redirecting ICMP traffic coming from VM1&amp;rsquo;s port P0&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;openstack sfc flow classifier create --protocol icmp --logical-source-port P0 FLOW-ICMP
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Finally, we can tie together flow classifier with a previously created port pair group. The default setting for &lt;strong&gt;correlation&lt;/strong&gt; (not shown again) in this case is &lt;code&gt;mpls&lt;/code&gt;. That means that each chain will have its own unique MPLS label to be used as an SFC encapsulation.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;openstack sfc port chain create --port-pair-group PPGROUP --flow-classifier FLOW-ICMP PCHAIN
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;That&amp;rsquo;s all the configuration needed to setup SFC. However if you login VM1&amp;rsquo;s console and try pinging default gateway, it will fail. Next, I&amp;rsquo;m going to give a quick demo of how to use a real-time network analyzer tool called Skydive to troubleshoot this issue.&lt;/p&gt;

&lt;h1 id=&#34;using-skydive-to-troubleshoot-sfc&#34;&gt;Using Skydive to troubleshoot SFC&lt;/h1&gt;

&lt;p&gt;&lt;a href=&#34;https://skydive-project.github.io/skydive/&#34; target=&#34;_blank&#34;&gt;Skydive&lt;/a&gt; is a new open-source distributed network probing and traffic analyzing tool. It consists of a set of agents running on compute nodes, collecting topology and flow information and forwarding it to a central element for analysis.&lt;/p&gt;

&lt;p&gt;The idea of using Skydive to analyze and track SFC is not new. In fact, for anyone interested in this topic I highly recommend the &lt;a href=&#34;http://blog.cafarelli.fr/2017/02/tracking-service-function-chaining-with-skydive/&#34; target=&#34;_blank&#34;&gt;following blogpost&lt;/a&gt;. In my case I&amp;rsquo;ll show how to use Skydive from a more practical perspective - troubleshooting multiple SFC issues.&lt;/p&gt;

&lt;p&gt;Skydive CLI client is available inside the &lt;code&gt;skydive_analyzer&lt;/code&gt; container. We need to start an interactive bash session inside this container and set some environment variables:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;docker exec -it skydive_analyzer bash
export SKYDIVE_ANALYZERS=192.168.133.100:8085
export SKYDIVE_USERNAME=admin
export SKYDIVE_PASSWORD=admin
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The first thing we can do to troubleshoot is see if ICMP traffic is entering the &lt;code&gt;ingress&lt;/code&gt; port of the FW VM. Based on the output of &lt;code&gt;openstack port list&lt;/code&gt; command I know that P1 has got an IP of &lt;code&gt;10.0.0.8&lt;/code&gt;. Let&amp;rsquo;s if we can identify a tap port corresponding to P1:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;skydive client topology query --gremlin &amp;quot;G.V().Has(&#39;Neutron.IPs&#39;, &#39;10.0.0.8&#39;, &#39;Type&#39;, &#39;tun&#39;).Values(&#39;Neutron&#39;)&amp;quot;
{
  &amp;quot;IPs&amp;quot;: &amp;quot;10.0.0.8&amp;quot;,
  &amp;quot;NetworkID&amp;quot;: &amp;quot;8eabb451-b026-417c-b54b-8e79ee6e71c3&amp;quot;,
  &amp;quot;NetworkName&amp;quot;: &amp;quot;demo-net&amp;quot;,
  &amp;quot;PortID&amp;quot;: &amp;quot;e6334df9-a5c4-4e86-a5f3-671760c2bbbe&amp;quot;,
  &amp;quot;TenantID&amp;quot;: &amp;quot;bd5829e0cb5b40b68ab4f8e7dc68b14d&amp;quot;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The output above proves that skydive agent has successfully read the configuration of the port and we can start a capture on that object to see any packets arriving on P1.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;skydive client capture create --gremlin &amp;quot;G.V().Has(&#39;Neutron.IPs&#39;, &#39;10.0.0.8&#39;, &#39;Type&#39;, &#39;tun&#39;)&amp;quot;
skydive client topology query --gremlin &amp;quot;G.V().Has(&#39;Neutron.IPs&#39;, &#39;10.0.0.8&#39;, &#39;Type&#39;, &#39;tun&#39;).Flows().Has(&#39;Application&#39;,&#39;ICMPv4&#39;).Values(&#39;Metric.ABPackets&#39;)&amp;quot;
[
  7
]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;If you &lt;code&gt;watch&lt;/code&gt; the last command for several seconds you should see that the number in brackets is increasing. That means that packets are hitting the ingress port of the FW VM. Now let&amp;rsquo;s repeat the same test on &lt;code&gt;egress&lt;/code&gt; port P2.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;skydive client capture create --gremlin &amp;quot;G.V().Has(&#39;Neutron.IPs&#39;, &#39;10.0.0.4&#39;, &#39;Type&#39;, &#39;tun&#39;)&amp;quot;
skydive client topology query --gremlin &amp;quot;G.V().Has(&#39;Neutron.IPs&#39;, &#39;10.0.0.4&#39;, &#39;Type&#39;, &#39;tun&#39;).Flows()&amp;quot;
[]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The output above tells us that there are no packets coming out of the FW VM. This is expected since we haven&amp;rsquo;t done any changes to the blank cirros image to make it forward the packets between the two interfaces. If we examine the IP configuration of the FW VM, we would see that it doesn&amp;rsquo;t have an IP address configured on the second interface. We would also need to create a source-based routing policy to force all traffic from VM1 (&lt;code&gt;10.0.0.6&lt;/code&gt;) to egress via interface &lt;code&gt;eth2&lt;/code&gt; and make sure IP forwarding is turned on. The following commands would need to be executed on FW VM:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;sudo cirros-dhcpc up eth1
sudo ip rule add from 10.0.0.6 table default
sudo ip route add default via 10.0.0.1 dev eth1 table default
sudo sysctl -w net.ipv4.ip_forward=1
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Having done that, we should see some packets coming out of &lt;code&gt;egress&lt;/code&gt; port P2.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;skydive client topology query --gremlin &amp;quot;G.V().Has(&#39;Neutron.IPs&#39;, &#39;10.0.0.4&#39;, &#39;Type&#39;, &#39;tun&#39;).Flows().Has(&#39;Application&#39;,&#39;ICMPv4&#39;).Values(&#39;Metric.ABPackets&#39;)&amp;quot;
[
  7
]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;However form the VM1&amp;rsquo;s perspective the ping is still failing. Next step would be to see if the packets are hitting the integration bridge that port P2 is attached to:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;skydive client capture create --gremlin &amp;quot;G.V().Has(&#39;Neutron.IPs&#39;, &#39;10.0.0.4&#39;, &#39;Type&#39;, &#39;veth&#39;)&amp;quot;
skydive client topology query --gremlin &amp;quot;G.V().Has(&#39;Neutron.IPs&#39;, &#39;10.0.0.4&#39;, &#39;Type&#39;, &#39;veth&#39;).Flows()&amp;quot;
[]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;No packets means they are getting dropped somewhere between the P2 and the integration bridge. This can only be done by security groups. In fact, source MAC/IP anti-spoofing is enabled by default which would only allow packets matching the source MAC/IP addresses assigned to P2 and would drop any packets coming from VM1&amp;rsquo;s IP address. The easiest fix would be to disable security groups for P2 completely:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;openstack port set --no-security-group --disable-port-security P2
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;After this step the counters should start incrementing and the ping from VM1 to its default gateway is resumed.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;skydive client topology query --gremlin &amp;quot;G.V().Has(&#39;Neutron.IPs&#39;, &#39;10.0.0.4&#39;, &#39;Type&#39;, &#39;veth&#39;).Flows().Has(&#39;Application&#39;,&#39;ICMPv4&#39;).Values(&#39;Metric.ABPackets&#39;)&amp;quot;
[
  79
]
&lt;/code&gt;&lt;/pre&gt;

&lt;h1 id=&#34;sfc-implementation-in-ovs-forwarding-pipeline&#34;&gt;SFC implementation in OVS forwarding pipeline&lt;/h1&gt;

&lt;p&gt;The only element being affected in our case (both VM1 and FW are on the same compute node) is the integration bridge. Refer to my &lt;a href=&#34;http://networkop.co.uk/blog/2016/04/22/neutron-native/&#34; target=&#34;_blank&#34;&gt;older post&lt;/a&gt; about vanilla OpenStack networking for a refresher of the vanilla OVS-agent architecture.&lt;/p&gt;

&lt;p&gt;Normally, I would start by collecting all port and flow details from the integration bridge with the following commands:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;ovs-ofctl dump-ports-desc br-int  | grep addr
ovs-ofctl dump-flows br-int | cut -d &#39;,&#39; -f3-
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;However, for the sake of brevity, I will omit the actual outputs and only show graphical representation of forwarding tables and packet flows. The tables below have two columns - first showing what is being matched and second showing the resulting action. Let&amp;rsquo;s start with the OpenFlow rules in an integration bridge before SFC is configured:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://networkop.co.uk/img/sfc-before-tables.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;As we can see, the table structure is quite simple, since integration bridge mostly relies on data-plane MAC learning. A couple of MAC and ARP anti-spoofing tables will check the validity of a packet and send it to table 60 where &lt;code&gt;NORMAL&lt;/code&gt; action will trigger the &amp;ldquo;flood-and-learn&amp;rdquo; behaviour. Therefore, an ICMP packet coming from VM1 will take the following path:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://networkop.co.uk/img/sfc-before-packet.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;After we&amp;rsquo;ve configured SFC, the forwarding pipeline is changed and now looks like this:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://networkop.co.uk/img/sfc-after-tables.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;First, we can see that table 0 acts as a classifier, by redirecting the &amp;ldquo;interesting&amp;rdquo; packets towards &lt;code&gt;group 1&lt;/code&gt;. This groups is an &lt;a href=&#34;https://floodlight.atlassian.net/wiki/spaces/floodlightcontroller/pages/7995427/How+to+Work+with+Fast-Failover+OpenFlow+Groups&#34; target=&#34;_blank&#34;&gt;OpenFlow Group&lt;/a&gt; of type &lt;code&gt;select&lt;/code&gt;, which load-balances traffic between multiple destinations. By default OVS will use a combination of L2-L4 header as described &lt;a href=&#34;http://docs.openvswitch.org/en/latest/faq/openflow/&#34; target=&#34;_blank&#34;&gt;here&lt;/a&gt; to calculate a hash which determines the output bucket, similar to how per-flow load-balancing works in traditional routers and switches. This behaviour can be overridden with a specific set of headers in &lt;code&gt;lb_fields&lt;/code&gt; setting of a port pair group.&lt;/p&gt;

&lt;p&gt;In our case we&amp;rsquo;ve only got a single SF, so the packet gets its destination MAC updated to that of SF&amp;rsquo;s ingress port and is forwarded to a new table 5. Table 5 is where all packets destined for a SF are aggregated with a single MPLS label which uniquely identifies the service function path. The packet is then forwarded to table 10, which I&amp;rsquo;ve called &lt;code&gt;SFC Ingress&lt;/code&gt;. This is where the packets are distributed to SF&amp;rsquo;s ingress ports based on the assigned MPLS label.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://networkop.co.uk/img/sfc-after-packet.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;After being processed by a SF, the packet leaves the &lt;code&gt;egress&lt;/code&gt; port and re-enters the integration bridge. This time table 0 knows that the packet has already been processed by a SF and, since the anti-spoofing rules have been disabled, simply floods the packet out of all ports in the same VLAN. The packet gets flooded to the tunnel bridge where it gets replicated and delivered to the &lt;code&gt;qrouter&lt;/code&gt; sitting on the controller node as per the &lt;a href=&#34;http://networkop.co.uk/blog/2016/04/22/neutron-native/&#34; target=&#34;_blank&#34;&gt;default behaviour&lt;/a&gt;.&lt;/p&gt;

&lt;h1 id=&#34;upcoming-enhancements&#34;&gt;Upcoming enhancements&lt;/h1&gt;

&lt;p&gt;SFC is a pretty vast topic and is still under active development. Some of the upcoming enhancement to the current implementation of SFC will include:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;NSH&lt;/strong&gt; header for SFC correlation&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;TAP&lt;/strong&gt; functionality which can replace the separate Tap-as-a-service OpenStack project&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Service graphs&lt;/strong&gt; allowing multiple chains to be interconnected to create more complex service chain scenarios&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&#34;coming-up&#34;&gt;Coming Up&lt;/h1&gt;

&lt;p&gt;SFC is one of the major features in Telco SDN and, like many things, it&amp;rsquo;s not meant to be configured manually. In fact, Telco SDN have their own framework for management and orchestration of VNFs (a.k.a. VMs) and VNF forwarding graphs (a.k.a. SFCs) called ETSI MANO. As it is expected from a Telco standard, it abounds with acronyms and confuses the hell out of anyone who&amp;rsquo;s name is not on the list of authors or contributors. That&amp;rsquo;s why in the next post I will try to provide a brief overview of what Telco SDN is and use Tacker, a software implementation of NFVO and VNFM, to automatically build a firewall VNF and provision a SFC, similar to what has been done in this post manually.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>OpenStack SDN - Building a Containerized OpenStack Lab</title>
      <link>https://networkop.co.uk/blog/2017/09/08/os-lab-docker/</link>
      <pubDate>Fri, 08 Sep 2017 00:00:00 +0000</pubDate>
      
      <guid>https://networkop.co.uk/blog/2017/09/08/os-lab-docker/</guid>
      <description>

&lt;p&gt;For quite a long time installation and deployment have been deemed as major barriers for OpenStack adoption. The classic &amp;ldquo;install everything manually&amp;rdquo; approach could only work in small production or lab environments and the ever increasing number of project under the &lt;a href=&#34;https://governance.openstack.org/tc/reference/projects/&#34; target=&#34;_blank&#34;&gt;&amp;ldquo;Big Tent&amp;rdquo;&lt;/a&gt; made service-by-service installation infeasible. This led to the rise of automated installers that over time evolved from a simple collection of scripts to container management systems.&lt;/p&gt;

&lt;h1 id=&#34;evolution-of-automated-openstack-installers&#34;&gt;Evolution of automated OpenStack installers&lt;/h1&gt;

&lt;p&gt;The first generation of automated installers were simple utilities that tied together a collection of Puppet/Chef/Ansible scripts. Some of these tools could do baremetal server provisioning through Cobbler or Ironic (Fuel, Compass) and some relied on server operating system to be pre-installed (Devstack, Packstack). In either case the packages were pulled from the Internet or local repository every time the installer ran.&lt;/p&gt;

&lt;p&gt;The biggest problem with the above approach is the time it takes to re-deploy, upgrade or scale the existing environment. Even for relatively small environments it could be hours before all packages are downloaded, installed and configured. One of the ways to tackle this is to pre-build an operating system with all the necessary packages and only use Puppet/Chef/Ansible to change configuration files and turn services on and off. Redhat&amp;rsquo;s TripleO is one example of this approach. It uses a &amp;ldquo;golden image&amp;rdquo; with pre-installed OpenStack packages, which is dd-written bit-by-bit onto the baremetal server&amp;rsquo;s disk. The undercloud then decides which services to turn on based on the overcloud server&amp;rsquo;s role.&lt;/p&gt;

&lt;p&gt;Another big problem with most of the existing deployment methods was that, despite their microservices architecture, all OpenStack services were deployed as static packages on top of a shared operating system. This made the ongoing operations, troubleshooting and ugprades really difficult. The obvious thing to do would be to have all OpenStack services (e.g. Neutron, Keyston, Nova) deployed as containers and managed by a container management system. The first company to implement that, as far as I know, was Canonical. The deployment process is quite complicated, however the end result is a highly flexible OpenStack cloud deployed using LXC containers, managed and orchestrated by Juju controller.&lt;/p&gt;

&lt;p&gt;Today (September 2017) deploying OpenStack services as containers is becoming mainstream and in this post I&amp;rsquo;ll show how to use Kolla to build container images and Kolla-Ansible to deploy them on a pair of &amp;ldquo;baremetal&amp;rdquo; VMs.&lt;/p&gt;

&lt;h1 id=&#34;lab-overview&#34;&gt;Lab overview&lt;/h1&gt;

&lt;p&gt;My lab consists of a single controller and a single compute VM. The goal was to make them as small as possible so they could run on a laptop with limited resources. Both VMs are connected to three VM bridged networks - provisioning, management and external VM access.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://networkop.co.uk/img/kolla-lab.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;I&amp;rsquo;ve written some bash and Ansible scripts to automate the deployment of VMs on top of any Fedora derivative (e.g. Centos7). These scripts should be run directly from the hypervisor:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;git clone https://github.com/networkop/kolla-odl-bgpvpn.git &amp;amp;&amp;amp; cd kolla-odl-bgpvpn
./1-create.sh do
./2-bootstrap.sh do
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The first bash script downloads the VM OS (Centos7), creates two blank VMs and sets up a local Docker registry. The second script installs all the dependencies, including Docker and Ansible.&lt;/p&gt;

&lt;h1 id=&#34;building-openstack-docker-containers-with-kolla&#34;&gt;Building OpenStack docker containers with Kolla&lt;/h1&gt;

&lt;p&gt;The first step in Kolla deployment workflow is deciding where to get the Docker images. Kolla maintains a &lt;a href=&#34;https://hub.docker.com/u/kolla/&#34; target=&#34;_blank&#34;&gt;Docker Hub registry&lt;/a&gt; with container images built for every major OpenStack release. The easiest way to get them would be to pull the images from Docker hub either directly or via a &lt;a href=&#34;https://docs.docker.com/registry/recipes/mirror/&#34; target=&#34;_blank&#34;&gt;pull-through caching registry&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;In my case I needed to build the latest version of OpenStack packages, not just the latest major release. I also wanted to build a few additional, non-OpenStack images (Opendaylight and Quagga). Because of that I had to build all Docker images locally and push them into a local docker registry. The procedure to build container images is very well documented in the official &lt;a href=&#34;https://docs.openstack.org/kolla/latest/image-building.html&#34; target=&#34;_blank&#34;&gt;Kolla image building guide&lt;/a&gt;. I&amp;rsquo;ve modified it slightly to include the Quagga Dockerfile and automated it so that the whole process can be run with a single command:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;./3-build.sh do
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This step can take quite a long time (anything from 1 to 4 hours depending on the network and disk I/O speed), however, once it&amp;rsquo;s been done these container images can be used to deploy as many OpenStack instances as necessary.&lt;/p&gt;

&lt;h1 id=&#34;deploying-openstack-with-kolla-ansible&#34;&gt;Deploying OpenStack with Kolla-Ansible&lt;/h1&gt;

&lt;p&gt;The next step in OpenStack deployment workflow is to deploy Docker images on target hosts. &lt;a href=&#34;https://docs.openstack.org/kolla-ansible/latest/quickstart.html&#34; target=&#34;_blank&#34;&gt;Kolla-Ansible&lt;/a&gt; is a highly customizable OpenStack deployment tool that is also extemely easy to use, at least for people familiar with Ansible. There are two main sources of information for Kolla-Ansible:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Global configuration file (/etc/kolla/globals.yaml), which contains some of the most common customization options&lt;/li&gt;
&lt;li&gt;Ansible inventory file (/usr/share/kolla-ansible/ansible/inventory/*), which maps OpenStack packages to target deployment hosts&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;To get started with Kolla-Ansible all what it takes is a few modifications to the global configuration file to make sure that network settings match the underlying OS interface configuration and an update to the inventory file to point it to the correct deployment hosts. In my case I&amp;rsquo;m making additional changes to enable SFC, Skydive and Tacker and adding files for Quagga container, all of which can be done with the following command:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;./4-deploy.sh do
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The best thing about this method of deployment is that it takes (in my case) under 5 minutes to get the full OpenStack cloud from scratch. That means if I break something or want to redeploy with some major changes (add/remove Opendaylight), all what I have to do is destroy the existing deployment (approx. 1 minute), modify global configuration file and re-deploy OpenStack. This makes Kolla-Ansible an ideal choice for my lab environment.&lt;/p&gt;

&lt;h1 id=&#34;overview-of-containerized-openstack&#34;&gt;Overview of containerized OpenStack&lt;/h1&gt;

&lt;p&gt;Once the deployment has been completed, we should be able to see a number of running Docker containers - one for each OpenStack process.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;root@compute-1# docker ps
CONTAINER ID        IMAGE                                                                 COMMAND             CREATED             STATUS              PORTS               NAMES
0bb8a8eeb1a9        172.26.0.1:5000/kolla/centos-source-skydive-agent:5.0.0               &amp;quot;kolla_start&amp;quot;       3 days ago          Up 3 days                               skydive_agent
63b5b643dfae        172.26.0.1:5000/kolla/centos-source-neutron-openvswitch-agent:5.0.0   &amp;quot;kolla_start&amp;quot;       3 days ago          Up 3 days                               neutron_openvswitch_agent
f6f74c5982cb        172.26.0.1:5000/kolla/centos-source-openvswitch-vswitchd:5.0.0        &amp;quot;kolla_start&amp;quot;       3 days ago          Up 3 days                               openvswitch_vswitchd
3078421a3892        172.26.0.1:5000/kolla/centos-source-openvswitch-db-server:5.0.0       &amp;quot;kolla_start&amp;quot;       3 days ago          Up 3 days                               openvswitch_db
9146c16d561b        172.26.0.1:5000/kolla/centos-source-nova-compute:5.0.0                &amp;quot;kolla_start&amp;quot;       3 days ago          Up 3 days                               nova_compute
8079f840627f        172.26.0.1:5000/kolla/centos-source-nova-libvirt:5.0.0                &amp;quot;kolla_start&amp;quot;       3 days ago          Up 3 days                               nova_libvirt
220d617d31a5        172.26.0.1:5000/kolla/centos-source-nova-ssh:5.0.0                    &amp;quot;kolla_start&amp;quot;       3 days ago          Up 3 days                               nova_ssh
743ce602d485        172.26.0.1:5000/kolla/centos-source-cron:5.0.0                        &amp;quot;kolla_start&amp;quot;       3 days ago          Up 3 days                               cron
8b71f08d2781        172.26.0.1:5000/kolla/centos-source-kolla-toolbox:5.0.0               &amp;quot;kolla_start&amp;quot;       3 days ago          Up 3 days                               kolla_toolbox
f76d0a7fcf2a        172.26.0.1:5000/kolla/centos-source-fluentd:5.0.0                     &amp;quot;kolla_start&amp;quot;       3 days ago          Up 3 days                               fluentd
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;All the standard docker tools are available to interact with those containers. For example, this is how we can see what processes are running inside a container:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;root@compute-1# docker exec nova_compute ps -www aux
USER       PID %CPU %MEM    VSZ   RSS TTY      STAT START   TIME COMMAND
nova         1  0.0  0.0    188     4 pts/3    Ss+  Sep04   0:00 /usr/local/bin/dumb-init /bin/bash /usr/local/bin/kolla_start
nova         7  0.7  1.3 2292560 134896 ?      Ssl  Sep04  35:33 /var/lib/kolla/venv/bin/python /var/lib/kolla/venv/bin/nova-compute
root        86  0.0  0.3 179816 32900 ?        S    Sep05   0:00 /var/lib/kolla/venv/bin/python /var/lib/kolla/venv/bin/privsep-helper --config-file /etc/nova/nova.conf --privsep_context vif_plug_ovs.privsep.vif_plug --privsep_sock_path /tmp/tmpFvP0GS/privsep.sock
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Some of you may have noticed that none of the containers expose any ports. So how do they communicate? The answer is very simple - all containers run in a &lt;strong&gt;host&lt;/strong&gt; networking mode, effectively disabling any network isolation and giving all contaners access to TCP/IP stacks of their Docker hosts. This is a simple way to avoid having to deal with Docker networking complexities, while at the same time preserving the immutability and portability of Docker containers.&lt;/p&gt;

&lt;p&gt;All containers are configured to restart in case of a failure, however there&amp;rsquo;s no &lt;a href=&#34;abbr:Container Management System&#34; target=&#34;_blank&#34;&gt;CMS&lt;/a&gt; to provide full lifecycle management and advanced scheduling. If upgrade of scale-in/out is needed, Kolla-Ansible will have to be re-run with updated configuration options. There is sibling project called &lt;a href=&#34;https://github.com/openstack/kolla-kubernetes&#34; target=&#34;_blank&#34;&gt;Kolla-Kubernetes&lt;/a&gt; (still under developement), that&amp;rsquo;s designed to address some of the mentioned shortcomings.&lt;/p&gt;

&lt;h1 id=&#34;coming-up&#34;&gt;Coming up&lt;/h1&gt;

&lt;p&gt;Now that the lab is up we can start exploring the new OpenStack SDN features. In the next post I&amp;rsquo;ll have a close look at Neutron&amp;rsquo;s &lt;a href=&#34;abbr: Service Function Chainng&#34; target=&#34;_blank&#34;&gt;SFC&lt;/a&gt; feature, how to configure it and how it&amp;rsquo;s been implemented in OVS forwarding pipeline.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Linux SSH Session Management for Network Engineers</title>
      <link>https://networkop.co.uk/blog/2017/05/12/linux-ssh/</link>
      <pubDate>Fri, 12 May 2017 00:00:00 +0000</pubDate>
      
      <guid>https://networkop.co.uk/blog/2017/05/12/linux-ssh/</guid>
      <description>

&lt;p&gt;A few weeks ago I bought myself a new Dell XPS-13 and decided for the n-th time to go all-in Linux, that is to have Linux as the main and only laptop OS. Since most of my Linux experience is with Fedora-family distros, I quickly installed Fedora-25 and embarked on a long and painful journey of getting out of my Windows comfort zone and re-establishing it in Linux. One of the most important aspects for me, as a network engineer, is to have a streamlined process of accessing network devices. In Windows I was using MTPutty and it helped define my expectations of an ideal SSH session manager:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;I want a multi-tab terminal with the ability to switch between tabs quickly - default (GNOME) terminal does that out-of-the box with no extra modifications&lt;/li&gt;
&lt;li&gt;I want to login the device without having to enter a password - Not available by default but is possible with some dirty &lt;code&gt;expect&lt;/code&gt; hacks.&lt;/li&gt;
&lt;li&gt;I want my SSH sessions to be organised in a hierarchical manner with groups representing various administrative domains - customer A, local VMs, lab.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Although GNOME terminal looked like a very good option, it didn&amp;rsquo;t meet all of my requirements. I briefly looked and PAC Manager and GNOME Connection Manager but quickly dismissed them due to their ugliness and clunkiness. Ideally I wanted to keep using GNOME terminal as the main terminal emulator, without having to configure and rely on other 3rd party apps. I also didn&amp;rsquo;t want to wrap my SSH session in &lt;code&gt;expect&lt;/code&gt; as I didn&amp;rsquo;t want my password to be pasted in my screen every time I &lt;em&gt;cat&lt;/em&gt; a file containing the trigger keyword &lt;em&gt;Password:&lt;/em&gt;. I&amp;rsquo;ve finally managed to make everything work inside the native GNOME terminal and this post is a documentation of my approach.&lt;/p&gt;

&lt;h1 id=&#34;1-install-ssh-copy-net&#34;&gt;1. Install ssh-copy-net&lt;/h1&gt;

&lt;p&gt;I&amp;rsquo;ve written a little &lt;a href=&#34;https://github.com/networkop/ssh-copy-net&#34; target=&#34;_blank&#34;&gt;tool&lt;/a&gt; that uses &lt;a href=&#34;https://github.com/ktbyers/netmiko&#34; target=&#34;_blank&#34;&gt;Netmiko&lt;/a&gt; to install (and remove) public SSH keys onto network devices. Assuming &lt;code&gt;python-pip&lt;/code&gt; is already installed here&amp;rsquo;s what&amp;rsquo;s required to download and install &lt;code&gt;ssh-copy-net&lt;/code&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ pip install git+https://github.com/networkop/ssh-copy-net.git
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Its functionality mimics the one of &lt;code&gt;ssh-copy-id&lt;/code&gt;, so the next step is always to upload the public key to the device:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ ssh-copy-net 10.6.142.1 juniper
Username: admin
Password:
All Done!
&lt;/code&gt;&lt;/pre&gt;

&lt;h1 id=&#34;2-define-ssh-config-for-network-devices&#34;&gt;2. Define SSH config for network devices&lt;/h1&gt;

&lt;p&gt;OpenSSH client &lt;a href=&#34;https://linux.die.net/man/5/ssh_config&#34; target=&#34;_blank&#34;&gt;config file&lt;/a&gt; provides a nice way of managing user&amp;rsquo;s SSH sessions. Configuration file allows you to define per-host SSH settings including username, port forwarding options, key checking flags etc. In my case all what I had to do was define IP addresses of my network devices:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Host srx
  HostName 10.6.142.1

Host arista
  HostName 10.6.142.2
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Now I am able to login the device by simply typing its name:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ ssh arista
Last login: Sun May  7 10:57:30 2017 from 10.1.2.3
arista-1&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;h1 id=&#34;3-define-zsh-aliases&#34;&gt;3. Define zsh aliases&lt;/h1&gt;

&lt;p&gt;The final step is session organisations. For that I&amp;rsquo;ve decided to use zsh aliases and have device groups encoded in the alias name, separated by dashes. For example, if my SRX device was in the &lt;strong&gt;lab&lt;/strong&gt; and Arista was in &lt;strong&gt;Site-51&lt;/strong&gt; of &lt;strong&gt;Customer-A&lt;/strong&gt; this is how I would write my aliases:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;alias lab-srx=&#39;ssh srx&#39;
alias customer-a-site-51-arista=&#39;ssh arista&#39;
&lt;/code&gt;&lt;/pre&gt;

&lt;h1 id=&#34;4-multi-pane-sessions-with-tmux&#34;&gt;4. Multi-pane sessions with tmux&lt;/h1&gt;

&lt;p&gt;As a network engineer, I often find myself troubleshooting issues spanning multiple devices, which is why I need multiple tabs inside a single terminal window. Simply pressing Ctrl+T in GNOME terminal opens a new tab and I can switch between tabs using Alt+[1-9]. However what would be really nice is to have a couple of tabs opened side by side so that I can see the logs and compare output on a number of devices at the same time. This is where tmux comes in. It can do much more than this, but I simply use it to have multiple panes inside the same terminal tab:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://networkop.co.uk/img/tmux.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Here&amp;rsquo;s an example of my tmux configuration file:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;# Automatically set window title
set-window-option -g automatic-rename on
set-option -g set-titles on

# Use Alt-arrow keys without prefix key to switch panes
bind -n M-Left select-pane -L
bind -n M-Right select-pane -R
bind -n M-Up select-pane -U
bind -n M-Down select-pane -D

# Pane splitting keys
bind-key v split-window -h
bind-key s split-window -v

# New key-binding to reset hung SSH sessions
bind-key k respawn-pane -k

# Easy fix for arrow keys inside ssh
set -g default-terminal &amp;quot;xterm&amp;quot;

# Enable mouse mode (tmux 2.1 and above)
set -g mouse on

# Reload tmux config
bind r source-file ~/.tmux.conf

# No delay for escape key press
set -sg escape-time 0
&lt;/code&gt;&lt;/pre&gt;

&lt;h1 id=&#34;demo&#34;&gt;Demo&lt;/h1&gt;

&lt;p&gt;Now having all the above defined and with the help of zsh command autocompletion, I can login the device with just a few keypresses (shown in square brackets below):&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ lab  [TAB]
$ lab-  [TAB]
lab-srx
$ lab-  [s][TAB]
$ lab-srx  [ENTER]
--- JUNOS 12.3X48-D30.7 built 2016-04-28 22:37:34 UTC
{primary:node0}
null@srx&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Press Ctrl+B v to split the terminal window vertically:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ customer [TAB]
$ customer- [TAB]
customer-a-site-51-arista
$ customer- [a][TAB]
$ customer-a-arista [ENTER]
Last login: Thu May 11 15:28:03 2017 from 10.1.2.3
arista-1&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;An so on and so forth&amp;hellip;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://networkop.co.uk/img/tmux.gif&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Using YANG Models in Ansible to Configure and Verify State of IOS-XE and JUNOS Devices</title>
      <link>https://networkop.co.uk/blog/2017/04/04/ansible-yang/</link>
      <pubDate>Tue, 04 Apr 2017 00:00:00 +0000</pubDate>
      
      <guid>https://networkop.co.uk/blog/2017/04/04/ansible-yang/</guid>
      <description>

&lt;p&gt;The idea of using Ansible for &lt;a href=&#34;http://networkop.co.uk/blog/2015/08/26/automating-network-build-p1/&#34; target=&#34;_blank&#34;&gt;configuration changes&lt;/a&gt; and &lt;a href=&#34;https://github.com/networktocode/ntc-ansible&#34; target=&#34;_blank&#34;&gt;state verification&lt;/a&gt; is not new. However the approach I&amp;rsquo;m going to demonstrate in this post, using YANG and NETCONF, will have a few notable differences:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;I will not use any templates and absolutely no XML/JSON for device config generation&lt;/li&gt;
&lt;li&gt;All changes will be pushed through a single, vendor and model-independent Ansible module&lt;/li&gt;
&lt;li&gt;State verification will be done with no pattern-matching or screen-scraping&lt;/li&gt;
&lt;li&gt;All configuration and operational state will be based on a couple of YAML files&lt;/li&gt;
&lt;li&gt;To demonstrate the model-agnostic behaviour I will use a mixture of vendor&amp;rsquo;s native, IETF and OpenConfig YANG models&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;I hope this promise is exciting enough so without further ado, let&amp;rsquo;s get cracking.&lt;/p&gt;

&lt;h1 id=&#34;environment-setup&#34;&gt;Environment setup&lt;/h1&gt;

&lt;p&gt;The test environment will consist of a single instance of CSR1000v running IOS-XE version 16.4.1 and a single instance of vMX running JUNOS version 17.1R1.8. The VMs containing the two devices are deployed within a single hypervisor and connected with one interface to the management network and back-to-back with the second  pair of interfaces for BGP peering.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://networkop.co.uk/img/ansible-yang.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Each device contains some basic initial configuration to allow it be reachable from the Ansible server.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;interface GigabitEthernet1
ip address 192.168.145.51 255.255.255.0
!
netconf-yang
netconf-yang cisco-odm polling enable
netconf-yang cisco-odm actions parse Interfaces
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;vMX configuration is quite similar. Static MAC address is &lt;a href=&#34;http://noshut.ru/2015/09/how-to-run-juniper-vmx-in-unetlab/&#34; target=&#34;_blank&#34;&gt;required&lt;/a&gt; in order for &lt;code&gt;ge&lt;/code&gt; interfaces to work.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;set system login user admin class super password admin123
set system services netconf
set interface fxp0 unit 0 family inet address 192.168.145.53/24
set interface ge-0/0/0 mac 00:0c:29:fc:1a:b7
&lt;/code&gt;&lt;/pre&gt;

&lt;h1 id=&#34;ansible-playbook-configuration&#34;&gt;Ansible playbook configuration&lt;/h1&gt;

&lt;p&gt;My &lt;a href=&#34;https://github.com/networkop/yang/tree/master/ansible-101&#34; target=&#34;_blank&#34;&gt;Ansible-101&lt;/a&gt; repository contains two plays - one for configuration and one for state verification. The local inventory file contains details about the two devices along with the login credentials. All the work will be performed by a custom Ansible module stored in the &lt;code&gt;./library&lt;/code&gt; directory. This module is a wrapper for a &lt;code&gt;ydk_yaml&lt;/code&gt; module described in my &lt;a href=&#34;https://networkop.co.uk/blog/2017/03/13/yaml-yang/&#34;&gt;previous post&lt;/a&gt;. I had to heavily modify the original &lt;code&gt;ydk_yaml&lt;/code&gt; module to work around some Ansible limitations, like the lack of support for &lt;strong&gt;set&lt;/strong&gt; data structures.&lt;br /&gt;
This custom Ansible module also relies on a number of &lt;a href=&#34;https://networkop.co.uk/blog/2017/02/22/odl-ydk/&#34;&gt;YDK&lt;/a&gt; Python bindings to be pre-installed. Refer to my &lt;a href=&#34;https://github.com/networkop/yang/tree/master/yaml-101&#34; target=&#34;_blank&#34;&gt;YAML&lt;/a&gt;, &lt;a href=&#34;https://github.com/networkop/yang/tree/master/oper-101&#34; target=&#34;_blank&#34;&gt;Operational&lt;/a&gt; and &lt;a href=&#34;https://github.com/networkop/yang/tree/master/junos-101&#34; target=&#34;_blank&#34;&gt;JUNOS&lt;/a&gt; repositories for the instructions on how to install those modules.&lt;br /&gt;
The desired configuration and expected operational state are documented inside a couple of device-specific host variable files. For each device there is a configuration file &lt;code&gt;config.yaml&lt;/code&gt;, describing the desired configuration state. For IOS-XE there is an additional file &lt;code&gt;verify.yaml&lt;/code&gt;, describing the expected operational state using the IETF interface YANG model (I couldn&amp;rsquo;t find how to get the IETF or OpenConfig state models to work on Juniper).&lt;br /&gt;
All of these files follow the same structure:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Root container can be either &lt;code&gt;config&lt;/code&gt; or &lt;code&gt;verify&lt;/code&gt; and defines how the enclosed data is supposed to be used&lt;/li&gt;
&lt;li&gt;First nested container has to match the top-most container of a YANG model. For example it could be &lt;strong&gt;bgp-state&lt;/strong&gt; for &lt;a href=&#34;https://github.com/YangModels/yang/blob/master/vendor/cisco/xe/1641/cisco-bgp-state.yang&#34; target=&#34;_blank&#34;&gt;cisco-bgp-state.yang&lt;/a&gt; or &lt;strong&gt;openconfig-bgp&lt;/strong&gt; for &lt;a href=&#34;https://github.com/openconfig/public/blob/master/release/models/bgp/openconfig-bgp.yang&#34; target=&#34;_blank&#34;&gt;openconfig-bgp.yang&lt;/a&gt; model&lt;/li&gt;
&lt;li&gt;The remaining nested data has to follow the structure of the original YANG model as described in my &lt;a href=&#34;https://networkop.co.uk/blog/2017/03/13/yaml-yang/&#34;&gt;previous post&lt;/a&gt;.&lt;br /&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Here&amp;rsquo;s how IOS-XE will be configured, using IETF interfaca YANG models (to unshut the interface) and Cisco&amp;rsquo;s native YANG model for interface IP and BGP settings:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-yaml&#34;&gt;---
config:
  interfaces:
    interface:
      - name: GigabitEthernet3
        enabled: true
  native:
    interface:
      gigabitethernet:
        - name: &#39;3&#39;
          description: P2P link
          ip:
            address:
              primary:
                address: 12.12.12.1
                mask: 255.255.255.0
      loopback:
        - name: 0
          description: ROUTER ID
          ip:
            address:
              primary:
                address: 1.1.1.1
                mask: 255.255.255.255
    router:
      bgp:
        - id: 65111
          bgp:
            router_id: 1.1.1.1
          neighbor:
            - id: 12.12.12.2
              remote_as: 65222
          redistribute:
            connected:
              empty: empty
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;For JUNOS configuration, instead of the default humongous native model, I&amp;rsquo;ll use a set of much more light-weight OpenConfig YANG models to configure interfaces, BGP and redistribution policies:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-yaml&#34;&gt;---
config:
  openconfig-interfaces:
    interface:
      - name: ge-0/0/0
        subinterfaces:
          subinterface:
            - index: 0
              ipv4:
                addresses:
                  address:
                    - ip: 12.12.12.2/24
                      config:
                        ip: 12.12.2.2
                        prefix_length: 24
      - name: lo0
        subinterfaces:
          subinterface:
            - index: 0
              ipv4:
                addresses:
                  address:
                    - ip: 2.2.2.2/32
                      config:
                        ip: 2.2.2.2
                        prefix_length: 32
  openconfig-policy:
    policy_definitions:
      policy_definition:
        - name: CONNECTED-&amp;gt;BGP
          statements:
            statement:
              - name: Loopback0
                conditions:
                  match_interface:
                    config:
                      interface: lo0
                      subinterface: 0
                actions:
                  config:
                    accept_route: empty
  openconfig-bgp:
    global_:
      config:
        as_: 65222
    neighbors:
      neighbor:
        - neighbor_address: 12.12.12.1
          config:
            peer_group: YANG
            peer_as: 65111
    peer_groups:
      peer_group:
        - peer_group_name: YANG
          config:
            peer_as: 65111
          apply_policy:
            config:
              export_policy:
                - CONNECTED-&amp;gt;BGP
&lt;/code&gt;&lt;/pre&gt;

&lt;h1 id=&#34;configuration&#34;&gt;Configuration&lt;/h1&gt;

&lt;p&gt;Both devices now can be configured with just a single command:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;ansible-playbook config.yaml
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Behind the scenes, Ansible calls my custom &lt;code&gt;ydk_module&lt;/code&gt; and passes to it the full configuration state and device credentials. This module then constructs an empty YDK binding based on the name of a YANG model and &lt;a href=&#34;https://networkop.co.uk/blog/2017/03/13/yaml-yang/&#34;&gt;populates it recursively&lt;/a&gt; with the data from the &lt;code&gt;config&lt;/code&gt; container. Finally, it pushes the data to the device with the help of YDK NETCONF service provider.&lt;/p&gt;

&lt;h1 id=&#34;verification&#34;&gt;Verification&lt;/h1&gt;

&lt;p&gt;There&amp;rsquo;s one side to YANG which I have carefully avoided until now and it&amp;rsquo;s operational state models. These YANG models are built similarly to configuration models, but with a different goal - to extract the running state from a device. The reason why I&amp;rsquo;ve avoided them is that, unlike the configuration models, the current support for state models is limited and somewhat brittle.&lt;br /&gt;
For example, JUNOS natively only supports state models as RPCs, where each RPC represents a certain &lt;code&gt;show&lt;/code&gt; command which, I assume, when passed to the devices gets evaluated, its output parsed and result returned back to the client. With IOX-XE things are a little better with a few of the operational models available in the current 16.4 release. You can check out my &lt;a href=&#34;https://github.com/networkop/yang/tree/master/oper-101&#34; target=&#34;_blank&#34;&gt;Github repo&lt;/a&gt; for some examples of how to check the interface and BGP neighbor state between the two IOS-XE devices. However, most of the models are still missing (I&amp;rsquo;m not counting the MIB-mapped YANG models) in the current release. The next few releases, though, are promised to come with an improved state model support, including some OpenConfig models, which is going to be super cool.&lt;br /&gt;
So in this post, since I couldn&amp;rsquo;t get JUNOS OpenConfig models report any state and my IOS-XE BGP state model wouldn&amp;rsquo;t return any output unless the BGP peering was with another Cisco device or in the &lt;strong&gt;Idle&lt;/strong&gt; state, I&amp;rsquo;m going to have to resort to simply checking the state of physical interfaces. This is how a sample operational state file would look like (question marks are YAML&amp;rsquo;s special notation for sets which is how I decided to encode Enum data type):&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;---
verify:
  interfaces-state:
    interface:
      - name: GigabitEthernet3
        oper_status:
          ? up
      - name: Loopback0
        oper_status:
          ? up
      - name: GigabitEthernet2
        oper_status:
          ? down
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Once again, all expected state can be verified with a single command:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;ansible-playbook verify.yaml
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;If the state defined in that YAML file matches the data returned by the IOS-XE device, the playbook completes successfully. You can check that it works by shutting down one of the &lt;code&gt;GigabitEthernet3&lt;/code&gt; or &lt;code&gt;Loopback0&lt;/code&gt; interfaces and observing how Ansible module returns an error.&lt;/p&gt;

&lt;h1 id=&#34;outro&#34;&gt;Outro&lt;/h1&gt;

&lt;p&gt;Now that I&amp;rsquo;ve come to the end of my YANG series of posts I feel like I need to provide some concise and critical summary of everything I&amp;rsquo;ve been through. However, if there&amp;rsquo;s one thing I&amp;rsquo;ve learned in the last couple of months about YANG, it&amp;rsquo;s that things are changing very rapidly. Both Cisco and Juniper are working hard introducing new models and improving support for the existing ones. So one thing to keep in mind, if you&amp;rsquo;re reading this post a few months after it was published (April 2017), is that some or most of the above limitations may not exist and it&amp;rsquo;s always worth checking what the latest software release has to offer.&lt;/p&gt;

&lt;p&gt;Finally, I wanted to say that I&amp;rsquo;m a strong believer that YANG models are the way forward for network device configuration and state verification, despite the timid scepticism of the networking industry. I think that there are two things that may improve the industry&amp;rsquo;s perception of YANG and help increase its adoption:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;Support from networking vendors - we&amp;rsquo;ve already seen Cisco changing by introducing YANG support on IOS-XE instead of producing another dubious One-PK clone. So big thanks to them and I hope that other vendors will follow suit.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Tools - this part, IMHO, is the most crucial. In order for people to start using YANG models we have to have the right tools that would be versatile enough to allow network engineers to be limited only by their imagination and at the same time be as robust as the CLI. So I wanted to give a big shout out to all the people contributing to open-source projects like &lt;strong&gt;pyang&lt;/strong&gt;, &lt;strong&gt;YDK&lt;/strong&gt; and many others that I have missed or don&amp;rsquo;t know about. You&amp;rsquo;re doing a great job guys, don&amp;rsquo;s stop.&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
</description>
    </item>
    
    <item>
      <title>YANG &amp; Ansible</title>
      <link>https://networkop.co.uk/tags/ansible-yang/</link>
      <pubDate>Tue, 04 Apr 2017 00:00:00 +0000</pubDate>
      
      <guid>https://networkop.co.uk/tags/ansible-yang/</guid>
      <description></description>
    </item>
    
  </channel>
</rss>
