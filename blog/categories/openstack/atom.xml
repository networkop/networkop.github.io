<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: Openstack | Network-oriented programming]]></title>
  <link href="http://networkop.github.io/blog/categories/openstack/atom.xml" rel="self"/>
  <link href="http://networkop.github.io/"/>
  <updated>2016-10-13T03:03:05-07:00</updated>
  <id>http://networkop.github.io/</id>
  <author>
    <name><![CDATA[Michael Kashin]]></name>
    <email><![CDATA[mmkashin@gmail.com]]></email>
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[OpenStack SDN - Distributed Virtual Routing]]></title>
    <link href="http://networkop.github.io/blog/2016/10/13/os-dvr/"/>
    <updated>2016-10-13T00:00:00-07:00</updated>
    <id>http://networkop.github.io/blog/2016/10/13/os-dvr</id>
    <content type="html"><![CDATA[<p>In this post we&rsquo;ll explore how DVR is implemented in OpenStack Neutron and what are some of its benefits and shortcomings.</p>

<!--more-->


<p>To be honest I was a little hesitant to write this post because the topic of Neutron&rsquo;s DVR has already been <abbr title="beaten to death">exhaustively covered</abbr> by many, including <a href="https://assafmuller.com/category/dvr/">Assaf Muller</a>, <a href="http://blog.gampel.net/2014/12/openstack-neutron-distributed-virtual.html">Eran Gampel</a> and in the official OpenStack <a href="http://docs.openstack.org/mitaka/networking-guide/scenario-dvr-ovs.html">networking guide</a>. The coverage of the topic was so thorough that I barely had anything to add. However I still decided to write a DVR post of my own for the following two reasons:</p>

<ol>
<li>I often use my own posts as references and it&rsquo;s always easier for me to find information in my own writings.</li>
<li>I wanted to use this post as a reference platform for subsequent posts about dynamic routing and OVN project.</li>
</ol>


<p>The topic of Neutron&rsquo;s DVR is quite vast so I had to compromise between the length of this post and the level of details. In the end, I edited out most of the repeated content and replaced it with references to my older posts. I think I left everything that should be needed to follow along the narrative so hopefully it won&rsquo;t seem too patchy.</p>

<h2>Virtual topology overview</h2>

<p>Let&rsquo;s see what we&rsquo;re going to be dealing with in this post. This is a simple virtual topology with two VMs sitting in two different subnets. VM1 has a floating IP assigned that is used for external access.</p>

<p><img class="center" src="/images/dvr-topo.png"></p>

<p>Before we get to the packet walk details, let me briefly describe how to build the above topology using Neutron CLI. I&rsquo;ll assume that OpenStack has just been installed and nothing has been configured yet, effectively we&rsquo;ll pick up from where we left our lab in the <a href="http://networkop.github.io/blog/2016/09/09/os-lab-p2/">previous post</a>.</p>

<h2>Virtual topology setup</h2>

<ol>
<li>Upload Cirros Linux image to OpenStack's image repository

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>curl http://download.cirros-cloud.net/0.3.4/cirros-0.3.4-x86_64-disk.img | glance \
</span><span class='line'>     image-create --name='IMG-CIRROS' \
</span><span class='line'>     --visibility=public \
</span><span class='line'>     --container-format=bare \
</span><span class='line'>     --disk-format=qcow2</span></code></pre></td></tr></table></div></figure>
</li>
<li>Create 2 virtual subnets - RED and BLUE

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>neutron net-create NET-BLUE
</span><span class='line'>neutron subnet-create --name SUB-BLUE NET-BLUE 10.0.0.0/24 \
</span><span class='line'>  --dns-nameserver 8.8.8.8
</span><span class='line'>
</span><span class='line'>neutron net-create NET-RED
</span><span class='line'>neutron subnet-create --name SUB-RED NET-RED 10.0.1.0/24 \
</span><span class='line'>  --dns-nameserver 8.8.8.8</span></code></pre></td></tr></table></div></figure>
</li>
<li>Create external network

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>neutron net-create EXT-NET --provider:network_type flat \
</span><span class='line'>  --provider:physical_network extnet  \
</span><span class='line'>  --router:external \
</span><span class='line'>  --shared
</span><span class='line'>
</span><span class='line'>neutron subnet-create --name EXT-SUB \
</span><span class='line'> --enable_dhcp=False \
</span><span class='line'> --allocation-pool=start=169.254.0.50,end=169.254.0.99 \
</span><span class='line'> --gateway=169.254.0.1 EXT-NET 169.254.0.0/24</span></code></pre></td></tr></table></div></figure>
</li>

<li>Create a router and attach it to all three networks created above

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>neutron router-create R1
</span><span class='line'>neutron router-interface-add R1 SUB-RED
</span><span class='line'>neutron router-interface-add R1 SUB-BLUE
</span><span class='line'>neutron router-gateway-set R1 EXT-NET</span></code></pre></td></tr></table></div></figure>
</li>

<li>Create two host aggregates to spread the VMs across two different hosts

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>nova aggregate-create AGG-RED AZ-RED
</span><span class='line'>nova aggregate-create AGG-BLUE AZ-BLUE
</span><span class='line'>nova aggregate-add-host AGG-BLUE compute-2
</span><span class='line'>nova aggregate-add-host AGG-RED compute-3</span></code></pre></td></tr></table></div></figure>
</li>

<li>Boot VMs on two different hypervisors

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>nova boot --flavor m1.tiny --image 'IMG-CIRROS' \
</span><span class='line'>     --nic net-name=NET-BLUE \
</span><span class='line'>    --availability-zone AZ-BLUE \
</span><span class='line'>     VM1
</span><span class='line'>
</span><span class='line'>nova boot --flavor m1.tiny --image 'IMG-CIRROS' \
</span><span class='line'>    --nic net-name=NET-RED \
</span><span class='line'>    --availability-zone AZ-RED \
</span><span class='line'>    VM2</span></code></pre></td></tr></table></div></figure>
</li>

<li>Assign a floating IP (Static NAT) to VM1

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>nova floating-ip-create EXT-NET
</span><span class='line'>nova floating-ip-associate VM1 169.254.0.55</span></code></pre></td></tr></table></div></figure>
</li>

<li>Enable ingress ICMP and SSH access

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>nova secgroup-add-rule default tcp 22 22 0.0.0.0/0
</span><span class='line'>nova secgroup-add-rule default icmp -1 -1 0.0.0.0/0</span></code></pre></td></tr></table></div></figure>
</li>

<li>Make sure that both VMs are up and running.

<figure class='code'><figcaption><span>nova list</span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'>+--------------------------------------+------+--------+------------+-------------+----------------------------------+
</span><span class='line'><span class="p">|</span> ID                                   <span class="p">|</span> Name <span class="p">|</span> Status <span class="p">|</span> Task State <span class="p">|</span> Power State <span class="p">|</span> Networks                         <span class="p">|</span>
</span><span class='line'>+--------------------------------------+------+--------+------------+-------------+----------------------------------+
</span><span class='line'><span class="p">|</span> 92263ae8-43d1-4cd0-b271-2b11f0efbe7f <span class="p">|</span> VM1  <span class="p">|</span> ACTIVE <span class="p">|</span> -          <span class="p">|</span> Running     <span class="p">|</span> NET-BLUE<span class="o">=</span>10.0.0.12, 169.254.0.55 <span class="p">|</span>
</span><span class='line'><span class="p">|</span> b4562f24-2461-49fb-875b-fa1bf869dc4a <span class="p">|</span> VM2  <span class="p">|</span> ACTIVE <span class="p">|</span> -          <span class="p">|</span> Running     <span class="p">|</span> NET-RED<span class="o">=</span>10.0.1.4                 <span class="p">|</span>
</span><span class='line'>+--------------------------------------+------+--------+------------+-------------+----------------------------------+
</span></code></pre></td></tr></table></div></figure>
</li>
</ol>


<h2>non-DVR traffic flow</h2>

<p>Using the technique described in my <a href="http://networkop.github.io/blog/2016/04/22/neutron-native/">earlier post</a> I&rsquo;ve collected the dynamically allocated port numbers and created a physical representation of our virtual network.</p>

<p><img class="center" src="/images/dvr-before.png"></p>

<p>For the sake of brevity I will omit the verification commands. The traffic flow between VM1 and VM2 will follow the standard path that I&rsquo;ve explored in my <a href="http://networkop.github.io/blog/2016/04/22/neutron-native/">native Neutron SDN post</a>.<br/>
It is obvious that in this case traffic flows are suboptimal. Instead of going directly between the peer compute nodes, the packet has to hairpin through a Neutron router. This adds to the end-to-end latency and creates unnecessary load on the Network node. These are one of the main reasons why Distributed Virtual Routing was introduced in OpenStack Juno.</p>

<h2>Enabling DVR</h2>

<p>Enabling DVR requires configuration changes of multiple files on all OpenStack nodes. At a high level, all compute nodes will now run Neutron&rsquo;s L3-agent service which will be responsible for provisioning of DVR and other auxiliary namespaces. The details of specific configuration options that need to be enabled can be found in the official OpenStack <a href="http://docs.openstack.org/mitaka/networking-guide/scenario-dvr-ovs.html">Networking guide</a>. As usual, I&rsquo;ve incorporated all the necessary changes into a single Chef <a href="https://github.com/networkop/chef-unl-os/tree/master/cookbooks/neutron">cookbook</a>, so in order to enable DVR in our lab all what you need to do is run the following commands from the UNetLab VM:</p>

<p><figure class='code panel panel-default'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'>git pull origin master
</span><span class='line'>chef-client -z -E lab neutron.rb
</span></code></pre></td></tr></table></div></figure></p>

<p>Once all changes has been made, we need to either create a new router or update the existing one to enable the DVR functionality:</p>

<p><figure class='code panel panel-default'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'>neutron router-update <span class="p">&amp;</span>ndash<span class="p">;</span>admin-state-up False <span class="p">&amp;</span>ndash<span class="p">;</span>distributed True R1
</span><span class='line'>neutron router-update <span class="p">&amp;</span>ndash<span class="p">;</span>admin-state-up True R1
</span></code></pre></td></tr></table></div></figure></p>

<h2>DVR East-West traffic flow</h2>

<p>Now let&rsquo;s see how the traffic flows have changed with the introduction of DVR.</p>

<p><img class="center" src="/images/dvr-ew.png"></p>

<p>We&rsquo;re going to be examining the following traffic flow:</p>

<ul>
<li>From VM1 (10.0.0.12/fa:16:3e:83:92:96)</li>
<li>Via router R1 (10.0.0.1/fa:16:3e:72:7a:50; 10.0.1.1/fa:16:3e:6a:2c:8b)</li>
<li>To VM2 (10.0.1.4/fa:16:3e:76:31:68)</li>
</ul>


<p>R1 now has an instance on all compute nodes that have VMs in the BLUE or RED networks. That means that VM1 will send a packet directly to the R1&rsquo;s BLUE interface via the integration bridge.</p>

<pre><code class="bash ovs-appctl fdb/show br-int"> port  VLAN  MAC                Age
    2     1  fa:16:3e:83:92:96    1
    4     1  fa:16:3e:72:7a:50    1
    5     2  fa:16:3e:6a:2c:8b    1
</code></pre>

<p>This is dynamically populated MAC address table of the integration bridge. You can see that the MAC address of VM1 and both interfaces of R1 have been learned. That means that when VM1 sends a packet to its default gateway&rsquo;s MAC address, it will go directly to R1&rsquo;s BLUE interface on port 4.</p>

<p>In this post I will omit the details of ARP resolution process which remains the same as <a href="http://networkop.github.io/blog/2016/05/06/neutron-l2pop/">before</a>, however there&rsquo;s one interesting detail that is worth mentioning before we move on. During the initial flood-and-learn phase on the <strong>br-int</strong>, the ARP request will get flooded down to the tunnel bridge. As per the standard behaviour, the packet should get replicated to all nodes. However, in this case we don&rsquo;t want to hear responses from other nodes, since the router is hosted locally. In order to help that, tunnel bridges explicitly drop all packets coming from integration bridges and destined for MAC addresses of locally hosted routers:</p>

<p><code>bash ovs-appctl ofproto/trace br-tun in_port=1,dl_vlan=1,dl_dst=fa:16:3e:72:7a:50 | grep -E "Rule|action"
Rule: table=0 cookie=0xa3536ac94478bd1d priority=1,in_port=1
OpenFlow actions=goto_table:1
        Rule: table=1 cookie=0xa3536ac94478bd1d priority=2,dl_vlan=1,dl_dst=fa:16:3e:72:7a:50
        OpenFlow actions=drop
</code></p>

<p>Getting back to our traffic flow, once the IP packet has reached the DVR instance of R1 on compute node #2, the routing lookup occurs and the packet is sent back to the integration bridge with a new source MAC of R1&rsquo;s RED interface.</p>

<pre><code class="bash ip netns exec qrouter-uuid ip route">10.0.0.0/24 dev qr-102c4426-86  proto kernel  scope link  src 10.0.0.1
10.0.1.0/24 dev qr-3779302e-62  proto kernel  scope link  src 10.0.1.1
</code></pre>

<p>Tunnel bridge will do its usual work by locating the target compute node based on the destination MAC address of VM2 (DVR requires <a href="http://networkop.github.io/blog/2016/05/06/neutron-l2pop/">L2 population</a> to be enabled) and will send the packet directly to the compute node #3.</p>

<p><code>bash ovs-appctl ofproto/trace br-tun in_port=1,dl_vlan=2,dl_src=fa:16:3e:6a:2c:8b,dl_dst=fa:16:3e:76:31:68 | grep -E "Rule|action"
Rule: table=0 cookie=0xa3536ac94478bd1d priority=1,in_port=1
OpenFlow actions=goto_table:1
        Rule: table=1 cookie=0xa3536ac94478bd1d priority=1,dl_vlan=2,dl_src=fa:16:3e:6a:2c:8b
        OpenFlow actions=set_field:fa:16:3f:d3:10:60-&gt;eth_src,goto_table:2
                Rule: table=2 cookie=0xa3536ac94478bd1d priority=0,dl_dst=00:00:00:00:00:00/01:00:00:00:00:00
                OpenFlow actions=goto_table:20
                        Rule: table=20 cookie=0xa3536ac94478bd1d priority=2,dl_vlan=2,dl_dst=fa:16:3e:76:31:68
                        OpenFlow actions=pop_vlan,set_field:0x4d-&gt;tun_id,output:3
</code></p>

<p>Since all instances of R1 have the same set of IP/MAC addresses, the MAC address of a local router can be learned by the remote integration bridge hosting the same instance of DVR. In order to prevent that from happening, the sending <strong>br-tun</strong> replaces the source MAC address of the frame with the <code>set_field:fa:16:3f:d3:10:60-&gt;eth_src</code> action. This way the real R1&rsquo;s MAC address gets masked as the frame leaves the node. These &ldquo;mask&rdquo; MACs are generated by and learned from the Neutron server, which ensures that each node gets a unique address.</p>

<p>The receiving node&rsquo;s <strong>br-tun</strong> will swap the VXLAN header with a VLAN ID and forward the frame up to the integration bridge.</p>

<p><code>bash ovs-appctl ofproto/trace br-tun in_port=3,tun_id=0x4d,dl_dst=fa:16:3e:76:31:68 | grep -E "Rule|action"
Rule: table=0 cookie=0x8a7dedf35101427f priority=1,in_port=3
OpenFlow actions=goto_table:4
        Rule: table=4 cookie=0x8a7dedf35101427f priority=1,tun_id=0x4d
        OpenFlow actions=push_vlan:0x8100,set_field:4097-&gt;vlan_vid,goto_table:9
                Rule: table=9 cookie=0x8a7dedf35101427f priority=0
                OpenFlow actions=goto_table:10
                        Rule: table=10 cookie=0x8a7dedf35101427f priority=1
                        OpenFlow actions=learn(table=20,hard_timeout=300,priority=1,cookie=0x8a7dedf35101427f,NXM_OF_VLAN_TCI[0..11],NXM_OF_ETH_DST[]=NXM_OF_ETH_SRC[],load:0-&gt;NXM_OF_VLAN_TCI[],load:NXM_NX_TUN_ID[]-&gt;NXM_NX_TUN_ID[],output:OXM_OF_IN_PORT[]),output:1
                                Rule: table=0 cookie=0x9a1e0026794eadc5 priority=1
                                OpenFlow actions=NORMAL
</code></p>

<p>Integration bridge of compute node #3 will lookup the destination MAC address and send the packet out port 2.</p>

<pre><code class="bash ovs-appctl fdb/show br-int"> port  VLAN  MAC                Age
    2     1  fa:16:3e:76:31:68    0
    4     2  fa:16:3e:72:7a:50    0
    5     1  fa:16:3e:6a:2c:8b    0
    1     1  fa:16:3e:29:de:20    0
</code></pre>

<p>The reverse packet flow is similar - the packet will get routed on the compute node #3 and sent in a BLUE network to the compute node #2.</p>

<h2>External connectivity</h2>

<p>External connectivity will be very different for VMs with and without a floating IP. Below diagram is a high-level representation of traffic flows in these two cases. We will examine each one of them individually.</p>

<h3>Case 1 - Overload NAT (VM2 with no FIP)</h3>

<p><img class="center" src="/images/dvr-snat.png"></p>

<p>External connectivity for VMs with no floating IP is still performed by the Network node. This time however, NATing is performed by a new element - SNAT namespace. As per the normal behaviour, VM2 will send a packet to its default gateway first. Let&rsquo;s have a closer look at the routing table of the DVR:</p>

<pre><code class="bash ip netns exec qrouter-uuid ip route">10.0.0.0/24 dev qr-102c4426-86  proto kernel  scope link  src 10.0.0.1
10.0.1.0/24 dev qr-3779302e-62  proto kernel  scope link  src 10.0.1.1
</code></pre>

<p>There&rsquo;s no default route in the main routing table, so how would it get routed out? DVRs extensively use <a href="http://linux-ip.net/html/tools-ip-rule.html">Linux routing policy database</a> (RPDB), a feature that has a lot in common with OpenFlow tables. The principle of RPDB is that every packet gets matched against a set of routing tables until there&rsquo;s a hit. The tables are checked in the order of their priority (lowest to highest). One of the main features of RPDB is the ability to perform matches based on something other than the destination IP address, which is why it&rsquo;s often referred to as policy-based routing. To view the contents of RPDB use the <code>ip rule</code> command under the DVR namespace:</p>

<pre><code class="bash ip netns exec qrouter-uuid ip rule">0:      from all lookup local
32766:  from all lookup main
32767:  from all lookup default
167772161:      from 10.0.0.1/24 lookup 167772161
167772417:      from 10.0.1.1/24 lookup 167772417
</code></pre>

<p>In our case table 167772161 matches all packets sourced from the BLUE subnet and if we examine the corresponding routing table we&rsquo;ll find the missing default route there.</p>

<pre><code class="bash ip netns exec qrouter-uuid ip route list table 167772417">default via 10.0.1.12 dev qr-3779302e-62
</code></pre>

<p>The next hop of this default route points to the SNAT&rsquo;s interface in the BLUE network. MAC address is statically programmed by the local L3-agent.</p>

<pre><code class="bash ip netns exec qrouter-uuid ip neigh | grep 10.0.1.12">10.0.1.12 dev qr-3779302e-62 lladdr fa:16:3e:29:de:20 PERMANENT
</code></pre>

<p>Integration bridge sends the packet out port 1 to the tunnel bridge.</p>

<pre><code class="bash ovs-appctl fdb/show br-int | grep fa:16:3e:29:de:20">    1     1  fa:16:3e:29:de:20    1
</code></pre>

<p>Tunnel bridge finds the corresponding match and sends the VXLAN-encapsulated packet to the Network node.</p>

<p><code>bash ovs-appctl ofproto/trace br-tun in_port=1,dl_vlan=1,dl_dst=fa:16:3e:29:de:20 | tail -n 1
Datapath actions: set(tunnel(tun_id=0x4d,src=10.0.0.4,dst=10.0.0.0,ttl=64,flags(df|key))),pop_vlan,3
</code></p>

<p>Tunnel bridge of the Network node forwards the frame up to the integration bridge.</p>

<p><code>bash ovs-appctl ofproto/trace br-tun in_port=3,tun_id=0x4d,dl_dst=fa:16:3e:29:de:20 | grep output
OpenFlow actions=learn(table=20,hard_timeout=300,priority=1,cookie=0xb9be3fe62922c800,NXM_OF_VLAN_TCI[0..11],NXM_OF_ETH_DST[]=NXM_OF_ETH_SRC[],load:0-&gt;NXM_OF_VLAN_TCI[],load:NXM_NX_TUN_ID[]-&gt;NXM_NX_TUN_ID[],output:OXM_OF_IN_PORT[]),output:1
</code></p>

<p>Integration bridge sends the frame to port 10, which is where SNAT namespace is attached</p>

<pre><code class="bash ovs-appctl fdb/show br-int | grep fa:16:3e:29:de:20">   10     1  fa:16:3e:29:de:20    0
</code></pre>

<p>SNAT is a namespace with an interface in each of the subnets - BLUE, RED and External subnet</p>

<pre><code class="bash ip netns exec snat-uuid ip a | grep -E "UP|inet"">16: sg-fefd493b-a5: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1450 qdisc noqueue state UNKNOWN
    link/ether fa:16:3e:99:5c:3a brd ff:ff:ff:ff:ff:ff
    inet 10.0.0.6/24 brd 10.0.0.255 scope global sg-fefd493b-a5
18: sg-b3d58360-b4: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1450 qdisc noqueue state UNKNOWN
    link/ether fa:16:3e:29:de:20 brd ff:ff:ff:ff:ff:ff
    inet 10.0.1.12/24 brd 10.0.1.255 scope global sg-b3d58360-b4
19: qg-765b5aca-ce: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc noqueue state UNKNOWN
    link/ether fa:16:3e:d5:75:0e brd ff:ff:ff:ff:ff:ff
    inet 169.254.0.57/24 brd 169.254.0.255 scope global qg-765b5aca-ce
</code></pre>

<p>SNAT has a single default route pointing to the External network&rsquo;s gateway.</p>

<pre><code class="bash ip netns exec snat-uuid ip route | grep default">default via 169.254.0.1 dev qg-765b5aca-ce
</code></pre>

<p>Before sending the packet out, iptables will NAT the packet to hide it behind SNAT&rsquo;s <strong>qg</strong> external interface IP.</p>

<pre><code class="bash ip netns exec snat-uuid iptables -t nat -L | grep SNAT">SNAT       all  --  anywhere             anywhere             to:169.254.0.57
</code></pre>

<h3>Case 2 - Static NAT (VM1 with FIP)</h3>

<p><img class="center" src="/images/dvr-dnat.png"></p>

<p>The first step in this scenario is the same - VM1 sends a packet to the MAC address of its default gateway. As before, the default route is missing in the main routing table.</p>

<pre><code class="bash ip netns exec qrouter-uuid ip route list table main">10.0.0.0/24 dev qr-102c4426-86  proto kernel  scope link  src 10.0.0.1
10.0.1.0/24 dev qr-3779302e-62  proto kernel  scope link  src 10.0.1.1
169.254.106.114/31 dev rfp-e4d4897e-7  proto kernel  scope link  src 169.254.106.114
</code></pre>

<p>Looking at the <strong>ip rule</strong> configuration we can find that table 16 matches all packets from that particular VM (10.0.0.12).</p>

<pre><code class="bash ip netns exec qrouter-uuid ip rule">0:      from all lookup local
32766:  from all lookup main
32767:  from all lookup default
57481:  from 10.0.0.12 lookup 16
167772161:      from 10.0.0.1/24 lookup 167772161
167772417:      from 10.0.1.1/24 lookup 167772417
</code></pre>

<p>Routing table 16 sends the packet via a point-to-point veth pair link to the FIP namespace.</p>

<pre><code class="bash ip netns exec qrouter-uuid ip route list table 16">default via 169.254.106.115 dev rfp-e4d4897e-7
</code></pre>

<p>Before sending the packet out, DVR translates the source IP of the packet to the FIP assigned to that VM.</p>

<pre><code class="bash ip netns exec qrouter-uuid iptables -t nat -L | grep NAT">SNAT       all  --  10.0.0.12            anywhere             to:169.254.0.55
</code></pre>

<p>A FIP namespace is a simple router designed to connect multiple DVRs to external network. This way all routers can share the same &ldquo;uplink&rdquo; namespace and don&rsquo;t have to consume valuable addresses from external subnet.</p>

<pre><code class="bash ip netns exec fip-uuid ip a | grep -E "UP|inet"">2: fpr-e4d4897e-7: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc pfifo_fast state UP qlen 1000
    inet 169.254.106.115/31 scope global fpr-e4d4897e-7
15: fg-d3bb699d-af: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc noqueue state UNKNOWN
    inet 169.254.0.58/24 brd 169.254.0.255 scope global fg-d3bb699d-af
</code></pre>

<p>Default route inside the FIP namespace points to the External subnet&rsquo;s gateway IP.</p>

<pre><code class="bash ip netns exec fip-uuid ip route | grep default">default via 169.254.0.1 dev fg-d3bb699d-af
</code></pre>

<p>The MAC address of the gateway is statically configured by the L3 agent.</p>

<pre><code class="bash ip netns exec fip-uuid ip neigh | grep 169.254.0.1">169.254.0.1 dev fg-d3bb699d-af lladdr 32:3e:7d:13:ca:78 DELAY
</code></pre>

<p>The packet is sent to the <strong>br-int</strong> with the destination MAC address of the default gateway.</p>

<pre><code class="bash ovs-appctl fdb/show br-int | grep 32:3e:7d:13:ca:78">  3     3  32:3e:7d:13:ca:78    1
</code></pre>

<p>External bridge strips the VLAN ID of the packet coming from the <strong>br-int</strong> and does the lookup in the dynamic MAC address table.</p>

<p><code>bash ovs-appctl ofproto/trace br-ex in_port=2,dl_vlan=3 | grep actions=
OpenFlow actions=pop_vlan,NORMAL
</code></p>

<p>The frame is forwarded out the physical interface.</p>

<pre><code class="bash ovs-appctl fdb/show br-ex | grep 32:3e:7d:13:ca:78">1     0  32:3e:7d:13:ca:78    1
</code></pre>

<p>Reverse packet flow will be quite similar, however in this case FIP namespace must be able to respond to ARP requests for the IPs that only exist on DVRs. In order to do that, it uses a proxy-ARP feature. First, L3 agent installs a static route for the FIP pointing back to the correct DVR over the veth pair interface:</p>

<pre><code class="bash ip netns exec fip-uuid ip route get 169.254.0.55">169.254.0.55 via 169.254.106.114 dev fpr-e4d4897e-7  src 169.254.106.115
</code></pre>

<p>Now that the FIP namespace knows the route to the floating IP, it can respond to ARPs on behalf of DVR as long as proxy-ARP is enabled on the external <strong>fg</strong> interface:</p>

<pre><code class="bash ip netns exec fip-uuid">cat /proc/sys/net/ipv4/conf/fg-d3bb699d-af/proxy_arp
1
</code></pre>

<p>Finally, the DVR NATs the packet back to its internal IP in the BLUE subnet and forwards it straight to VM1.</p>

<pre><code class="bash ip netns exec qrouter-uuid iptables -t nat -L | grep DNAT">DNAT       all  --  anywhere             169.254.0.55         to:10.0.0.12
</code></pre>

<h2>DVR Pros and Cons</h2>

<p>Without a doubt DVR has introduced a number of much needed <strong>improvements</strong> to OpenStack networking:</p>

<ul>
<li>East-West traffic now follows the most optimal path thereby reducing the load on the Network node.</li>
<li>External connectivity to floating IPs now also follows the most optimal path directly to the compute node hosting the VM.</li>
</ul>


<p>However, there&rsquo;s a number of <strong>issues</strong> that either remain unaddressed or result directly from the current DVR architecture:</p>

<ul>
<li>DHCP and SNAT are still hosted on the Network node.</li>
<li>Asymmetric routing means that every DVR needs to have an interface in every configured subnet, even when there are no VMs that belong to those subnets on the current compute node.</li>
<li>Direct connectivity to FIP means that all compute nodes now need to have direct L2 adjacency to external subnets.</li>
<li>FIP namespace on compute nodes consumes IP addresses from external subnets which can be a problem if external subnet is in a public IPv4 address range.</li>
<li>DVR implementation as a network namespace creates additional overhead in packet processing.</li>
</ul>


<p>Some of the above issues are not critical and can be fixed with a little effort:</p>

<ul>
<li>In order to reduce the scope of a External network VLAN span inside the DC, dedicate a subset of hosts that will have a direct L2 adjacency to external networks and only deploy external-facing VMs on those hosts.</li>
<li>Since FIP namespace only requires an external IP address for <a href="http://lists.openstack.org/pipermail/openstack-dev/2016-June/096386.html">debugging purposes</a>, we can create an additional, secondary, subnet in RFC1918 space for FIP connectivity. This is enabled by a feature called subnet <a href="https://specs.openstack.org/openstack/neutron-specs/specs/newton/subnet-service-types.html">&ldquo;Service types&rdquo;</a> and is <a href="https://github.com/openstack/neutron-specs/blob/master/specs/newton/subnet-service-types.rst">available</a> in the latest Newton release.</li>
</ul>


<p>However the main issue still remains unresolved. Every North-South packet has to hop several times between the global and DVR/FIP/NAT namespaces. These kind of operations are very expensive in terms of consumed CPU and memory resources and can be very detrimental to network performance. Using namespaces may be the most straight-forward and non-disruptive way of implementing DVR, however it&rsquo;s definitely not the most optimal. Ideally we&rsquo;d like to see both L2 and L3 pipelines implemented in OpenvSwitch tables. This way all packets can benefit from OVS <a href="https://networkheresy.com/2014/11/13/accelerating-open-vswitch-to-ludicrous-speed/">fast-path flow caching</a>. But fear not, the solution to this already exists in a shape of <a href="https://www.openstack.org/summit/vancouver-2015/summit-videos/presentation/ovn-native-virtual-networking-for-open-vswitch">Open Virtual Network</a>. OVN is a project spawned from the OVS and aims to <a href="https://blog.russellbryant.net/2016/09/29/ovs-2-6-and-the-first-release-of-ovn/">address</a> a number of shortcomings existing in current implementations of virtual networks.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Automating the Build of OpenStack Lab (Part 2)]]></title>
    <link href="http://networkop.github.io/blog/2016/09/09/os-lab-p2/"/>
    <updated>2016-09-09T00:00:00-07:00</updated>
    <id>http://networkop.github.io/blog/2016/09/09/os-lab-p2</id>
    <content type="html"><![CDATA[<p>In this post we&rsquo;ll use Chef, unnumbered BGP and Cumulus VX to build a massively scalable &ldquo;Lapukhov&rdquo; Leaf-Spine data centre.</p>

<!--more-->


<hr />

<p>In the <a href="http://networkop.github.io/blog/2016/08/26/os-lab-p1/">last post</a> we&rsquo;ve seen how to use Chef to automate the build of a 3-node OpenStack cloud. The only thing remaining is to build an underlay network supporting communication between the nodes, which is what we&rsquo;re going to do next. The build process will, again, be relatively simple and will include only a few manual steps, but before we get there let me go over some of the decisions and assumptions I&rsquo;ve made in my network design.</p>

<h2>High-level design</h2>

<p>The need to provide more bandwidth for East-West traffic has made the Clos Leaf-Spine architecture a de facto standard in any data centre network design. The use of virtual overlay networks has obviated the requirement to have a strict VLAN and IP numbering schemes in the underlay. The only requirement for the compute nodes now is to have any-to-any layer 3 connectivity. This is how the underlay network design has converged to a Layer 3 Leaf-Spine architecture.<br/>
The choice of a routing protocol is not so straight-forward. My fellow countryman Petr Lapukhov and co-authors of <a href="https://tools.ietf.org/html/draft-ietf-rtgwg-bgp-routi3ng-large-dc-11">RFC draft</a> claim that having a single routing protocol in your WAN and DC reduces complexity and makes interoperability and operations a lot easier. This draft presents some of the design principles that can be used to build a L3 data centre with BGP as the only routing protocol. In our lab we&rsquo;re going to implement a single &ldquo;cluster&rdquo; of the multi-tier topology proposed in that RFC.</p>

<p><img class="center" src="/images/os-lab-chef-full.png"></p>

<p>In order to help us build this in an automated and scalable way, we&rsquo;re going to use a relatively new feature called <strong>unnumbered BGP</strong>.</p>

<h2>Unnumbered BGP as a replacement for IGP</h2>

<p>As we all know, one of the main advantages of interior gateway protocols is the automatic discovery of adjacent routers which is accomplished with the help of link-local multicasts. On the other hand, BGP traditionally required you to explicitly define neighbor&rsquo;s IP address in order to establish a peering relationship with it. This is where IPv6 comes to the rescue. With the help of neighbor discovery protocol and router advertisement messages, it becomes possible to accurately determine the address of the peer BGP router on an intra-fabric link. The only question is how we would exchange IPv4 information over and IPv6-only BGP network.<br/>
<a href="https://tools.ietf.org/html/rfc5549">RFC 5549</a>, described an &ldquo;extended nexthop encoding capability&rdquo; which allows BGP to exchange routing updates with nexthops that don&rsquo;t belong to the address family of the advertised prefix. In plain English it means that BGP is now capable of advertising an IPV4 prefix with an IPv6 nexthop. This makes it possible to configure all transit links inside the Clos fabric with IPv6 link-local addresses and still maintain reachability between the edge IPv4 host networks. Since nexthop IPs will get updated at every hop, there is no need for an underlying IGP to distribute them between all BGP routers. What we see is, effectively, BGP <strong>absorbing</strong> the functions of an IGP protocol inside the data centre.</p>

<h2>Configuration example on Cumulus VX</h2>

<p>In order to implement BGP unnumbered on Cumulus Linux all you need to is:</p>

<ol>
<li>Enable IPv6 router advertisements on all transit links</li>
<li>Enable BGP on the same interfaces</li>
</ol>


<p>Example Quagga configuration snippet will look like this:</p>

<p><figure class='code panel panel-default'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'>interface swp1
</span><span class='line'>  ipv6 nd ra-interval 5
</span><span class='line'>  no ipv6 nd suppress-ra&lt;/p&gt;
</span><span class='line'>
</span><span class='line'>&lt;p&gt;rouer bgp &lt;ASN&gt;
</span><span class='line'>  neighbor swp1 interface
</span><span class='line'>  neighbor swp1 external
</span></code></pre></td></tr></table></div></figure></p>

<p>As you can see, Cumulus simplifies it even more by allowing you to only specify the BGP peering type (external/internal) and learning the value of peer BGP AS dynamically from a neighbor.</p>

<h2>Design assumptions and caveats</h2>

<p>With all the above in mind, this is the list of decisions I&rsquo;ve made while building the fabric configuration:</p>

<ul>
<li>All switches inside the fabric will be running BGP peerings using <strong>IPv6 link-local</strong> addresses</li>
<li><strong>eBGP</strong> will be used throughout to simplify configuration automation (all peers will be external)</li>
<li>Each Leaf/Spine switch will have a <strong>unique IPv4 loopback</strong> address assigned for management purposes (ICMP, SSH)</li>
<li>On each Leaf switch <strong>all directly connected IPv4</strong> prefixes will get redistributed into BGP</li>
<li>BGP multipath rule will be &ldquo;relaxed&rdquo; to allow for different AS-PATHs. This is not used in our current topology but is required in an HA Leaf switch design (same IPv4 prefix will be advertised from two Leaf switches with different ASN)</li>
<li>Loop prevention on Leaf switches will also be &ldquo;relaxed&rdquo;. This, again, is not used in our single &ldquo;cluster&rdquo; topology, however it will allow same Leaf ASNs to be reused in a different cluster.</li>
</ul>


<h2>Implementation steps</h2>

<p>Picking up where we left off after the OpenStack node provisioning described in the <a href="http://networkop.github.io/blog/2016/08/26/os-lab-p1/">previous post</a></p>

<ol>
<li><p>Get the latest <a href="https://github.com/networkop/chef-unl-os">OpenStack lab cookbooks</a></p>

<p> <figure class='code panel panel-default'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'> git clone &lt;a <span class="nv">href</span><span class="o">=</span><span class="s2">&quot;https://github.com/networkop/chef-unl-os.git&quot;</span>&gt;https://github.com/networkop/chef-unl-os.git&lt;/a&gt;
</span><span class='line'> <span class="nb">cd </span>chef-unl-os
</span><span class='line'>
</span></code></pre></td></tr></table></div></figure></p></li>
<li><p><a href="https://cumulusnetworks.com/cumulus-vx/">Download</a> and import Cumulus VX image similar to how it&rsquo;s described <a href="http://www.unetlab.com/2015/06/adding-cisco-asav-images/">here</a>.</p>

<p> <figure class='code panel panel-default'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'> /opt/unetlab/addons/qemu/cumulus-vx/hda.qcow2
</span><span class='line'>
</span></code></pre></td></tr></table></div></figure></p></li>
<li><p>Build the topology inside UNL. Make sure that Node IDs inside UNL match the ones in <strong>chef-unl-os/environment/lab.rb</strong> file and that interfaces are connected as shown in the diagram below</p>

<p> <img class="center" src="/images/os-lab-unl.png"></p></li>
<li><p>Re-run UNL self-provisioning cookbook to create a <a href="https://github.com/networkop/chef-unl-os/blob/master/cookbooks/pxe/templates/ztp.erb">zero touch provisioning</a> file and update DHCP server configuration with static entries for the switches.</p>

<p> <figure class='code panel panel-default'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'> chef-client -z -E lab -o pxe
</span><span class='line'>
</span></code></pre></td></tr></table></div></figure></p>

<p> Cumulus <a href="https://docs.cumulusnetworks.com/display/DOCS/Zero+Touch+Provisioning+-+ZTP">ZTP</a> allows you to run a predefined script on the first boot of the operating system. In our case we inject a UNL VM&rsquo;s public key and enable passwordless <strong>sudo</strong> for cumulus user.</p></li>
<li><p>Kickoff Chef provisioning to bootstrap and configure the DC fabric.</p>

<p> <figure class='code panel panel-default'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'> chef-client -z -E lab fabric.rb
</span><span class='line'>
</span></code></pre></td></tr></table></div></figure></p>

<p> This command instructs Chef provisioning to connect to each switch, download and install the Chef client and run a simple recipe to create quagga configuration file from a template.</p></li>
</ol>


<p>At the end of step 5 we should have a fully functional BGP-only fabric and all 3 compute nodes should be able to reach each other in at most 4 hops.</p>

<p><code>bash [root@controller-1 ~]# traceroute 10.0.0.4
traceroute to 10.0.0.4 (10.0.0.4), 30 hops max, 60 byte packets
 1  10.0.0.1 (10.0.0.1)  0.609 ms  0.589 ms  0.836 ms
 2  10.255.255.7 (10.255.255.7)  0.875 ms  2.957 ms  3.083 ms
 3  10.255.255.6 (10.255.255.6)  3.473 ms  5.486 ms  3.147 ms
 4  10.0.0.4 (10.0.0.4)  4.231 ms  4.159 ms  4.115 ms
</code></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Automating the Build of OpenStack Lab (Part 1)]]></title>
    <link href="http://networkop.github.io/blog/2016/08/26/os-lab-p1/"/>
    <updated>2016-08-26T00:00:00-07:00</updated>
    <id>http://networkop.github.io/blog/2016/08/26/os-lab-p1</id>
    <content type="html"><![CDATA[<p>In this post we will explore what&rsquo;s required to perform a zero-touch deployment of an OpenStack cloud. We&rsquo;ll get a 3-node lab up and running inside UNetLab with just a few commands.</p>

<!--more-->


<hr />

<p>Now that I&rsquo;m finally beginning to settle down at my new place of residence I can start spending more time on research and blogging. I have left off right before I was about to start exploring the native OpenStack distributed virtual routing function. However as I&rsquo;d started rebuilding my OpenStack lab from scratch I realised that I was doing a lot of repetitive tasks which can be easily automated. Couple that with the fact that I needed to learn Chef for my new work and you&rsquo;ve got this blogpost describing a few Chef <a href="https://github.com/networkop/chef-unl-os.git">cookbooks</a> (similar to Ansible&rsquo;s playbook) automating all those manual steps described in my earlier blogposts <a href="http://networkop.github.io/blog/2016/04/04/openstack-unl/">1</a> and <a href="http://networkop.github.io/blog/2016/04/18/os-unl-lab/">2</a>.<br/>
In addition to that in this post I&rsquo;ll show how to build a very simple OpenStack baremetal provisioner and installer. Some examples of production-grade baremetal provisioners are <a href="https://wiki.openstack.org/wiki/Ironic">Ironic</a>, <a href="http://crowbar.github.io/">Crowbar</a> and <a href="http://maas.io/">MAAS</a>. In our case we&rsquo;ll turn UNetLab VM into an <strong>undercloud</strong>, a server used to provision and deploy our OpenStack lab, an <strong>overcloud</strong>. To do that we&rsquo;ll first install and configure DHCP, TFTP and Apache servers to PXE-boot our UNL OpenStack nodes. Once all the nodes are bootstrapped, we&rsquo;ll use Chef to configure the server networking and kickoff the packstack OpenStack installer.</p>

<p><img class="center" src="/images/os-lab-chef.png"></p>

<p>In this post I&rsquo;ll try to use Chef recipes that I&rsquo;ve written as much as possible, therefore you won&rsquo;t see the actual configuration commands, e.g. how to configure Apache or DHCP servers. However I will try to describe everything that happens at each step and hopefully that will provide enough incentive for the curious to look into the Chef code and see how it&rsquo;s done. To help with the Chef code understanding let me start with a brief overview of what to look for in a cookbook.</p>

<h2>How to read a Chef cookbook (Optional)</h2>

<p>A cookbook directory (<strong>/cookbooks/[cookbook_name]</strong>) contains all its configuration scripts in <strong>/recipes</strong>. Each file inside a recipe contains a list of steps to be performed on a server. Each step is an operation (add/delete/update) on a <strong>resource</strong>. Here are some of the common Chef resources:</p>

<ul>
<li>Package - allows you to add, remove or update a package</li>
<li>Template - creates a file from an <strong>erb</strong>-formatted template</li>
<li>Execute - runs an ad-hoc CLI command</li>
</ul>


<p>Just these three basic resources allow you to do 95% of administrative tasks on any server. Most importantly they do it in platform-independent (any flavour of Linux) and idempotent (only make changes if current state is different from a desired state) way. Other directories you might want to explore are:</p>

<ul>
<li>/templates - contains all the <strong>erb</strong>-formatted templates</li>
<li>/attributes - contains recipe variables (file paths, urls etc.)</li>
<li>/files - contains the non-template files, i.e. files with static content</li>
</ul>


<h2>Bootstrapping the OpenStack nodes</h2>

<ol>
<li><p>If you haven&rsquo;t done it yet, download a copy of the <strong>UNetLab VM</strong> from the <a href="http://www.unetlab.com/">official website</a>. Set it up inside your hypervisor so that you can access Internet through the first interface <strong>pnet0</strong> (i.e. connect the first NIC of the VM to hypervisor&rsquo;s NAT interface). Make sure the VM has got at least 6GB of RAM and VT-x support enabled for nested virtualization.</p></li>
<li><p>Follow the official <a href="https://downloads.chef.io/chef-dk/">installation instructions</a> to <strong>install Chef Development Kit</strong> inside UNetLab VM.</p>

<p><figure class='code panel panel-default'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'>wget &lt;a <span class="nv">href</span><span class="o">=</span><span class="s2">&quot;https://packages.chef.io/stable/ubuntu/12.04/chefdk_0.16.28-1_amd64.deb&quot;</span>&gt;https://packages.chef.io/stable/ubuntu/12.04/chefdk_0.16.28-1_amd64.deb&lt;/a&gt;
</span><span class='line'>dpkg -i chefdk_0.16.28-1_amd64.deb
</span></code></pre></td></tr></table></div></figure></p></li>
<li><p><strong>Install git</strong> and clone <a href="https://github.com/networkop/chef-unl-os.git">chef cookbooks</a>.</p>

<p><figure class='code panel panel-default'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'>apt-get -y update
</span><span class='line'>apt-get -y install git
</span><span class='line'>git clone &lt;a <span class="nv">href</span><span class="o">=</span><span class="s2">&quot;https://github.com/networkop/chef-unl-os.git&quot;</span>&gt;https://github.com/networkop/chef-unl-os.git&lt;/a&gt;
</span><span class='line'><span class="nb">cd </span>chef-unl-os
</span></code></pre></td></tr></table></div></figure></p></li>
<li><p>Examine the lab <strong>environment settings</strong> to see what values are going to be used. You can modify that file to your liking.</p>

<blockquote><p>Note that the OpenStack node IDs (keys of <em>os_lab</em> hash) MUST have one to one correspondence with the UNL node IDs which will be created at step 5</p></blockquote>

<p><figure class='code panel panel-default'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'>cat environment/lab.rb
</span></code></pre></td></tr></table></div></figure></p></li>
<li><p>Run Chef against a local server to setup the <strong>baremetal provisioner</strong>. This step installs and configures DHCP, TFTP and Apache servers. It also creates all the necessary PXE-boot and kickstart files based on our environment settings. Note that a part of the process is the download of a 700MB CentOS image so it might take a while to complete.</p>

<p><figure class='code panel panel-default'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'>chef-client -z -E lab -o pxe
</span></code></pre></td></tr></table></div></figure></p>

<p>At the start of the PXE-boot process, DCHP server sends an OFFER which, along with the standard IP information, includes the name of the PXE boot image and the IP address of TFTP server where to get it from. A server loads this image and then searches the TFTP server for the boot configuration file which tells it what kernel to load and where to get a kickstart file. Both kickstart and the actual installation files are accessed via HTTP and served by the same Apache server that runs UNL GUI.</p></li>
<li><p>From <strong>UNL GUI</strong> create a new lab, add 3 OpenStack nodes and connect them all to <strong>pnet10</strong> interface as described in <a href="http://www.unetlab.com/2014/11/using-cloud-devices/">this guide</a>. Note that the <strong>pnet10</strong> interface has already been created by Chef so you don&rsquo;t have to re-create it again.</p>

<blockquote><p>Make sure that the UNL node IDs match the ones defined in the environment setting file</p></blockquote></li>
<li><p>Fire-up the nodes and watch them being bootstrapped by our UNL VM.</p></li>
</ol>


<h2>Server provisioning</h2>

<p>Next step is to configure the server networking and kickoff the OpenStack installer. These steps will also be done with a single command:</p>

<p>   <figure class='code panel panel-default'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'>   chef-client -z -E lab lab.rb
</span><span class='line'>
</span></code></pre></td></tr></table></div></figure>
The first part of this script will connect to each prospective OpenStack node and setup its network interfaces and hostnames. The second part of this script will generate a packstack answer file and modify its settings to exclude some of the components we&rsquo;re not going to use (like Nagios, Ceph and Ceilometer). Have a look at <strong>cookbooks/packstack/recipe/default.rb</strong> for the list of modifications. The final step is a command to kickoff the packstack installer which will use another configuration management system, Puppet, to install and configure OpenStack according to the provided answer file.</p>

<p>At the end of these steps you should have a fully functional 3-node OpenStack environment.</p>

<h2>To be continued&hellip;</h2>

<p>This is a part of a 2-post series. In the next post we&rsquo;ll look into how to use the same tools to perform the baremetal provisioning of our physical underlay network.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[OpenStack SDN - Interconnecting VMs and Physical Devices With Cumulus VX L2 Gateway]]></title>
    <link href="http://networkop.github.io/blog/2016/05/21/neutron-l2gw/"/>
    <updated>2016-05-21T00:00:00-07:00</updated>
    <id>http://networkop.github.io/blog/2016/05/21/neutron-l2gw</id>
    <content type="html"><![CDATA[<p>One of the basic function of any data centre network is the ability to communicate with baremetal servers. In this post we&rsquo;ll see how Neutron L2 Gateway plugin can be used to configure a Cumulus VX switch for VXLAN-VLAN bridging.</p>

<!--more-->


<p>Since I have all my OpenStack environment running inside UNetLab, it makes it really easy for me to extend my L3 fabric with a switch from another vendor. In my previous posts I&rsquo;ve used <a href="/blog/2016/04/18/os-unl-lab/">Cisco</a> and <a href="/blog/2016/05/11/neutron-routed-extnet/">Arista</a> switches to build a 4-leaf 2-spine CLOS fabric. For this task I&rsquo;ve decided to use a Cumulus VX switch which I&rsquo;ve <a href="https://cumulusnetworks.com/cumulus-vx/">downloaded</a> and imported into my lab.</p>

<p><img class="center" src="/images/neutron-l2gw-overview.png"></p>

<p>To simulate the baremetal server (10.0.0.100) I&rsquo;ve VRF&rsquo;d an interface on Arista &ldquo;L4&rdquo; switch and connected it directly to a &ldquo;swp3&rdquo; interface of the Cumulus VX. This is not shown on the diagram.</p>

<h2>Solution overview</h2>

<p><a href="https://wiki.openstack.org/wiki/Neutron/L2-GW">L2 Gateway</a> is a relatively <a href="https://github.com/openstack/networking-l2gw/releases">new</a> service plugin for OpenStack Neutron.  It provides the ability to interconnect a given tenant network with a VLAN on a physical switch. There are three main components that compose this solution:</p>

<ul>
<li><strong>Hardware switch</strong> implementing the OVSDB hardware vtep schema. This is a special &ldquo;flavour&rdquo; of OVSDB designed specifically to enable connectivity between logical (VXLAN VTEP) and physical (switchport) interfaces.</li>
<li><strong>L2GW agent</strong> running on a network node. This is the process responsible for connecting to OVSDB server running on a hardware switch and updating that database based on instructions received from a L2GW service plugin.</li>
<li><strong>L2GW Service Plugin</strong> residing on a control node. The task of this plugin is to notify the L2GW agent and normal L2 OVS agents running on compute hosts about network events and distribute VTEP IP address information between them.</li>
</ul>


<p>Note that in our case both network and control nodes are running on the same VM.</p>

<h2>Cumulux VX configuration</h2>

<p>Cumulux is a debian-based linux distribution, therefore most of the basic networking configuration will be similar to how things are done in Ubuntu. First, let&rsquo;s start by configuring basic IP addressing on Loopback (VTEP IP), Eth0 (OOB management), swp1 and swp2 (fabric) interfaces.</p>

<pre><code class="bash /etc/network/interfaces">iface lo inet loopback
        address 10.0.0.5/32

auto eth0
iface eth0 inet static
        address 192.168.91.21/24

auto swp1
iface swp1 inet static
        address 169.254.51.5/24

auto swp2
iface swp2 inet static
        address 169.254.52.5/24

auto swp3
iface swp3
</code></pre>

<p>Next, let&rsquo;s enable OSPF</p>

<pre><code class="bash Enable OSPF process">sudo sed -i s/zebra=no/zebra=yes/ /etc/quagga/daemons
sudo sed -i s/ospfd=no/ospfd=yes/ /etc/quagga/daemons
sudo service quagga restart
</code></pre>

<p>Once OSPFd is running, we can use <code>sudo vtysh</code> to connect to local quagga shell and finalise the configuration.</p>

<pre><code class="bash show run">interface lo
 ip ospf area 0.0.0.0
 link-detect
!
interface swp1
 ip ospf area 0.0.0.0
 ip ospf network point-to-point
 link-detect
!
interface swp2
 ip ospf area 0.0.0.0
 ip ospf network point-to-point
 link-detect
!
router ospf
 ospf router-id 10.0.0.5
 passive-interface default
 no passive-interface swp1
 no passive-interface swp2
</code></pre>

<p>At this stage our Cumulus VX switch should be fully adjacent to both spines and its loopback IP (10.0.0.5) should be reachable from all OpenStack nodes.</p>

<p>The final step is to enable the hardware VTEP functionality. The <a href="https://docs.cumulusnetworks.com/display/CL22/Integrating+Hardware+VTEPs+with+Midokura+MidoNet+and+OpenStack">process</a> is fairly simple and involves only a few commands.</p>

<pre><code class="bash">$ sudo sed -i s/START=no/START=yes/g /etc/default/openvswitch-vtep
$ sudo service openvswitch-vtep start
$ sudo vtep-bootstrap L5 10.0.0.5 192.168.91.21 --no_encryption
</code></pre>

<p>The last command runs a bootstrap script that does the following things:</p>

<ul>
<li>Creates a hardware VTEP OVSDB schema</li>
<li>Inside that schema creates a new physical switch called &ldquo;L5&rdquo;</li>
<li>Sets the VTEP IP to 10.0.0.5</li>
<li>Starts listening to incoming OVSDB connections on 192.168.91.21</li>
</ul>


<h2>Hardware VTEP vs OpenvSwitch OVSDB schemas (Optional)</h2>

<p>By now you&rsquo;re probably wondering what&rsquo;s that hardware VTEP OVSDB schema and how it&rsquo;s different from a normal OVS schema. First of all, remember that <a href="https://tools.ietf.org/html/rfc7047">OVSDB</a> is just a database and OVSDB protocol is just a set of JSON RPC calls to work with that database. Information that can be stored in the database is defined by a schema - a structure that represents tables and their relations. Therefore, OVSDB can be used to store and manage <a href="https://twitter.com/ben_pfaff/status/453333818653417472">ANY</a> type of data which makes it very flexible. Specificallly OVS project defines two OVSDB schemas:</p>

<ul>
<li><strong><a href="http://openvswitch.org/ovs-vswitchd.conf.db.5.pdf">Open_vSwitch schema</a></strong> - used to manage bridges, ports and controllers of OpenvSwitch. This schema is used by OVS inside every compute host we have in our OpenStack environment.</li>
<li><strong><a href="http://openvswitch.org/docs/vtep.5.pdf">Hardware_vtep schema</a></strong> - designed to be used by physical switches. The goal of this schema is to extend the virtual L2 switch into a physical realm by providing the ability to map physical ports to logical networks. For each logical network the hardware VTEP database holds mappings of MAC addresses to VTEPs and physical switchport.</li>
</ul>


<p>The information from these databases is later consumed by another process that sets up the actual bridges and ports. The first schema is used by the <strong>ovs-vswitchd</strong> process running on all compute hosts to configure ports and flows of integration and tunnel bridges. In case of a Cumulus switch, the information from <strong>hardware_vtep</strong> OVSDB is used by a process called <strong>ovs-vtepd</strong> that is responsible for settings up VXLAN VTEP interfaces, provisioning of VLANs on physical switchports and interconnecting them with a Linux bridge.</p>

<p>If you want to learn more, check out this <a href="http://www.relaxdiego.com/2014/09/hardware_vtep.html">awesome post</a> about hardware VTEP and OVS.</p>

<h2>OpenStack Control node configuration</h2>

<p>Most of the following procedure has been borrowed from <a href="http://kimizhang.com/neutron-l2-gateway-hp-5930-switch-ovsdb-integration/">another blog</a>. It&rsquo;s included it this post because I had to do some modifications and also for the sake of completeness.</p>

<ol>
<li><p>Clone the L2GW repository</p>

<pre><code class="`"> git clone -b stable/mitaka https://github.com/openstack/networking-l2gw.git
</code></pre></li>
<li><p>Use pip to install the plugin</p>

<pre><code class="`"> pip install ./networking-l2gw/
</code></pre></li>
<li><p>Enable the L2GW service plugin</p>

<pre><code class="`"> sudo sed -ri 's/^(service_plugins.*)/\1,networking_l2gw.services.l2gateway.plugin.L2GatewayPlugin/' \
 /etc/neutron/neutron.conf
</code></pre></li>
<li><p>Copy L2GW configuration files into the neutron configuration directory</p>

<pre><code class="`"> cp  /usr/etc/neutron/l2g* /etc/neutron/
</code></pre></li>
<li><p>Point the L2GW plugin to our Cumulus VX switch</p>

<pre><code class="`"> sudo sed -ri "s/^#\s+(ovsdb_hosts).*/\1 = 'ovsdb1:192.168.91.21:6632'/" /etc/neutron/l2gateway_agent.ini
</code></pre></li>
<li><p>Update Neutron database with the new schema required by L2GW plugin</p>

<pre><code class="`"> systemctl stop neutron-server
 neutron-db-manage --config-file /etc/neutron/neutron.conf --config-file /etc/neutron/l2gw_plugin.ini  upgrade head
 systemctl start neutron-server
</code></pre></li>
<li><p>Update Neutron startup script to load the L2GW plugin configuration file</p>

<pre><code class="`"> sed -ri "s/(ExecStart=.*)/\1 --config-file \/etc\/neutron\/l2gw_plugin.ini /" /usr/lib/systemd/system/neutron-server.service
</code></pre></li>
<li><p>Create a L2GW systemd unit file</p>

<pre><code class="`"> cat &gt;&gt; /usr/lib/systemd/system/neutron-l2gateway-agent.service &lt;&lt; EOF
 [Unit]
 Description=OpenStack Neutron L2 Gateway Agent
 After=neutron-server.service

 [Service]
 Type=simple
 User=neutron
 ExecStart=/usr/bin/neutron-l2gateway-agent --config-file /etc/neutron/neutron.conf --config-file /etc/neutron/l2gateway_agent.ini
 KillMode=process

 [Install]
 WantedBy=multi-user.target
 EOF
</code></pre></li>
<li><p>Restart both L2GW and neutron server</p>

<pre><code class="`"> systemctl daemon-reload
 systemctl restart neutron-server.service
 systemctl start neutron-l2gateway-agent.service  
</code></pre></li>
<li><p>Enter the &ldquo;neutron configuration mode&rdquo;</p>

<pre><code>source ~/keystone_admin
neutron
</code></pre></li>
<li><p>Create a new L2 gateway device</p>

<pre><code>l2-gateway-create --device name="L5",interface_names="swp3" CUMULUS-L2GW
</code></pre></li>
<li><p>Create a connection between a &ldquo;private_network&rdquo; and a native vlan (dot1q 0) of swp3 interface</p>

<pre><code>l2-gateway-connection-create --default-segmentation-id 0 CUMULUS-L2GW private_network
</code></pre></li>
</ol>


<h2>Verification and Traffic Flows</h2>

<p>At this stage everything should be ready for testing. We&rsquo;ll start by examining the following traffic flow:</p>

<ul>
<li>From VM-2 10.0.0.4/fa:16:3e:d7:0e:14</li>
<li>To baremetal server 10.0.0.100/50:00:00:6b:2e:70</li>
</ul>


<p><img class="center" src="/images/neutron-l2gw-detailed.png"></p>

<p>The communication starts with VM-2 sending an ARP request for the MAC address of the baremetal server. Packet flow inside the compute host will be exactly the same <a href="/blog/2016/04/22/neutron-native/">as before</a>, with packet being flooded from the VM to the integration and tunnel bridges. Inside the tunnel bridge the packet gets resubmitted to table 22 where head-end replication of ARP request takes place.</p>

<p>The only exception is that this time the frame will get replicated to a new VXLAN port pointing towards the Cumulux VTEP IP. We&rsquo;ll use the <code>ovs-appctl ofproto/trace</code> command to see the full path a packet takes inside OVS, which is similar to <code>packet-tracer</code> command of Cisco ASA. To simulate an ARP packet we need to specify the incoming port(in_port), EtherType(arp), internal VLAN number for our tenant(dl_vlan) and an ARP request target IP address(arp_tpa). You can find the full list of fields that can be matched in <a href="http://openvswitch.org/support/dist-docs/ovs-ofctl.8.txt">this document</a>.</p>

<pre><code class="bash ARP request to the baremetal server">$ ovs-appctl ofproto/trace br-tun in_port=1,arp,dl_vlan=1,arp_tpa=10.0.0.100 | grep -E "Rule|actions="
Rule: table=0 cookie=0xb3c018296c2aa8a3 priority=1,in_port=1
OpenFlow actions=resubmit(,2)
        Rule: table=2 cookie=0xb3c018296c2aa8a3 priority=0,dl_dst=00:00:00:00:00:00/01:00:00:00:00:00
        OpenFlow actions=resubmit(,20)
                Rule: table=20 cookie=0xb3c018296c2aa8a3 priority=0
                OpenFlow actions=resubmit(,22)
                        Rule: table=22 cookie=0xb3c018296c2aa8a3 dl_vlan=1
                        OpenFlow actions=strip_vlan,set_tunnel:0x45,output:9,output:4,output:6
</code></pre>

<p>The packet leaving port 9 will get encapsulated into a VXLAN header with destination IP of 10.0.0.5 and forwarded out the fabric-facing interface eth1.100. When VXLAN packet reaches the <strong>vxln69</strong> interface (10.0.0.5) of the Cumulus switch, the <strong>br-vxlan69</strong> Linux bridge floods the frame out the second connected interface - <strong>swp3</strong>.</p>

<pre><code class="bash brctl show br-vxln69">bridge name        bridge id          STP enabled     interfaces
br-vxln69          8000.500000070003  no              swp3
                                                      vxln69
</code></pre>

<p>The rest of the story is very simple. When ARP packet hits the baremetal server it populates its ARP cache. A unicast response travels all the way back to the Cumulus switch, gets matched by the static MAC (0e:14) entry created based on information provided by the L2GW plugin. This entry points to the VTEP IP of Compute host 2(10.0.2.10) which is where it gets forwarded next.</p>

<pre><code class="bash bridge fdb show">50:00:00:09:00:04 dev swp3 vlan 0 master br-vxln69
50:00:00:07:00:03 dev swp3 vlan 0 master br-vxln69 permanent
50:00:00:6b:2e:70 dev swp3 vlan 0 master br-vxln69
26:21:90:a8:8a:cc dev vxln69 vlan 0 master br-vxln69 permanent
fa:16:3e:57:1c:6c dev vxln69 dst 10.0.3.10 vlan 65535 self permanent
fa:16:3e:a4:12:e6 dev vxln69 dst 10.0.3.10 vlan 65535 self permanent
fa:16:3e:d7:0e:14 dev vxln69 dst 10.0.2.10 vlan 65535 self permanent
fa:16:3e:3c:51:d7 dev vxln69 dst 10.0.1.10 vlan 65535 self permanent
</code></pre>

<p>The packet travels through compute host 2, populating the flow entries of all OVS bridges along the way. These entries are then used by subsequent unicast packets travelling from VM-2.</p>

<pre><code class="bash Unicast packet to the baremetal server">$ ovs-appctl ofproto/trace br-tun in_port=1,dl_vlan=1,dl_dst=50:00:00:6b:2e:70 | grep -E "Rule|actions="
Rule: table=0 cookie=0xb5625033061a8ae5 priority=1,in_port=1
OpenFlow actions=resubmit(,2)
        Rule: table=2 cookie=0xb5625033061a8ae5 priority=0,dl_dst=00:00:00:00:00:00/01:00:00:00:00:00
        OpenFlow actions=resubmit(,20)
                Rule: table=20 cookie=0xb5625033061a8ae5 priority=1,vlan_tci=0x0001/0x0fff,dl_dst=50:00:00:6b:2e:70
                OpenFlow actions=load:0-&gt;NXM_OF_VLAN_TCI[],load:0x45-&gt;NXM_NX_TUN_ID[],output:9
</code></pre>

<p>It all looks fine until the ARP cache of the baremetal server expires and you get an ARP request coming from the physical into the virtual world. There is a <a href="https://drive.google.com/file/d/0Bx8nDIFktlzBRm0tV3pmYURnZ3M/view">known issue</a> with BUM forwarding which requires a special <a href="http://blog.scottlowe.org/2014/02/27/learning-nsx-part-10-adding-a-service-node/">service node</a> to perform the head-end replication. The idea is that a switch that needs to flood a multicast packet, would send it to a service node which keeps track of all active VTEPs in the network and performs packet replication on behalf of the sender. OpenStack doesn&rsquo;t have a dedicated service node, however it is possible to trick the network node into performing a similar functionality, which is what I&rsquo;m going to demonstrate next.</p>

<h2>Programming Network Node as BUM replication service node</h2>

<p>First of all, we need to tell our Cumulus switch to send all multicast packets to the network node. To do that we need to modify OVSDB table called &ldquo;Mcast_Macs_Remote&rdquo;. You can view the contents of the database using the <code>ovsdb-client dump --pretty tcp:192.168.91.21:6632</code> command to make sure that this table is empty. Using the VTEP control command we need to force all <strong>unknown-dst</strong> (BUM) traffic to go to the network node(10.0.3.10). The UUID of the logical switch can be found with <code>sudo vtep-ctl list-ls</code> command.</p>

<pre><code class="bash Forward all BUM traffic to OpenStack network node">sudo vtep-ctl add-mcast-remote 818b4779-645c-49bb-ae4a-aa9340604019 unknown-dst 10.0.3.10
</code></pre>

<p>At this stage all BUM traffic hits the network node and gets flooded to the DHCP and the virtual router namespaces. In order to force this traffic to also be replicated to all compute nodes we can use some of the existing tables of the tunnel bridge. Before we do anything let&rsquo;s have a look at the tables our ARP request has to go through inside the tunnel bridge.</p>

<pre><code class="bash Packet from Cumulus VTEP inside br-tun">table=0, priority=1,in_port=2 actions=resubmit(,4)
table=4, priority=1,tun_id=0x45 actions=mod_vlan_vid:1,resubmit(,10)
table=10,priority=1 actions=learn(table=20,hard_timeout=300,priority=1,cookie=0x9f3e746b7ee48bbf,NXM_OF_VLAN_TCI[0..11],NXM_OF_ETH_DST[]=NXM_OF_ETH_SRC[],load:0-&gt;NXM_OF_VLAN_TCI[],load:NXM_NX_TUN_ID[]-&gt;NXM_NX_TUN_ID[],output:NXM_OF_IN_PORT[]),output:1
</code></pre>

<p>We also have a default head-end replication table 22 which floods all BUM traffic received from the integration bridge to all VTEPs:</p>

<pre><code class="bash BUM replication table">table=22, dl_vlan=1 actions=strip_vlan,set_tunnel:0x45,output:2,output:4,output:6
</code></pre>

<p>So what we can do is create a new flow entry that would intercept all ARP packets inside Table 4 and resubmit them to tables 10 and 22. Table 10 will take our packet up to the integration bridge of the network node, since we still need to be able to talk the virtual router and the DHCP. Table 22 will receive a copy of the packet and flood it to all known VXLAN endpoints.</p>

<pre><code class="bash Manipulating OVS flows">ovs-ofctl add-flow br-tun "table=4,arp,tun_id=0x45,priority=2,actions=mod_vlan_vid:1,resubmit(,10),resubmit(,22)"
</code></pre>

<p>We can once again use the trace command to see the ARP request flow inside the tunnel bridge.</p>

<pre><code class="bash ARP request received from the Cumulus switch">$ ovs-appctl ofproto/trace br-tun in_port=2,arp,tun_id=0x45 | grep -E "Rule|actions="
Rule: table=0 cookie=0x9f3e746b7ee48bbf priority=1,in_port=2
OpenFlow actions=resubmit(,4)
        Rule: table=4 cookie=0 priority=2,arp,tun_id=0x45
        OpenFlow actions=mod_vlan_vid:1,resubmit(,10),resubmit(,22)
                Rule: table=10 cookie=0x9f3e746b7ee48bbf priority=1
                OpenFlow actions=learn(table=20,hard_timeout=300,priority=1,cookie=0x9f3e746b7ee48bbf,NXM_OF_VLAN_TCI[0..11],NXM_OF_ETH_DST[]=NXM_OF_ETH_SRC[],load:0-&gt;NXM_OF_VLAN_TCI[],load:NXM_NX_TUN_ID[]-&gt;NXM_NX_TUN_ID[],output:NXM_OF_IN_PORT[]),output:1
                        Rule: table=0 cookie=0x91b1a9a9b6e8d608 priority=0
                        OpenFlow actions=NORMAL
                                Rule: table=0 cookie=0xb36f6e358a37bea6 priority=2,in_port=2
                                OpenFlow actions=drop
                Rule: table=22 cookie=0x9f3e746b7ee48bbf dl_vlan=1
                OpenFlow actions=strip_vlan,set_tunnel:0x45,output:2,output:4,output:6
</code></pre>

<p><img class="center" src="/images/neutron-l2gw-arp.png"></p>

<p>Now we should be able to clear the ARP cache on baremetal device and successfully ping both VM-2, VM-1 and the virtual router.</p>

<h2>Conclusion</h2>

<p>The workaround presented above is just a temporary solution for the problem. In order to fix the problem properly, OVS vtep schema needs to be updated to support source node replication. Luckily, the patch implementing this functionality has been <a href="https://github.com/openvswitch/ovs/commit/b351ac0c9bc270b3fff07ae8c7434c53d59b132c">merged</a> into master OVS branch only a few days ago. So hopefully, this update trickles down to Cumulus package repositories soon.</p>

<p>Despite all the issues, Neutron L2 gateway plugin is a cool project that provides a very important piece of functionality without having to rely on 3rd party SDN controllers. Let&rsquo;s hope it will continue to be supported and developed by the community.</p>

<h2>Coming up</h2>

<p>In the next post I was planning to examine another &ldquo;must have&rdquo; feature of any SDN solution - Distributed Virtual Routing. However due to my current circumstances I may need to take a few weeks' break before going on. Be back soon!</p>

<p><img class="center" src="/images/be-back.jpg"></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Openstack SDN - Extending a L2 Provider Network Over a L3 Fabric]]></title>
    <link href="http://networkop.github.io/blog/2016/05/11/neutron-routed-extnet/"/>
    <updated>2016-05-11T00:00:00-07:00</updated>
    <id>http://networkop.github.io/blog/2016/05/11/neutron-routed-extnet</id>
    <content type="html"><![CDATA[<p>In the this post we&rsquo;ll tackle yet another Neutron scalability problem identified in my <a href="http://networkop.github.io/blog/2016/04/22/neutron-native/">earlier post</a> - a requirement to have a direct L2 adjacency between the external provider network and the network node.</p>

<!--more-->


<h2>Provider vs Tenant networks</h2>

<p>Before we start, let&rsquo;s recap the difference between the <a href="http://docs.openstack.org/mitaka/networking-guide/intro-os-networking-overview.html">two major</a> Neutron network types:</p>

<ul>
<li>Tenant networks are:

<ul>
<li>provisioned by tenants</li>
<li>used for inter-VM (east-west) communication</li>
<li>use Neutron virtual router as their default gateway</li>
</ul>
</li>
<li>Provider networks are:

<ul>
<li>provisioned by OpenStack administrator(for use by tenants)</li>
<li>match existing physical networks</li>
<li>can be either flat (untagged VLAN) or VLAN-based (multiple VLANs)</li>
<li>need to be L2 adjacent to network and/or compute nodes</li>
</ul>
</li>
</ul>


<p>These two network types are not mutually exclusive. In our case the <strong>admin tenant</strong> network is implemented as a VXLAN-based overlay whose only requirement is to have a layer-3 reachability in the underlay. However tenant network could also have been implemented using a VLAN-based provider network in which case a set of dot1Q tags pre-provisioned in the underlay would have been used for tenant network segregation.</p>

<h2>External provider network</h2>

<p>External network is used by VMs to communicate with the outside world (north-south). Since default gateway is located outside of OpenStack environment this, by definition, is a provider network. Normally, tenant networks will use the non-routable address space and will rely on a Neutron virtual router to perform some form of NAT translation. As we&rsquo;ve seen in the <a href="http://networkop.github.io/blog/2016/04/22/neutron-native/">earlier post</a>, Neutron virtual router is directly connected to the external bridge which allows it to &ldquo;borrow&rdquo; ip address from the external provider network to use for two types of NAT operations:</p>

<ul>
<li>SNAT - a source-based port address translation performed by the Neutron virtual router</li>
<li>DNAT - a static NAT created for every <a href="https://www.rdoproject.org/networking/difference-between-floating-ip-and-private-ip/">floating ip address</a> configured for a VM</li>
</ul>


<p>In default deployments all NATing functionality is performed by a network node, so external provider network only needs to be L2 adjacent with a limited number of physical hosts. In deployments where <abbr title=" Distributed Virtual Router">DVR</abbr> is used, the virtual router and NAT functionality gets distributed among all compute hosts which means that they, too, now need to be layer-2 adjacent to the external network.</p>

<h2>Solutions overview</h2>

<p>The direct adjacency requirement presents a big problem for deployments where layer-3 routed underlay is used for the tenant networks. There is a limited number of ways to satisfy this requirements, for example:</p>

<ul>
<li>Span a L2 segment across the whole DC fabric. This means that the fabric needs to be converted to layer-2, reintroducing spanning-tree and all the unique vendor solutions to overcome STP limitations(e.g. TRILL, Fabripath, SPB).</li>
<li>Build a dedicated physical network. This may not always be feasible, especially considering that it needs to be delivered to all compute hosts.</li>
<li>Extend the provider network over an existing L3 fabric with VXLAN overlay. This can easily be implemented with just a few commands, however it requires a border leaf switch capable of performing VXLAN-VLAN translation.</li>
</ul>


<h2>Detailed design</h2>

<p>As I&rsquo;ve said in my <a href="http://networkop.github.io/blog/2016/04/18/os-unl-lab/">earlier post</a>, I&rsquo;ve built the leaf-spine fabric out of Cisco IOU virtual switches, however the plan was to start introducing other vendors later in the series. So this time for the border leaf role I&rsquo;ve chosen Arista vEOS switch, however, technically, it could have been any other vendor capable of doing VXLAN-VLAN bridging (e.g. any hardware switch with <a href="http://blog.ipspace.net/2014/06/trident-2-chipset-and-nexus-9500.html">Trident 2</a> or similar ASIC).</p>

<p><img class="center" src="/images/neutron-extnet-l3.png"></p>

<h3>Arista vEOS configuration</h3>

<p>Configuration of Arista switches is very similar to Cisco IOS. In fact, I was able to complete all interface and OSPF routing configuration only with the help of CLI context help. The only bit that was new to me and that I had to lookup in the official guide was the <a href="https://eos.arista.com/vxlan-with-mlag-configuration-guide/">VXLAN configuration</a>. These similarities makes the transition from Cisco to Arista very easy and I can understand (but not approve!) why Cisco would file a lawsuit against Arista for copying its &ldquo;industry-standard CLI&rdquo;.</p>

<pre><code class="text L4 configuration">interface Ethernet1
   description SPINE-1:Eth0/3
   no switchport
   ip address 169.254.41.4/24
   ip ospf network point-to-point
!
interface Ethernet2
   description SPINE-2:Eth0/3
   no switchport
   ip address 169.254.42.4/24
   ip ospf network point-to-point
!
interface Ethernet3
   description VM-HOST-ONLY:PNET1
   switchport access vlan 100
   spanning-tree portfast
!
interface Loopback0
   ip address 10.0.0.4/32
!
interface Vxlan1
   vxlan source-interface Loopback0
   vxlan udp-port 4789
   vxlan vlan 100 vni 1000
   vxlan vlan 100 flood vtep 10.0.3.10
!
router ospf 1
   router-id 10.0.0.4
   passive-interface default
   no passive-interface Ethernet1
   no passive-interface Ethernet2
   network 0.0.0.0/0 area 0.0.0.0
!
</code></pre>

<p>Interface VXLAN1 sets up VXLAN-VLAN bridging between VNI 1000 and VLAN 100. VLAN 100 is used to connect to VMware Workstation&rsquo;s host-only interface, the one that was <a href="http://networkop.github.io/blog/2016/04/18/os-unl-lab/">previously</a> connected directly to the L3 leaf switch. VXLAN interface does the multicast source replication by flooding unknown packets over the layer 3 fabric to the network node (10.0.3.10).</p>

<h3>OpenStack network node configuration</h3>

<p>Since we don&rsquo;t yet have the distributed routing feature enabled, the only OpenStack component that requires any changes is the network node. First, let&rsquo;s remove the physical interface from the external bridge, since it will no longer be used to connect to the external provider network.</p>

<pre><code class="bash Remove the physical interface from the external bridge">$ ovs-vsctl del-port br-ex eth1.300
</code></pre>

<p>Next let&rsquo;s add the VXLAN interface towards the Loopback IP address of the Arista border leaf switch. The key option sets the VNI which must be equal to the VNI defined on the border leaf.</p>

<pre><code class="bash add the VXLAN interface towards the Arista switch">$ ovs-vsctl add-port br-ex vxlan1 \
-- set interface vxlan1 \
type=vxlan \
options:remote_ip=10.0.0.4 \
options:key=1000
</code></pre>

<p>Without any physical interfaces attached to the external bridge, the OVS will use the Linux network stack to find the outgoing interface. When a packet hits the <strong>vxlan1</strong> interface of the br-ex, it will get encapsulated in a VXLAN header and passed on to the OS network stack where it will follow the <a href="http://networkop.github.io/blog/2016/04/18/os-unl-lab/">pre-configured</a> static route forwarding all 10/8 traffic towards the leaf-spine fabric. Check out <a href="http://blog.scottlowe.org/2013/05/15/examining-open-vswitch-traffic-patterns/">this article</a> if you want to learn more about different types of interfaces and traffic forwarding behaviours in OpenvSwitch.</p>

<h3>Cleanup</h3>

<p>In order to make changes persistent and prevent the static interface configuration from interfering with OVS, remove all OVS-related configuration and shutdown interface eth1.300.</p>

<pre><code class="bash /etc/sysconfig/network-scripts/ifcfg-eth1.300">ONBOOT=no
VLAN=yes
</code></pre>

<h2>Change in the packet flow</h2>

<p>None of the packet flows have changed as the result of this modification. All VMs will still use NAT to break out of the private environment, the NAT&rsquo;d packets will reach the external bridge <strong>br-ex</strong> as described in my <a href="http://networkop.github.io/blog/2016/04/22/neutron-native/">earlier post</a>. However this time <strong>br-ex</strong> will forward the packets out the <strong>vxlan1</strong> port which will deliver them to the Arista switch over the same L3 fabric used for east-west communication.</p>

<p>If we did a capture on the fabric-facing interface <strong>eth1</strong> of the control node while running a ping from one of the VMs to the external IP address, we would see a VXLAN-encapsulated packet destined for the Loopback IP of L4 leaf switch.</p>

<p><img class="center" src="/images/neutron-provider-vxlan.png"></p>

<h2>Coming Up</h2>

<p>In the next post we&rsquo;ll examine the L2 gateway feature that allows tenant networks to communicate with physical servers through yet another VXLAN-VLAN hardware gateway.</p>
]]></content>
  </entry>
  
</feed>
