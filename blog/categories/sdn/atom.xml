<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: Sdn | Network-oriented programming]]></title>
  <link href="http://networkop.github.io/blog/categories/sdn/atom.xml" rel="self"/>
  <link href="http://networkop.github.io/"/>
  <updated>2017-11-23T12:21:53+00:00</updated>
  <id>http://networkop.github.io/</id>
  <author>
    <name><![CDATA[Michael Kashin]]></name>
    <email><![CDATA[mmkashin@gmail.com]]></email>
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Openstack SDN - NFV Management and Orchestration]]></title>
    <link href="http://networkop.github.io/blog/2017/11/23/os-nfv-mano/"/>
    <updated>2017-11-23T00:00:00+00:00</updated>
    <id>http://networkop.github.io/blog/2017/11/23/os-nfv-mano</id>
    <content type="html"><![CDATA[<p>In this post I&rsquo;ll have a brief look at the NFV MANO framework developed by ETSI and create a simple vIDS network service using Tacker.</p>

<!--more-->


<p>In the ongoing hysteria surrounding all things SDN, one important thing gets often overlooked. You don&rsquo;t build SDN for its own sake. SDN is just a little cog in a big machine called &ldquo;cloud&rdquo;. To take it even further, I would argue that the best SDN solution is the one that you don&rsquo;t know even exists. Despite what the big vendors tell you, operators are not supposed to interact with SDN interface, be it GUI or CLI. If you dig up some of the earliest presentation about Cisco ACI, when the people talking about it were the actual people who designed the product, you&rsquo;ll notice one common motif being repeated over and over again. That is that ACI was never designed for direct human interaction, but rather was supposed to be configured by a higher level orchestrating system. In data center environments such orchestrating system may glue together services of virtualization layer and SDN layer to provide a seamless &ldquo;cloud&rdquo; experience to the end users. The focus of this post will be one incarnation of such orchestration system, specific to SP/Telco world, commonly known as NFV MANO.</p>

<hr />

<h2>NFV MANO for Telco SDN</h2>

<p>At the early dawn of SDN/NFV era a lot of people got very excited by <strong>&ldquo;the promise&rdquo;</strong> and started applying the disaggregation and virtualization paradigms to all areas of networking. For Telcos that meant virtualizing network functions that built the service core of their networks - EPC, IMS, RAN. Traditionally those network functions were a collection of vertically-integrated baremetal appliances that took a long time to commission and had to be overprovisioned to cope with the peak-hour demand. Virtualizing them would have made it possible to achieve quicker time-to-market, elasticity to cope with a changing network demand and hardware/software disaggregation.</p>

<p>As expected however, such fundamental change has to come at price. Not only do Telcos get a new virtualization platform to manage but they also need to worry about lifecycle management and end-to-end orchestration (MANO) of VNFs. Since any such change presents an opportunity for new streams of revenue, it didn&rsquo;t take long for vendors to jump on the bandwagon and start working on a new architecture designed to address those issues.</p>

<p>The first problem was the easiest to solve since VMware and OpenStack already existed at that stage and could be used to host VNFs with very little modifications. The management and orchestration problem, however, was only partially solved by existing orchestration solutions. There were a lot of gaps between the current operational model and the new VNF world and although these problems could have been solved by Telcos engaging themselves with the open-source community, this proved to be too big of a change for them and they&rsquo;ve turned to the only thing they could trust - the standards bodies.</p>

<h2>ETSI MANO</h2>

<p>ETSI NFV MANO working group has set out to define a reference architecture for management and orchestration of virtualized resources in Telco data centers. The goal of NFV MANO initiative was to do a research into what&rsquo;s required to manage and orchestrate VNFs, what&rsquo;s currently available and identify potential gaps for other standards bodies to fill. Initial ETSI NFV Release 1 (2014) defined a base framework through relatively weak requirements and recommendations and was followed by Release 2 (2016) that made them more concrete by locking down the interfaces and data model specifications. For a very long time Release 1 was the only available NFV MANO standard, which led to a lot of inconsistencies in each vendors' implementations of it. This was very frustrating for Telcos since it required a lot of integration effort to build a multi-vendor MANO stack. Another potential issue with ETSI MANO standard is its limited scope - a lot of critical components like OSS and EMS are left outside of it which created a lot of confusion for Telcos and resulted in other standardisation efforts addressing those gaps.</p>

<p>On the below diagram I have shown an adbridged version of the original ETSI MANO <a href="https://www.ietf.org/proceedings/88/slides/slides-88-opsawg-6.pdf">reference architecture diagram</a> adapted to the use case I&rsquo;ll be demonstrating in this post.</p>

<p><img class="center" src="/images/etsi-mano.png"></p>

<p>This architecture consists of the following building blocks:</p>

<ul>
<li><strong>NFVI</strong> (NFV Infrastructure) - OpenStacks compute or VMware&rsquo;s ESXI nodes</li>
<li><strong>VIM</strong> (Virtual Infrastructure Manager) - OpenStack&rsquo;s controller/API or VMware&rsquo;s vCenter nodes</li>
<li><strong>VNFM</strong> (VNF Manager) - an element responsible for lifecycle management (create,delete,scale) and monitoring of VNFs</li>
<li><strong>NFVO</strong> (NFV Orchestrator) - an element responsible for lifecyle management of Network Services (described below)</li>
</ul>


<p>All these elements are working together towards a single goal - managing and orchestrating a Network Service (NS), which itself is comprised of multiple VNFs, Virtual Links (VLs), VNF Forwarding Graphs (VNFFGs) and Physical Network Functions (PNFs). In this post I create a NS for a simple virtual IDS use case, described in my previous <a href="/blog/2017/09/15/os-sfc-skydive/">SFC post</a>. The goal is to steer all ICMP traffic coming from VM1 through a vIDS VNF which will forward the traffic to its original destination.</p>

<p><img class="center" src="/images/vids-created.png"></p>

<p>Before I get to the implementation, let me give a quick overview of how a Network Service is build from its constituent parts, in the context of our vIDS use case.</p>

<h2>Relationship between NS, VNF and VNFFG</h2>

<p>According to ETSI MANO, a <strong>Network Service</strong> (NS) is a subset of end-to-end service implemented by VNFs and instantiated on the NFVI. As I&rsquo;ve mentioned before, some examples of a NS would be vEPC, vIMS or vCPE. NS can be described in either a YANG or a Tosca template called NS Descriptor (NSD). The main goal of a NSD is to tie together VNFs, VLs, VNFFGs and PNFs by defining relationship between various templates describing those objects (VNFDs, VLDs, VNFFGDs). Once NSD is onboarded (uploaded), it can be instantiated by NFVO, which communicates with VIM and VNFM to create the constituent components and stitch them together as described in a template. NSD normally does not contain VNFD or VNFFGD templates, but imports them through their names, which means that in order to instantiate a NSD, the corresponding VNFDs and VNFFGDs should already be onboarded.</p>

<p><img class="center" src="/images/vids-nsd.png"></p>

<p><strong>VNF Descriptor</strong> is a template describing the compute and network parameters of a single VNF. Each VNF consists of one or more VNF components (VNFCs), represented in Tosca as Virtual Deployment Units (VDUs). A VDU is the smallest part of a VNF and can be implemented as either a container or, as it is in our case, a VM. Apart from the usual set of parameters like CPU, RAM and disk, VNFD also describes all the virtual networks required for internal communication between VNFCs, called internal VLs. VNFM can ask VIM to create those networks when the VNF is being instantiated. VNFD also contains a reference to external networks, which are supposed to be created by NFVO. Those networks are used to connect different VNFs together or to connect VNFs to PNFs and other elements outside of NFVI platform. If external VLs are defined in a VNFD, VNFM will need to source them externally, either as input parameters to VNFM or from NFVO. In fact, VNF instantiation by VNFM, as described in Tacker <a href="https://docs.openstack.org/tacker/latest/user/vnfm_usage_guide.html">documentation</a>, is only used for testing purposes and since a VNF only makes sense as a part of a Network Service, the intended way is to use a NSD to instantiate all VNFs in production environment.</p>

<p>The final component that we&rsquo;re going to use is VNF Forwarding Graph. <strong>VNFFG Descriptor</strong> is an optional component that describes how different VNFs are supposed to be chained together to form a Network Service. In the absence of VNFFG, VNFs will fall back to the default destination-based forwarding, when the IPs of VNFs forming a NS are either automatically discovered (e.g. through DNS) or provisioned statically. Tacker&rsquo;s implementation of VNFFG is not fully integrated with NSD yet and VNFFGD has to be instantiated separately and, as will be shown below, linked to an already running instance of a Network Service through its ID.</p>

<h2>Using Tacker to orchestrate a Network Service</h2>

<p>Tacker is an OpenStack project implementing a generic VNFM and NFVO. At the input it consumes Tosca-based templates, converts them to Heat templates which are then used to spin up VMs on OpenStack. This diagram from Brocade, the biggest Tacker contributor (at least until its acquisition), is the best overview of internal Tacker architecture.</p>

<p><img class="center" src="/images/brocade-tacker.jpg"></p>

<p>For this demo environment I&rsquo;ll keep using my OpenStack Kolla lab environment described in my <a href="/blog/2017/09/08/os-lab-docker/">previous post</a>.</p>

<h3>Step 1 - VIM registration</h3>

<p>Before we can start using Tacker, it needs to know how to reach the OpenStack environment, so the first step in the workflow is OpenStack or VIM registration. We need to provide the address of the keystone endpoint along with the admin credentials to give Tacker enough rights to create and delete VMs and SFC objects:</p>

<p><figure class='code panel panel-default'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'>cat <span class="p">&amp;</span>lt<span class="p">;&amp;</span>lt<span class="p">;</span> EOF &gt; ./vim.yaml
</span><span class='line'>auth_url: <span class="p">&amp;</span>lsquo<span class="p">;</span>&lt;a <span class="nv">href</span><span class="o">=</span><span class="s2">&quot;http://192.168.133.254:35357/v3&quot;</span>&gt;http://192.168.133.254:35357/v3&lt;/a&gt;<span class="p">&amp;</span>rsquo<span class="p">;</span>
</span><span class='line'>username: <span class="p">&amp;</span>lsquo<span class="p">;</span>admin<span class="p">&amp;</span>rsquo<span class="p">;</span>
</span><span class='line'>password: <span class="p">&amp;</span>lsquo<span class="p">;</span>admin<span class="p">&amp;</span>rsquo<span class="p">;</span>
</span><span class='line'>project_name: <span class="p">&amp;</span>lsquo<span class="p">;</span>admin<span class="p">&amp;</span>rsquo<span class="p">;</span>
</span><span class='line'>project_domain_name: <span class="p">&amp;</span>lsquo<span class="p">;</span>Default<span class="p">&amp;</span>rsquo<span class="p">;</span>
</span><span class='line'>user_domain_name: <span class="p">&amp;</span>lsquo<span class="p">;</span>Default<span class="p">&amp;</span>rsquo<span class="p">;</span>
</span><span class='line'>EOF&lt;/p&gt;
</span><span class='line'>
</span><span class='line'>&lt;p&gt;tacker vim-register <span class="p">&amp;</span>ndash<span class="p">;</span>is-default <span class="p">&amp;</span>ndash<span class="p">;</span>config-file vim.yaml <span class="p">&amp;</span>ndash<span class="p">;</span>description MYVIM KOLLA-OPENSTACK
</span></code></pre></td></tr></table></div></figure></p>

<p>The successful result can be checked with <code>tacker vim-list</code> which should report that registered VIM is now reachable.</p>

<h3>Step 2 - Onboarding a VNFD</h3>

<p>VNFD defines a set of VMs (VNFCs), network ports (CPs) and networks (VLs) and their relationship. In our case we have a single cirros-based VM with a pair of ingress/egress ports. In this template we also define a special node type <code>tosca.nodes.nfv.vIDS</code> which will be used by NSD to pass the required parameters for ingress and egress VLs. These parameters are going to be used by VNFD to attach network ports (CPs) to virtual networks (VLs) as defined in the <code>substitution_mappings</code> section.</p>

<p><figure class='code panel panel-default'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
<span class='line-number'>38</span>
<span class='line-number'>39</span>
<span class='line-number'>40</span>
<span class='line-number'>41</span>
<span class='line-number'>42</span>
<span class='line-number'>43</span>
<span class='line-number'>44</span>
<span class='line-number'>45</span>
<span class='line-number'>46</span>
<span class='line-number'>47</span>
<span class='line-number'>48</span>
<span class='line-number'>49</span>
<span class='line-number'>50</span>
<span class='line-number'>51</span>
<span class='line-number'>52</span>
<span class='line-number'>53</span>
<span class='line-number'>54</span>
<span class='line-number'>55</span>
<span class='line-number'>56</span>
<span class='line-number'>57</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'>cat <span class="p">&amp;</span>lt<span class="p">;&amp;</span>lt<span class="p">;</span> EOF &gt; ./vnfd.yaml
</span><span class='line'>tosca_definitions_version: tosca_simple_profile_for_nfv_1_0_0
</span><span class='line'>description: Cirros vIDS example&lt;/p&gt;
</span><span class='line'>
</span><span class='line'>&lt;p&gt;node_types:
</span><span class='line'>  tosca.nodes.nfv.vIDS:
</span><span class='line'>    requirements:
</span><span class='line'>      - INGRESS_VL:
</span><span class='line'>          <span class="nb">type</span>: tosca.nodes.nfv.VL
</span><span class='line'>          required: <span class="nb">true</span>
</span><span class='line'>      - EGRESS_VL:
</span><span class='line'>          <span class="nb">type</span>: tosca.nodes.nfv.VL
</span><span class='line'>          required: <span class="nb">true</span>&lt;/p&gt;
</span><span class='line'>
</span><span class='line'>&lt;p&gt;topology_template:
</span><span class='line'>  substitution_mappings:
</span><span class='line'>    node_type: tosca.nodes.nfv.vIDS
</span><span class='line'>    requirements:
</span><span class='line'>      INGRESS_VL: <span class="o">[</span>CP1, virtualLink<span class="o">]</span>
</span><span class='line'>      EGRESS_VL:  <span class="o">[</span>CP2, virtualLink<span class="o">]</span>&lt;/p&gt;
</span><span class='line'>
</span><span class='line'>&lt;p&gt;  node_templates:
</span><span class='line'>    VDU1:
</span><span class='line'>      <span class="nb">type</span>: tosca.nodes.nfv.VDU.Tacker
</span><span class='line'>      properties:
</span><span class='line'>        availability_zone: nova
</span><span class='line'>        flavor: m1.nano
</span><span class='line'>        image: cirros
</span><span class='line'>        mgmt_driver: noop
</span><span class='line'>        user_data_format: RAW
</span><span class='line'>        user_data: <span class="p">|</span>
</span><span class='line'>          <span class="c">#!/bin/sh</span>
</span><span class='line'>          sudo cirros-dhcpc up eth1
</span><span class='line'>          sudo ip rule add iif eth0 table default
</span><span class='line'>          sudo ip route add default via 10.0.0.1 dev eth1 table default
</span><span class='line'>          sudo sysctl -w net.ipv4.ip_forward<span class="o">=</span>1&lt;/p&gt;
</span><span class='line'>
</span><span class='line'>&lt;pre&gt;&lt;code&gt;CP1:
</span><span class='line'>  <span class="nb">type</span>: tosca.nodes.nfv.CP.Tacker
</span><span class='line'>  properties:
</span><span class='line'>    anti_spoofing_protection: <span class="nb">false</span>
</span><span class='line'><span class="nb">  </span>requirements:
</span><span class='line'>    - virtualBinding:
</span><span class='line'>        node: VDU1
</span><span class='line'>
</span><span class='line'>CP2:
</span><span class='line'>  <span class="nb">type</span>: tosca.nodes.nfv.CP.Tacker
</span><span class='line'>  properties:
</span><span class='line'>    anti_spoofing_protection: <span class="nb">false</span>
</span><span class='line'><span class="nb">  </span>requirements:
</span><span class='line'>    - virtualBinding:
</span><span class='line'>        node: VDU1
</span><span class='line'>&lt;/code&gt;&lt;/pre&gt;
</span><span class='line'>
</span><span class='line'>&lt;p&gt;EOF&lt;/p&gt;
</span><span class='line'>
</span><span class='line'>&lt;p&gt;tacker vnfd-create <span class="p">&amp;</span>ndash<span class="p">;</span>vnfd-file vnfd.yaml vIDS-TEMPLATE
</span></code></pre></td></tr></table></div></figure></p>

<h3>Step 4 - Onboarding a NSD</h3>

<p>In our use case the NSD template is going to really small. All what we need to define is a single VNF of the <code>tosca.nodes.nfv.vIDS</code> type that was defined previously in the VNFD. We also define a VL node which points to the pre-existing <code>demo-net</code> virtual network and pass this VL to both INGRESS_VL and EGRESS_VL parameters of the VNFD.</p>

<p><figure class='code panel panel-default'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'>cat <span class="p">&amp;</span>lt<span class="p">;&amp;</span>lt<span class="p">;</span> EOF &gt; ./nsd.yaml
</span><span class='line'>tosca_definitions_version: tosca_simple_profile_for_nfv_1_0_0
</span><span class='line'>imports:
</span><span class='line'>  - vIDS-TEMPLATE&lt;/p&gt;
</span><span class='line'>
</span><span class='line'>&lt;p&gt;topology_template:
</span><span class='line'>  node_templates:
</span><span class='line'>    vIDS:
</span><span class='line'>      <span class="nb">type</span>: tosca.nodes.nfv.vIDS
</span><span class='line'>      requirements:
</span><span class='line'>        - INGRESS_VL: VL1
</span><span class='line'>        - EGRESS_VL: VL1
</span><span class='line'>    VL1:
</span><span class='line'>      <span class="nb">type</span>: tosca.nodes.nfv.VL
</span><span class='line'>      properties:
</span><span class='line'>          network_name: demo-net
</span><span class='line'>          vendor: tacker
</span><span class='line'>EOF&lt;/p&gt;
</span><span class='line'>
</span><span class='line'>&lt;p&gt;tacker nsd-create <span class="p">&amp;</span>ndash<span class="p">;</span>nsd-file nsd.yaml NSD-vIDS-TEMPLATE
</span></code></pre></td></tr></table></div></figure></p>

<h3>Step 5 - Instantiating a NSD</h3>

<p>As I&rsquo;ve mentioned before, VNFFG is not integrated with NSD yet, so we&rsquo;ll add it later. For now, we have provided enough information to instantiate our NSD.</p>

<p><figure class='code panel panel-default'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'>tacker ns-create <span class="p">&amp;</span>ndash<span class="p">;</span>nsd-name NSD-vIDS-TEMPLATE NS-vIDS-1
</span></code></pre></td></tr></table></div></figure></p>

<p>This last command creates a cirros-based VM with two interfaces and connects them to <code>demo-net</code> virtual network. All ICMP traffic from VM1 still goes directly to its default gateway so the last thing we need to do is create a VNFFG.</p>

<h3>Step 6 - Onboarding and Instantiating a VNFFG</h3>

<p>VNFFG consists of two two types of nodes. The first type defines a Forwarding Path (FP) as a set of virtual ports (CPs) and a flow classifier to build an equivalent service function chain inside the VIM. The second type groups multiple forwarding paths to build a complex service chain graphs, however only one FP is supported by Tacker at the time of writing.</p>

<p>The following template demonstrates another important feature - template parametrization. Instead of defining all parameters statically in a template, they can be provided as inputs during instantiation, which allows to keep templates generic. In this case I&rsquo;ve replaced the network port id parameter with <code>PORT_ID</code> variable which will be provided during VNFFGD instantiation.</p>

<p><figure class='code panel panel-default'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
<span class='line-number'>38</span>
<span class='line-number'>39</span>
<span class='line-number'>40</span>
<span class='line-number'>41</span>
<span class='line-number'>42</span>
<span class='line-number'>43</span>
<span class='line-number'>44</span>
<span class='line-number'>45</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'>cat <span class="p">&amp;</span>lt<span class="p">;&amp;</span>lt<span class="p">;</span> EOF &gt; ./vnffg.yaml
</span><span class='line'>tosca_definitions_version: tosca_simple_profile_for_nfv_1_0_0&lt;/p&gt;
</span><span class='line'>
</span><span class='line'>&lt;p&gt;description: vIDS VNFFG tosca&lt;/p&gt;
</span><span class='line'>
</span><span class='line'>&lt;p&gt;topology_template:
</span><span class='line'>  inputs:
</span><span class='line'>    PORT_ID:
</span><span class='line'>      <span class="nb">type</span>: string
</span><span class='line'>      description: Port ID of the target VM&lt;/p&gt;
</span><span class='line'>
</span><span class='line'>&lt;p&gt;  node_templates:&lt;/p&gt;
</span><span class='line'>
</span><span class='line'>&lt;pre&gt;&lt;code&gt;Forwarding_Path-1:
</span><span class='line'>  <span class="nb">type</span>: tosca.nodes.nfv.FP.Tacker
</span><span class='line'>  description: creates path <span class="o">(</span>CP1-<span class="p">&amp;</span>gt<span class="p">;</span>CP2<span class="o">)</span>
</span><span class='line'>  properties:
</span><span class='line'>    id: 51
</span><span class='line'>    policy:
</span><span class='line'>      <span class="nb">type</span>: ACL
</span><span class='line'>      criteria:
</span><span class='line'>        - network_src_port_id: <span class="o">{</span> get_input: PORT_ID <span class="o">}</span>
</span><span class='line'>        - ip_proto: 1
</span><span class='line'>    path:
</span><span class='line'>      - forwarder: vIDS-TEMPLATE
</span><span class='line'>        capability: CP1
</span><span class='line'>      - forwarder: vIDS-TEMPLATE
</span><span class='line'>        capability: CP2
</span><span class='line'>&lt;/code&gt;&lt;/pre&gt;
</span><span class='line'>
</span><span class='line'>&lt;p&gt;  groups:
</span><span class='line'>    VNFFG1:
</span><span class='line'>      <span class="nb">type</span>: tosca.groups.nfv.VNFFG
</span><span class='line'>      description: Set of Forwarding Paths
</span><span class='line'>      properties:
</span><span class='line'>        vendor: tacker
</span><span class='line'>        version: 1.0
</span><span class='line'>        number_of_endpoints: 1
</span><span class='line'>        dependent_virtual_link: <span class="o">[</span>VL1<span class="o">]</span>
</span><span class='line'>        connection_point: <span class="o">[</span>CP1<span class="o">]</span>
</span><span class='line'>        constituent_vnfs: <span class="o">[</span>vIDS-TEMPLATE<span class="o">]</span>
</span><span class='line'>      members: <span class="o">[</span>Forwarding_Path-1<span class="o">]</span>
</span><span class='line'>EOF&lt;/p&gt;
</span><span class='line'>
</span><span class='line'>&lt;p&gt;tacker vnffgd-create <span class="p">&amp;</span>ndash<span class="p">;</span>vnffgd-file vnffgd.yaml VNFFG-TEMPLATE
</span></code></pre></td></tr></table></div></figure></p>

<p>In order to instantiate a VNFFGD we need to provide two runtime parameters:</p>

<ul>
<li>OpenStack port ID of VM1 for forwarding path flow classifier</li>
<li>ID of the VNF created by the Network Service</li>
</ul>


<p>All these parameters can be obtained using the CLI commands as shown below:</p>

<p><figure class='code panel panel-default'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'><span class="nv">CLIENT_IP</span><span class="o">=</span><span class="k">$(</span>openstack server list <span class="p">|</span> grep VM1 <span class="p">|</span> grep -Eo <span class="p">&amp;</span>lsquo<span class="p">;</span><span class="o">[</span>0-9<span class="o">]</span>+.<span class="o">[</span>0-9<span class="o">]</span>+.<span class="o">[</span>0-9<span class="o">]</span>+.<span class="o">[</span>0-9<span class="o">]</span>+<span class="p">&amp;</span>rsquo<span class="p">;</span><span class="k">)</span>
</span><span class='line'><span class="nv">PORT_ID</span><span class="o">=</span><span class="k">$(</span>openstack port list <span class="p">|</span> grep <span class="nv">$CLIENT_IP</span> <span class="p">|</span> awk <span class="p">&amp;</span>lsquo<span class="p">;</span><span class="o">{</span>print <span class="nv">$2</span><span class="o">}</span><span class="p">&amp;</span>rsquo<span class="p">;</span><span class="k">)</span>
</span><span class='line'><span class="nb">echo</span> <span class="p">&amp;</span>ldquo<span class="p">;</span>PORT_ID: <span class="nv">$PORT_ID</span><span class="p">&amp;</span>rdquo<span class="p">;</span> &gt; params-vnffg.yaml
</span><span class='line'><span class="nv">vIDS_ID</span><span class="o">=</span><span class="k">$(</span>tacker ns-show NS-vIDS-1 -f value -c vnf_ids <span class="p">|</span> sed <span class="p">&amp;</span>ldquo<span class="p">;</span>s/<span class="p">&amp;</span>lsquo<span class="p">;</span>/<span class="se">\&amp;</span>rdquo<span class="p">;</span>/g<span class="s2">&quot; | jq &amp;rsquo;.vIDS&#39; | sed &amp;ldquo;s/\&amp;rdquo;//g&quot;</span><span class="k">)</span>
</span></code></pre></td></tr></table></div></figure></p>

<p>The following command creates a VNFFG and an equivalent SFC to steer all ICMP traffic from VM1 through vIDS VNF. The result can be verified using Skydive following the procedure described in my <a href="/blog/2017/09/15/os-sfc-skydive/">previous post</a>.</p>

<p><figure class='code panel panel-default'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'>tacker vnffg-create <span class="p">&amp;</span>ndash<span class="p">;</span>vnffgd-name VNFFG-TEMPLATE <span class="se">\</span>
</span><span class='line'>                    <span class="p">&amp;</span>ndash<span class="p">;</span>vnf-mapping vIDS-TEMPLATE:<span class="nv">$vIDS_ID</span> <span class="se">\</span>
</span><span class='line'>                    <span class="p">&amp;</span>ndash<span class="p">;</span>param-file params-vnffg.yaml VNFFG-1
</span></code></pre></td></tr></table></div></figure></p>

<h2>Other Tacker features</h2>

<p>This post only scratches the surface of what&rsquo;s available in Tacker with a lot of other salient features left out of scope, including:</p>

<ul>
<li>VNF monitoring - through monitoring driver its possible to do VNF monitoring from VNFM using various methods ranging from a single ICMP/HTTP ping to Alarm-based monitoring using OpenStack&rsquo;s <a href="https://wiki.openstack.org/wiki/Telemetry">Telemetry framework</a></li>
<li>Enhanced Placement Awareness - VNFD Tosca template extensions that allow the definition of required performance features like NUMA topology mapping, SR-IOV and CPU pinning.</li>
<li>Mistral workflows - ability to drive Tacker workflows through Mistral</li>
</ul>


<h2>Conclusion</h2>

<p>Tacker is one of <a href="https://thenewstack.io/opensource-nfv-part-4-opensource-mano/">many</a> NFV orchestration platforms in a very competitive environment. Other <a href="https://www.mirantis.com/blog/which-nfv-orchestration-platform-best-review-osm-open-o-cord-cloudify/">open-source initiatives</a> have been created in response to the shortcomings of the original ETSI Release 1 reference architecture. The fact the some of the biggest Telcos have finally realised that the only way to achieve the goal of NFV orchestration is to get involved with open-source and do it themselves, may be a good sign for the industry and maybe not so good for the ETSI NFV MANO working group. Whether ONAP with its broader scope becomes a new de-facto standard for NFV orchestration, still remains to be seen, until then ETSI MANO remains the only viable standard for NFV lifecycle management and orchestration.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Openstack SDN - Skydiving Into Service Function Chaining]]></title>
    <link href="http://networkop.github.io/blog/2017/09/15/os-sfc-skydive/"/>
    <updated>2017-09-15T00:00:00+01:00</updated>
    <id>http://networkop.github.io/blog/2017/09/15/os-sfc-skydive</id>
    <content type="html"><![CDATA[<p>In this post I&rsquo;ll show how to configure Neutron&rsquo;s service function chaining,
troubleshoot it with Skydive and how SFC is implemented in OVS forwarding pipeline.</p>

<!--more-->


<hr />

<p><abbr title="Service Function Chaining">SFC</abbr> is another SDN feature that for a long time only used to be available in proprietary SDN solutions and that has recently become available in vanilla OpenStack. It serves as another proof that proprietary SDN solutions are losing the competitive edge, especially for Telco SDN/NFV use cases. Hopefully, by the end of this series of posts I&rsquo;ll manage do demonstrate how to build a complete open-source solution that has feature parity (in terms of major networking features) with all the major proprietary data centre SDN platforms. But for now, let&rsquo;s just focus on SFC.</p>

<h2>SFC High-level overview</h2>

<p>In most general terms, SFC refers to packet forwarding technique that uses more than just destination IP address to decide how to forward packets. In more specific terms, SFC refers to &ldquo;steering&rdquo; of traffic through a specific set of endpoints (a.k.a Service Functions), overriding the default destination-based forwarding. For those coming from a traditional networking background, think of SFC as a set of policy-based routing instances orchestrated from a central element (SDN controller). Typical use cases for SFC would be things like firewalling, IDS/IPS, proxying, NAT'ing, monitoring.</p>

<p>SFC is usually modelled as a directed (acyclic) graph, where the first and the last elements are the source and destination respectively and each vertex inside the graph represents a SF to be chained. IETF RFC7665 defines the reference architecture for SFC implementations and establishes some of the basic terminology. A simplified SFC architecture consists of the following main components:</p>

<ul>
<li>Classifier - a network element that matches and redirects traffic flows to a chain</li>
<li>Service Function - an element responsible for packet processing</li>
<li>Service Function Forwarder - a network element that forwards traffic to and from a directly connected SF</li>
</ul>


<p><img class="center" src="/images/sfc-overview.png"></p>

<p>One important property of a SF is elasticity. More instances of the same type can be added to a pool of SF and SFF will load-balance the traffic between them. This is the reason why, as we&rsquo;ll see in the next section, SFF treats connections to a SF as a group of ports rather than just a single port.</p>

<h2>Insertion modes and implementation models</h2>

<p>In legacy, pre-SDN environments SFs had no idea if they were a part of a service chain and network devices (routers and switches) had to &ldquo;insert&rdquo; the interesting traffic into the service function using one of the following two modes:</p>

<ul>
<li><p><strong>L2 mode</strong> is when SF is physically inserted between the source and destination inside a single broadcast domain, so traffic flows through a SF without any intervention from a switch. Example of this mode could be a firewall in transparent mode, physically connected between a switch and a default gateway router. All packets entering a SF have their original source and destination MAC addresses, which requires SF to be in promiscuous mode.</p></li>
<li><p><strong>L3 mode</strong> is when a router overrides its default destination-based forwarding and redirects the interesting traffic to a SF. In legacy networks this could have been achieved with PBR or WCCP. In this case SF needs to be L2-attached to a router and all redirected packets have their destination MAC updated to that of a SF&rsquo;s ingress interface.</p></li>
</ul>


<p>Modern SDN networks make it really easy to modify forwarding behaviour of network elements, both physical and virtual. There is no need for policy-based routing or bump-in-the-wire designs anymore. When flow needs to be redirected to a SF on a virtual switch, all what&rsquo;s required is a matching OpenFlow entry with a high enough priority. However redirecting traffic to a SF is just one part of the problem. Another part is how to make SFs smarter, to provide greater visibility of end-to-end service function path.</p>

<p>So far SFs have only been able to extract metadata from the packet itself. This limited the flexibility of SF logic and became computationally expensive in case many SFs need to access some L7 header information. Ideal way would be to have an additional header which can be used to read and write arbitrary information and pass it along the service function chain. RFC7665 defines requirements for &ldquo;SFC Encapsulation&rdquo; header which can be used to uniquely identify an instance of a chain as well as share metadata between all its elements. Neutron API refers to SFC encapsulation as <em>correlation</em> since its primary function is to identify a particular service function path. There are two implementations of SFC encapsulation in use today:</p>

<ul>
<li><strong>MPLS</strong> - used by current OVS agent driver (as of Pike). This method does not provide any means to share metadata and serves only for SFP identification. It is intended as an interim solution until NSH becomes available upstream in OVS.</li>
<li><strong>NSH</strong> - complete implementation of SFC encapsulation defined in RFC7665. This method is currently implemented in Opendaylight where NSH is used as a shim between VXLAN-GPE and the encapsulated packet</li>
</ul>


<p>It should be noted that the new approach with SFC encapsulation still allows for legacy, non-SFC-aware SFs to be chained. In this case SFC encapsulation is stripped off the packet by an &ldquo;SFC proxy&rdquo; before the packet is sent to the ingress port of a service function. All logical elements forming an SFC forwarding pipeline, including SFC proxy, Classifier and Forwarder, are implemented inside the same OVS bridges (br-int and br-tun) used by vanilla OVS-agent driver.</p>

<h2>Configuring Neutron SFC</h2>

<p> We&rsquo;ll pick up where we left off in the <a href="/blog/2017/09/08/os-lab-docker/">previous post</a>. All Neutron and ML2 configuration files have already been updated thanks to the <code>enable_sfc="yes"</code> setting in the global Kolla-Ansible configuration file. If not, you can change it in <code>/etc/kolla/globals.yaml</code> and re-run kolla-ansible deployment script.</p>

<p> First, let&rsquo;s generate OpenStack credentials using a post-deployment script. We later can use a default bootstrap script to downloads the cirros image and set up some basic networking and security rules.</p>

<p><figure class='code panel panel-default'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'>kolla-ansible post-deploy
</span><span class='line'><span class="nb">source</span> /etc/kolla/admin-openrc.sh
</span><span class='line'>/usr/share/kolla-ansible/init-runonce
</span></code></pre></td></tr></table></div></figure></p>

<p>The goal for this post is to create a simple uni-directional SFC to steer the ICMP requests from VM1 to its default gateway through another VM that will be playing the role of a firewall.</p>

<p><img class="center" src="/images/sfc-example.png"></p>

<p>The network was already created by the bootstrap script so all what we have to do is create a test VM. I&rsquo;m creating a port in a separate step simply so that I can refer to it by name instead of UUID.</p>

<p><figure class='code panel panel-default'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'>openstack port create <span class="p">&amp;</span>ndash<span class="p">;</span>network demo-net P0
</span><span class='line'>openstack server create <span class="p">&amp;</span>ndash<span class="p">;</span>image cirros <span class="p">&amp;</span>ndash<span class="p">;</span>flavor m1.tiny <span class="p">&amp;</span>ndash<span class="p">;</span>port P0 VM1
</span></code></pre></td></tr></table></div></figure></p>

<p>I&rsquo;ll go over all the necessary steps to setup SFC, but will only provide a brief explanation. Refer to the official OpenStack <a href="https://docs.openstack.org/newton/networking-guide/config-sfc.html">Networking Guide</a> for a complete SFC configuration guide.</p>

<p>First, let&rsquo;s create a FW VM with two ports - P1 and P2.</p>

<p><figure class='code panel panel-default'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'>openstack port create <span class="p">&amp;</span>ndash<span class="p">;</span>network demo-net P1
</span><span class='line'>openstack port create <span class="p">&amp;</span>ndash<span class="p">;</span>network demo-net P2
</span><span class='line'>openstack server create <span class="p">&amp;</span>ndash<span class="p">;</span>image cirros <span class="p">&amp;</span>ndash<span class="p">;</span>flavor m1.tiny <span class="p">&amp;</span>ndash<span class="p">;</span>port P1 <span class="p">&amp;</span>ndash<span class="p">;</span>port P2 FW
</span></code></pre></td></tr></table></div></figure></p>

<p>Next, we need create an ingress/egress port pair and assign it to a port pair group. The default setting for <strong>correlation</strong> in a port pair (not shown) is <code>none</code>. That means that SFC encapsulation header (MPLS) will get stripped before the packet is sent to P1.</p>

<p><figure class='code panel panel-default'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'>openstack sfc port pair create <span class="p">&amp;</span>ndash<span class="p">;</span>ingress P1 <span class="p">&amp;</span>ndash<span class="p">;</span>egress P2 PPAIR
</span><span class='line'>openstack sfc port pair group create <span class="p">&amp;</span>ndash<span class="p">;</span>port-pair PPAIR PPGROUP
</span></code></pre></td></tr></table></div></figure></p>

<p>Port pair group also allows to specify the L2-L4 headers which to use for load-balancing in OpenFlow groups, overriding the default behaviour described in the next section.</p>

<p>Another required element is a flow classifier. We will be redirecting ICMP traffic coming from VM1&rsquo;s port P0</p>

<p><figure class='code panel panel-default'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'>openstack sfc flow classifier create <span class="p">&amp;</span>ndash<span class="p">;</span>protocol icmp <span class="p">&amp;</span>ndash<span class="p">;</span>logical-source-port P0 FLOW-ICMP
</span></code></pre></td></tr></table></div></figure></p>

<p>Finally, we can tie together flow classifier with a previously created port pair group. The default setting for <strong>correlation</strong> (not shown again) in this case is <code>mpls</code>. That means that each chain will have its own unique MPLS label to be used as an SFC encapsulation.</p>

<p><figure class='code panel panel-default'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'>openstack sfc port chain create <span class="p">&amp;</span>ndash<span class="p">;</span>port-pair-group PPGROUP <span class="p">&amp;</span>ndash<span class="p">;</span>flow-classifier FLOW-ICMP PCHAIN
</span></code></pre></td></tr></table></div></figure></p>

<p>That&rsquo;s all the configuration needed to setup SFC. However if you login VM1&rsquo;s console and try pinging default gateway, it will fail. Next, I&rsquo;m going to give a quick demo of how to use a real-time network analyzer tool called Skydive to troubleshoot this issue.</p>

<h2>Using Skydive to troubleshoot SFC</h2>

<p><a href="https://skydive-project.github.io/skydive/">Skydive</a> is a new open-source distributed network probing and traffic analyzing tool. It consists of a set of agents running on compute nodes, collecting topology and flow information and forwarding it to a central element for analysis.</p>

<p>The idea of using Skydive to analyze and track SFC is not new. In fact, for anyone interested in this topic I highly recommend the <a href="http://blog.cafarelli.fr/2017/02/tracking-service-function-chaining-with-skydive/">following blogpost</a>. In my case I&rsquo;ll show how to use Skydive from a more practical perspective - troubleshooting multiple SFC issues.</p>

<p>Skydive CLI client is available inside the <code>skydive_analyzer</code> container. We need to start an interactive bash session inside this container and set some environment variables:</p>

<p><figure class='code panel panel-default'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'>docker <span class="nb">exec</span> -it skydive_analyzer bash
</span><span class='line'><span class="nb">export </span><span class="nv">SKYDIVE_ANALYZERS</span><span class="o">=</span>192.168.133.100:8085
</span><span class='line'><span class="nb">export </span><span class="nv">SKYDIVE_USERNAME</span><span class="o">=</span>admin
</span><span class='line'><span class="nb">export </span><span class="nv">SKYDIVE_PASSWORD</span><span class="o">=</span>admin
</span></code></pre></td></tr></table></div></figure></p>

<p>The first thing we can do to troubleshoot is see if ICMP traffic is entering the <code>ingress</code> port of the FW VM. Based on the output of <code>openstack port list</code> command I know that P1 has got an IP of <code>10.0.0.8</code>. Let&rsquo;s if we can identify a tap port corresponding to P1:</p>

<p><figure class='code panel panel-default'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'>skydive client topology query <span class="p">&amp;</span>ndash<span class="p">;</span>gremlin <span class="p">&amp;</span>ldquo<span class="p">;</span>G.V<span class="o">()</span>.Has<span class="o">(</span><span class="p">&amp;</span>lsquo<span class="p">;</span>Neutron.IPs<span class="p">&amp;</span>rsquo<span class="p">;</span>, <span class="p">&amp;</span>lsquo<span class="p">;</span>10.0.0.8<span class="p">&amp;</span>rsquo<span class="p">;</span>, <span class="p">&amp;</span>lsquo<span class="p">;</span>Type<span class="p">&amp;</span>rsquo<span class="p">;</span>, <span class="p">&amp;</span>lsquo<span class="p">;</span>tun<span class="p">&amp;</span>rsquo<span class="p">;</span><span class="o">)</span>.Values<span class="o">(</span><span class="p">&amp;</span>lsquo<span class="p">;</span>Neutron<span class="p">&amp;</span>rsquo<span class="p">;</span><span class="o">)</span><span class="p">&amp;</span>rdquo<span class="p">;</span>
</span><span class='line'><span class="o">{</span>
</span><span class='line'>  <span class="p">&amp;</span>ldquo<span class="p">;</span>IPs<span class="p">&amp;</span>rdquo<span class="p">;</span>: <span class="p">&amp;</span>ldquo<span class="p">;</span>10.0.0.8<span class="p">&amp;</span>rdquo<span class="p">;</span>,
</span><span class='line'>  <span class="p">&amp;</span>ldquo<span class="p">;</span>NetworkID<span class="p">&amp;</span>rdquo<span class="p">;</span>: <span class="p">&amp;</span>ldquo<span class="p">;</span>8eabb451-b026-417c-b54b-8e79ee6e71c3<span class="p">&amp;</span>rdquo<span class="p">;</span>,
</span><span class='line'>  <span class="p">&amp;</span>ldquo<span class="p">;</span>NetworkName<span class="p">&amp;</span>rdquo<span class="p">;</span>: <span class="p">&amp;</span>ldquo<span class="p">;</span>demo-net<span class="p">&amp;</span>rdquo<span class="p">;</span>,
</span><span class='line'>  <span class="p">&amp;</span>ldquo<span class="p">;</span>PortID<span class="p">&amp;</span>rdquo<span class="p">;</span>: <span class="p">&amp;</span>ldquo<span class="p">;</span>e6334df9-a5c4-4e86-a5f3-671760c2bbbe<span class="p">&amp;</span>rdquo<span class="p">;</span>,
</span><span class='line'>  <span class="p">&amp;</span>ldquo<span class="p">;</span>TenantID<span class="p">&amp;</span>rdquo<span class="p">;</span>: <span class="p">&amp;</span>ldquo<span class="p">;</span>bd5829e0cb5b40b68ab4f8e7dc68b14d<span class="p">&amp;</span>rdquo<span class="p">;</span>
</span><span class='line'><span class="o">}</span>
</span></code></pre></td></tr></table></div></figure></p>

<p>The output above proves that skydive agent has successfully read the configuration of the port and we can start a capture on that object to see any packets arriving on P1.</p>

<p><figure class='code panel panel-default'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'>skydive client capture create <span class="p">&amp;</span>ndash<span class="p">;</span>gremlin <span class="p">&amp;</span>ldquo<span class="p">;</span>G.V<span class="o">()</span>.Has<span class="o">(</span><span class="p">&amp;</span>lsquo<span class="p">;</span>Neutron.IPs<span class="p">&amp;</span>rsquo<span class="p">;</span>, <span class="p">&amp;</span>lsquo<span class="p">;</span>10.0.0.8<span class="p">&amp;</span>rsquo<span class="p">;</span>, <span class="p">&amp;</span>lsquo<span class="p">;</span>Type<span class="p">&amp;</span>rsquo<span class="p">;</span>, <span class="p">&amp;</span>lsquo<span class="p">;</span>tun<span class="p">&amp;</span>rsquo<span class="p">;</span><span class="o">)</span><span class="p">&amp;</span>rdquo<span class="p">;</span>
</span><span class='line'>skydive client topology query <span class="p">&amp;</span>ndash<span class="p">;</span>gremlin <span class="p">&amp;</span>ldquo<span class="p">;</span>G.V<span class="o">()</span>.Has<span class="o">(</span><span class="p">&amp;</span>lsquo<span class="p">;</span>Neutron.IPs<span class="p">&amp;</span>rsquo<span class="p">;</span>, <span class="p">&amp;</span>lsquo<span class="p">;</span>10.0.0.8<span class="p">&amp;</span>rsquo<span class="p">;</span>, <span class="p">&amp;</span>lsquo<span class="p">;</span>Type<span class="p">&amp;</span>rsquo<span class="p">;</span>, <span class="p">&amp;</span>lsquo<span class="p">;</span>tun<span class="p">&amp;</span>rsquo<span class="p">;</span><span class="o">)</span>.Flows<span class="o">()</span>.Has<span class="o">(</span><span class="p">&amp;</span>lsquo<span class="p">;</span>Application<span class="p">&amp;</span>rsquo<span class="p">;</span>,<span class="p">&amp;</span>lsquo<span class="p">;</span>ICMPv4<span class="p">&amp;</span>rsquo<span class="p">;</span><span class="o">)</span>.Values<span class="o">(</span><span class="p">&amp;</span>lsquo<span class="p">;</span>Metric.ABPackets<span class="p">&amp;</span>rsquo<span class="p">;</span><span class="o">)</span><span class="p">&amp;</span>rdquo<span class="p">;</span>
</span><span class='line'><span class="o">[</span>
</span><span class='line'>  7
</span><span class='line'><span class="o">]</span>
</span></code></pre></td></tr></table></div></figure></p>

<p>If you <code>watch</code> the last command for several seconds you should see that the number in brackets is increasing. That means that packets are hitting the ingress port of the FW VM. Now let&rsquo;s repeat the same test on <code>egress</code> port P2.</p>

<p><figure class='code panel panel-default'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'>skydive client capture create <span class="p">&amp;</span>ndash<span class="p">;</span>gremlin <span class="p">&amp;</span>ldquo<span class="p">;</span>G.V<span class="o">()</span>.Has<span class="o">(</span><span class="p">&amp;</span>lsquo<span class="p">;</span>Neutron.IPs<span class="p">&amp;</span>rsquo<span class="p">;</span>, <span class="p">&amp;</span>lsquo<span class="p">;</span>10.0.0.4<span class="p">&amp;</span>rsquo<span class="p">;</span>, <span class="p">&amp;</span>lsquo<span class="p">;</span>Type<span class="p">&amp;</span>rsquo<span class="p">;</span>, <span class="p">&amp;</span>lsquo<span class="p">;</span>tun<span class="p">&amp;</span>rsquo<span class="p">;</span><span class="o">)</span><span class="p">&amp;</span>rdquo<span class="p">;</span>
</span><span class='line'>skydive client topology query <span class="p">&amp;</span>ndash<span class="p">;</span>gremlin <span class="p">&amp;</span>ldquo<span class="p">;</span>G.V<span class="o">()</span>.Has<span class="o">(</span><span class="p">&amp;</span>lsquo<span class="p">;</span>Neutron.IPs<span class="p">&amp;</span>rsquo<span class="p">;</span>, <span class="p">&amp;</span>lsquo<span class="p">;</span>10.0.0.4<span class="p">&amp;</span>rsquo<span class="p">;</span>, <span class="p">&amp;</span>lsquo<span class="p">;</span>Type<span class="p">&amp;</span>rsquo<span class="p">;</span>, <span class="p">&amp;</span>lsquo<span class="p">;</span>tun<span class="p">&amp;</span>rsquo<span class="p">;</span><span class="o">)</span>.Flows<span class="o">()</span><span class="p">&amp;</span>rdquo<span class="p">;</span>
</span><span class='line'><span class="o">[]</span>
</span></code></pre></td></tr></table></div></figure></p>

<p>The output above tells us that there are no packets coming out of the FW VM. This is expected since we haven&rsquo;t done any changes to the blank cirros image to make it forward the packets between the two interfaces. If we examine the IP configuration of the FW VM, we would see that it doesn&rsquo;t have an IP address configured on the second interface. We would also need to create a source-based routing policy to force all traffic from VM1 (<code>10.0.0.6</code>) to egress via interface <code>eth2</code> and make sure IP forwarding is turned on. The following commands would need to be executed on FW VM:</p>

<p><figure class='code panel panel-default'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'>sudo cirros-dhcpc up eth1
</span><span class='line'>sudo ip rule add from 10.0.0.6 table default
</span><span class='line'>sudo ip route add default via 10.0.0.1 dev eth1 table default
</span><span class='line'>sudo sysctl -w net.ipv4.ip_forward<span class="o">=</span>1
</span></code></pre></td></tr></table></div></figure></p>

<p>Having done that, we should see some packets coming out of <code>egress</code> port P2.</p>

<p><figure class='code panel panel-default'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'>skydive client topology query <span class="p">&amp;</span>ndash<span class="p">;</span>gremlin <span class="p">&amp;</span>ldquo<span class="p">;</span>G.V<span class="o">()</span>.Has<span class="o">(</span><span class="p">&amp;</span>lsquo<span class="p">;</span>Neutron.IPs<span class="p">&amp;</span>rsquo<span class="p">;</span>, <span class="p">&amp;</span>lsquo<span class="p">;</span>10.0.0.4<span class="p">&amp;</span>rsquo<span class="p">;</span>, <span class="p">&amp;</span>lsquo<span class="p">;</span>Type<span class="p">&amp;</span>rsquo<span class="p">;</span>, <span class="p">&amp;</span>lsquo<span class="p">;</span>tun<span class="p">&amp;</span>rsquo<span class="p">;</span><span class="o">)</span>.Flows<span class="o">()</span>.Has<span class="o">(</span><span class="p">&amp;</span>lsquo<span class="p">;</span>Application<span class="p">&amp;</span>rsquo<span class="p">;</span>,<span class="p">&amp;</span>lsquo<span class="p">;</span>ICMPv4<span class="p">&amp;</span>rsquo<span class="p">;</span><span class="o">)</span>.Values<span class="o">(</span><span class="p">&amp;</span>lsquo<span class="p">;</span>Metric.ABPackets<span class="p">&amp;</span>rsquo<span class="p">;</span><span class="o">)</span><span class="p">&amp;</span>rdquo<span class="p">;</span>
</span><span class='line'><span class="o">[</span>
</span><span class='line'>  7
</span><span class='line'><span class="o">]</span>
</span></code></pre></td></tr></table></div></figure></p>

<p>However form the VM1&rsquo;s perspective the ping is still failing. Next step would be to see if the packets are hitting the integration bridge that port P2 is attached to:</p>

<p><figure class='code panel panel-default'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'>skydive client capture create <span class="p">&amp;</span>ndash<span class="p">;</span>gremlin <span class="p">&amp;</span>ldquo<span class="p">;</span>G.V<span class="o">()</span>.Has<span class="o">(</span><span class="p">&amp;</span>lsquo<span class="p">;</span>Neutron.IPs<span class="p">&amp;</span>rsquo<span class="p">;</span>, <span class="p">&amp;</span>lsquo<span class="p">;</span>10.0.0.4<span class="p">&amp;</span>rsquo<span class="p">;</span>, <span class="p">&amp;</span>lsquo<span class="p">;</span>Type<span class="p">&amp;</span>rsquo<span class="p">;</span>, <span class="p">&amp;</span>lsquo<span class="p">;</span>veth<span class="p">&amp;</span>rsquo<span class="p">;</span><span class="o">)</span><span class="p">&amp;</span>rdquo<span class="p">;</span>
</span><span class='line'>skydive client topology query <span class="p">&amp;</span>ndash<span class="p">;</span>gremlin <span class="p">&amp;</span>ldquo<span class="p">;</span>G.V<span class="o">()</span>.Has<span class="o">(</span><span class="p">&amp;</span>lsquo<span class="p">;</span>Neutron.IPs<span class="p">&amp;</span>rsquo<span class="p">;</span>, <span class="p">&amp;</span>lsquo<span class="p">;</span>10.0.0.4<span class="p">&amp;</span>rsquo<span class="p">;</span>, <span class="p">&amp;</span>lsquo<span class="p">;</span>Type<span class="p">&amp;</span>rsquo<span class="p">;</span>, <span class="p">&amp;</span>lsquo<span class="p">;</span>veth<span class="p">&amp;</span>rsquo<span class="p">;</span><span class="o">)</span>.Flows<span class="o">()</span><span class="p">&amp;</span>rdquo<span class="p">;</span>
</span><span class='line'><span class="o">[]</span>
</span></code></pre></td></tr></table></div></figure></p>

<p>No packets means they are getting dropped somewhere between the P2 and the integration bridge. This can only be done by security groups. In fact, source MAC/IP anti-spoofing is enabled by default which would only allow packets matching the source MAC/IP addresses assigned to P2 and would drop any packets coming from VM1&rsquo;s IP address. The easiest fix would be to disable security groups for P2 completely:</p>

<p><figure class='code panel panel-default'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'>openstack port <span class="nb">set</span> <span class="p">&amp;</span>ndash<span class="p">;</span>no-security-group <span class="p">&amp;</span>ndash<span class="p">;</span>disable-port-security P2
</span></code></pre></td></tr></table></div></figure></p>

<p>After this step the counters should start incrementing and the ping from VM1 to its default gateway is resumed.</p>

<p><figure class='code panel panel-default'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'>skydive client topology query <span class="p">&amp;</span>ndash<span class="p">;</span>gremlin <span class="p">&amp;</span>ldquo<span class="p">;</span>G.V<span class="o">()</span>.Has<span class="o">(</span><span class="p">&amp;</span>lsquo<span class="p">;</span>Neutron.IPs<span class="p">&amp;</span>rsquo<span class="p">;</span>, <span class="p">&amp;</span>lsquo<span class="p">;</span>10.0.0.4<span class="p">&amp;</span>rsquo<span class="p">;</span>, <span class="p">&amp;</span>lsquo<span class="p">;</span>Type<span class="p">&amp;</span>rsquo<span class="p">;</span>, <span class="p">&amp;</span>lsquo<span class="p">;</span>veth<span class="p">&amp;</span>rsquo<span class="p">;</span><span class="o">)</span>.Flows<span class="o">()</span>.Has<span class="o">(</span><span class="p">&amp;</span>lsquo<span class="p">;</span>Application<span class="p">&amp;</span>rsquo<span class="p">;</span>,<span class="p">&amp;</span>lsquo<span class="p">;</span>ICMPv4<span class="p">&amp;</span>rsquo<span class="p">;</span><span class="o">)</span>.Values<span class="o">(</span><span class="p">&amp;</span>lsquo<span class="p">;</span>Metric.ABPackets<span class="p">&amp;</span>rsquo<span class="p">;</span><span class="o">)</span><span class="p">&amp;</span>rdquo<span class="p">;</span>
</span><span class='line'><span class="o">[</span>
</span><span class='line'>  79
</span><span class='line'><span class="o">]</span>
</span></code></pre></td></tr></table></div></figure></p>

<h2>SFC implementation in OVS forwarding pipeline</h2>

<p>The only element being affected in our case (both VM1 and FW are on the same compute node) is the integration bridge. Refer to my <a href="http://networkop.co.uk/blog/2016/04/22/neutron-native/">older post</a> about vanilla OpenStack networking for a refresher of the vanilla OVS-agent architecture.</p>

<p>Normally, I would start by collecting all port and flow details from the integration bridge with the following commands:</p>

<p><figure class='code panel panel-default'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'>ovs-ofctl dump-ports-desc br-int  <span class="p">|</span> grep addr
</span><span class='line'>ovs-ofctl dump-flows br-int <span class="p">|</span> cut -d <span class="p">&amp;</span>lsquo<span class="p">;</span>,<span class="p">&amp;</span>rsquo<span class="p">;</span> -f3-
</span></code></pre></td></tr></table></div></figure></p>

<p>However, for the sake of brevity, I will omit the actual outputs and only show graphical representation of forwarding tables and packet flows. The tables below have two columns - first showing what is being matched and second showing the resulting action. Let&rsquo;s start with the OpenFlow rules in an integration bridge before SFC is configured:</p>

<p><img class="center" src="/images/sfc-before-tables.png"></p>

<p>As we can see, the table structure is quite simple, since integration bridge mostly relies on data-plane MAC learning. A couple of MAC and ARP anti-spoofing tables will check the validity of a packet and send it to table 60 where <code>NORMAL</code> action will trigger the &ldquo;flood-and-learn&rdquo; behaviour. Therefore, an ICMP packet coming from VM1 will take the following path:</p>

<p><img class="center" src="/images/sfc-before-packet.png"></p>

<p>After we&rsquo;ve configured SFC, the forwarding pipeline is changed and now looks like this:</p>

<p><img class="center" src="/images/sfc-after-tables.png"></p>

<p>First, we can see that table 0 acts as a classifier, by redirecting the &ldquo;interesting&rdquo; packets towards <code>group 1</code>. This groups is an <a href="https://floodlight.atlassian.net/wiki/spaces/floodlightcontroller/pages/7995427/How+to+Work+with+Fast-Failover+OpenFlow+Groups">OpenFlow Group</a> of type <code>select</code>, which load-balances traffic between multiple destinations. By default OVS will use a combination of L2-L4 header as described <a href="http://docs.openvswitch.org/en/latest/faq/openflow/">here</a> to calculate a hash which determines the output bucket, similar to how per-flow load-balancing works in traditional routers and switches. This behaviour can be overridden with a specific set of headers in <code>lb_fields</code> setting of a port pair group.</p>

<p>In our case we&rsquo;ve only got a single SF, so the packet gets its destination MAC updated to that of SF&rsquo;s ingress port and is forwarded to a new table 5. Table 5 is where all packets destined for a SF are aggregated with a single MPLS label which uniquely identifies the service function path. The packet is then forwarded to table 10, which I&rsquo;ve called <code>SFC Ingress</code>. This is where the packets are distributed to SF&rsquo;s ingress ports based on the assigned MPLS label.</p>

<p><img class="center" src="/images/sfc-after-packet.png"></p>

<p>After being processed by a SF, the packet leaves the <code>egress</code> port and re-enters the integration bridge. This time table 0 knows that the packet has already been processed by a SF and, since the anti-spoofing rules have been disabled, simply floods the packet out of all ports in the same VLAN. The packet gets flooded to the tunnel bridge where it gets replicated and delivered to the <code>qrouter</code> sitting on the controller node as per the <a href="http://networkop.co.uk/blog/2016/04/22/neutron-native/">default behaviour</a>.</p>

<h2>Upcoming enhancements</h2>

<p>SFC is a pretty vast topic and is still under active development. Some of the upcoming enhancement to the current implementation of SFC will include:</p>

<ul>
<li><strong>NSH</strong> header for SFC correlation</li>
<li><strong>TAP</strong> functionality which can replace the separate Tap-as-a-service OpenStack project</li>
<li><strong>Service graphs</strong> allowing multiple chains to be interconnected to create more complex service chain scenarios</li>
</ul>


<h2>Coming Up</h2>

<p>SFC is one of the major features in Telco SDN and, like many things, it&rsquo;s not meant to be configured manually. In fact, Telco SDN have their own framework for management and orchestration of VNFs (a.k.a. VMs) and VNF forwarding graphs (a.k.a. SFCs) called ETSI MANO. As it is expected from a Telco standard, it abounds with acronyms and confuses the hell out of anyone who&rsquo;s name is not on the list of authors or contributors. That&rsquo;s why in the next post I will try to provide a brief overview of what Telco SDN is and use Tacker, a software implementation of NFVO and VNFM, to automatically build a firewall VNF and provision a SFC, similar to what has been done in this post manually.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Openstack SDN - Building a Containerized OpenStack Lab]]></title>
    <link href="http://networkop.github.io/blog/2017/09/08/os-lab-docker/"/>
    <updated>2017-09-08T00:00:00+01:00</updated>
    <id>http://networkop.github.io/blog/2017/09/08/os-lab-docker</id>
    <content type="html"><![CDATA[<p>I&rsquo;m returning to my OpenStack SDN series to explore some of the new platform features like service function chaining, network service orchestration, intent-based networking and dynamic WAN routing. To kick things off I&rsquo;m going to demonstrate my new fully-containerized OpenStack Lab that I&rsquo;ve built using an OpenStack project called Kolla.</p>

<!--more-->


<hr />

<p>For quite a long time installation and deployment have been deemed as major barriers for OpenStack adoption. The classic &ldquo;install everything manually&rdquo; approach could only work in small production or lab environments and the ever increasing number of project under the <a href="https://governance.openstack.org/tc/reference/projects/">&ldquo;Big Tent&rdquo;</a> made service-by-service installation infeasible. This led to the rise of automated installers that over time evolved from a simple collection of scripts to container management systems.</p>

<h2>Evolution of automated OpenStack installers</h2>

<p>The first generation of automated installers were simple utilities that tied together a collection of Puppet/Chef/Ansible scripts. Some of these tools could do baremetal server provisioning through Cobbler or Ironic (Fuel, Compass) and some relied on server operating system to be pre-installed (Devstack, Packstack). In either case the packages were pulled from the Internet or local repository every time the installer ran.</p>

<p>The biggest problem with the above approach is the time it takes to re-deploy, upgrade or scale the existing environment. Even for relatively small environments it could be hours before all packages are downloaded, installed and configured. One of the ways to tackle this is to pre-build an operating system with all the necessary packages and only use Puppet/Chef/Ansible to change configuration files and turn services on and off. Redhat&rsquo;s TripleO is one example of this approach. It uses a &ldquo;golden image&rdquo; with pre-installed OpenStack packages, which is dd-written bit-by-bit onto the baremetal server&rsquo;s disk. The undercloud then decides which services to turn on based on the overcloud server&rsquo;s role.</p>

<p>Another big problem with most of the existing deployment methods was that, despite their microservices architecture, all OpenStack services were deployed as static packages on top of a shared operating system. This made the ongoing operations, troubleshooting and ugprades really difficult. The obvious thing to do would be to have all OpenStack services (e.g. Neutron, Keyston, Nova) deployed as containers and managed by a container management system. The first company to implement that, as far as I know, was Canonical. The deployment process is quite complicated, however the end result is a highly flexible OpenStack cloud deployed using LXC containers, managed and orchestrated by Juju controller.</p>

<p>Today (September 2017) deploying OpenStack services as containers is becoming mainstream and in this post I&rsquo;ll show how to use Kolla to build container images and Kolla-Ansible to deploy them on a pair of &ldquo;baremetal&rdquo; VMs.</p>

<h2>Lab overview</h2>

<p>My lab consists of a single controller and a single compute VM. The goal was to make them as small as possible so they could run on a laptop with limited resources. Both VMs are connected to three VM bridged networks - provisioning, management and external VM access.</p>

<p><img class="center" src="/images/kolla-lab.png"></p>

<p>I&rsquo;ve written some bash and Ansible scripts to automate the deployment of VMs on top of any Fedora derivative (e.g. Centos7). These scripts should be run directly from the hypervisor:</p>

<p><figure class='code panel panel-default'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'>git clone &lt;a <span class="nv">href</span><span class="o">=</span><span class="s2">&quot;https://github.com/networkop/kolla-odl-bgpvpn.git&quot;</span>&gt;https://github.com/networkop/kolla-odl-bgpvpn.git&lt;/a&gt; <span class="p">&amp;</span>amp<span class="p">;&amp;</span>amp<span class="p">;</span> <span class="nb">cd </span>kolla-odl-bgpvpn
</span><span class='line'>./1-create.sh <span class="k">do</span>
</span><span class='line'>./2-bootstrap.sh <span class="k">do</span>
</span></code></pre></td></tr></table></div></figure></p>

<p>The first bash script downloads the VM OS (Centos7), creates two blank VMs and sets up a local Docker registry. The second script installs all the dependencies, including Docker and Ansible.</p>

<h2>Building OpenStack docker containers with Kolla</h2>

<p>The first step in Kolla deployment workflow is deciding where to get the Docker images. Kolla maintains a <a href="https://hub.docker.com/u/kolla/">Docker Hub registry</a> with container images built for every major OpenStack release. The easiest way to get them would be to pull the images from Docker hub either directly or via a <a href="https://docs.docker.com/registry/recipes/mirror/">pull-through caching registry</a>.</p>

<p>In my case I needed to build the latest version of OpenStack packages, not just the latest major release. I also wanted to build a few additional, non-Openstack images (Opendaylight and Quagga). Because of that I had to build all Docker images locally and push them into a local docker registry. The procedure to build container images is very well documented in the official <a href="https://docs.openstack.org/kolla/latest/image-building.html">Kolla image building guide</a>. I&rsquo;ve modified it slightly to include the Quagga Dockerfile and automated it so that the whole process can be run with a single command:</p>

<p><figure class='code panel panel-default'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'>./3-build.sh <span class="k">do</span>
</span></code></pre></td></tr></table></div></figure></p>

<p>This step can take quite a long time (anything from 1 to 4 hours depending on the network and disk I/O speed), however, once it&rsquo;s been done these container images can be used to deploy as many OpenStack instances as necessary.</p>

<h2>Deploying OpenStack with Kolla-Ansible</h2>

<p>The next step in OpenStack deployment workflow is to deploy Docker images on target hosts. <a href="https://docs.openstack.org/kolla-ansible/latest/quickstart.html">Kolla-Ansible</a> is a highly customizable OpenStack deployment tool that is also extemely easy to use, at least for people familiar with Ansible. There are two main sources of information for Kolla-Ansible:</p>

<ul>
<li>Global configuration file (/etc/kolla/globals.yaml), which contains some of the most common customization options</li>
<li>Ansible inventory file (/usr/share/kolla-ansible/ansible/inventory/*), which maps OpenStack packages to target deployment hosts</li>
</ul>


<p>To get started with Kolla-Ansible all what it takes is a few modifications to the global configuration file to make sure that network settings match the underlying OS interface configuration and an update to the inventory file to point it to the correct deployment hosts. In my case I&rsquo;m making additional changes to enable SFC, Skydive and Tacker and adding files for Quagga container, all of which can be done with the following command:</p>

<p><figure class='code panel panel-default'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'>./4-deploy.sh <span class="k">do</span>
</span></code></pre></td></tr></table></div></figure></p>

<p>The best thing about this method of deployment is that it takes (in my case) under 5 minutes to get the full OpenStack cloud from scratch. That means if I break something or want to redeploy with some major changes (add/remove Opendaylight), all what I have to do is destroy the existing deployment (approx. 1 minute), modify global configuration file and re-deploy OpenStack. This makes Kolla-Ansible an ideal choice for my lab environment.</p>

<h2>Overview of containerized Openstack</h2>

<p>Once the deployment has been completed, we should be able to see a number of running Docker containers - one for each OpenStack process.</p>

<p><figure class='code panel panel-default'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'>root@compute-1# docker ps
</span><span class='line'>CONTAINER ID        IMAGE                                                                 COMMAND             CREATED             STATUS              PORTS               NAMES
</span><span class='line'>0bb8a8eeb1a9        172.26.0.1:5000/kolla/centos-source-skydive-agent:5.0.0               <span class="p">&amp;</span>ldquo<span class="p">;</span>kolla_start<span class="p">&amp;</span>rdquo<span class="p">;</span>       <span class="m">3</span> days ago          Up <span class="m">3</span> days                               skydive_agent
</span><span class='line'>63b5b643dfae        172.26.0.1:5000/kolla/centos-source-neutron-openvswitch-agent:5.0.0   <span class="p">&amp;</span>ldquo<span class="p">;</span>kolla_start<span class="p">&amp;</span>rdquo<span class="p">;</span>       <span class="m">3</span> days ago          Up <span class="m">3</span> days                               neutron_openvswitch_agent
</span><span class='line'>f6f74c5982cb        172.26.0.1:5000/kolla/centos-source-openvswitch-vswitchd:5.0.0        <span class="p">&amp;</span>ldquo<span class="p">;</span>kolla_start<span class="p">&amp;</span>rdquo<span class="p">;</span>       <span class="m">3</span> days ago          Up <span class="m">3</span> days                               openvswitch_vswitchd
</span><span class='line'>3078421a3892        172.26.0.1:5000/kolla/centos-source-openvswitch-db-server:5.0.0       <span class="p">&amp;</span>ldquo<span class="p">;</span>kolla_start<span class="p">&amp;</span>rdquo<span class="p">;</span>       <span class="m">3</span> days ago          Up <span class="m">3</span> days                               openvswitch_db
</span><span class='line'>9146c16d561b        172.26.0.1:5000/kolla/centos-source-nova-compute:5.0.0                <span class="p">&amp;</span>ldquo<span class="p">;</span>kolla_start<span class="p">&amp;</span>rdquo<span class="p">;</span>       <span class="m">3</span> days ago          Up <span class="m">3</span> days                               nova_compute
</span><span class='line'>8079f840627f        172.26.0.1:5000/kolla/centos-source-nova-libvirt:5.0.0                <span class="p">&amp;</span>ldquo<span class="p">;</span>kolla_start<span class="p">&amp;</span>rdquo<span class="p">;</span>       <span class="m">3</span> days ago          Up <span class="m">3</span> days                               nova_libvirt
</span><span class='line'>220d617d31a5        172.26.0.1:5000/kolla/centos-source-nova-ssh:5.0.0                    <span class="p">&amp;</span>ldquo<span class="p">;</span>kolla_start<span class="p">&amp;</span>rdquo<span class="p">;</span>       <span class="m">3</span> days ago          Up <span class="m">3</span> days                               nova_ssh
</span><span class='line'>743ce602d485        172.26.0.1:5000/kolla/centos-source-cron:5.0.0                        <span class="p">&amp;</span>ldquo<span class="p">;</span>kolla_start<span class="p">&amp;</span>rdquo<span class="p">;</span>       <span class="m">3</span> days ago          Up <span class="m">3</span> days                               cron
</span><span class='line'>8b71f08d2781        172.26.0.1:5000/kolla/centos-source-kolla-toolbox:5.0.0               <span class="p">&amp;</span>ldquo<span class="p">;</span>kolla_start<span class="p">&amp;</span>rdquo<span class="p">;</span>       <span class="m">3</span> days ago          Up <span class="m">3</span> days                               kolla_toolbox
</span><span class='line'>f76d0a7fcf2a        172.26.0.1:5000/kolla/centos-source-fluentd:5.0.0                     <span class="p">&amp;</span>ldquo<span class="p">;</span>kolla_start<span class="p">&amp;</span>rdquo<span class="p">;</span>       <span class="m">3</span> days ago          Up <span class="m">3</span> days                               fluentd
</span></code></pre></td></tr></table></div></figure></p>

<p>All the standard docker tools are available to interact with those containers. For example, this is how we can see what processes are running inside a container:</p>

<p><figure class='code panel panel-default'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'>root@compute-1# docker <span class="nb">exec </span>nova_compute ps -www aux
</span><span class='line'>USER       PID %CPU %MEM    VSZ   RSS TTY      STAT START   TIME COMMAND
</span><span class='line'>nova         <span class="m">1</span>  0.0  0.0    <span class="m">188</span>     <span class="m">4</span> pts/3    Ss+  Sep04   0:00 /usr/local/bin/dumb-init /bin/bash /usr/local/bin/kolla_start
</span><span class='line'>nova         <span class="m">7</span>  0.7  1.3 <span class="m">2292560</span> <span class="m">134896</span> ?      Ssl  Sep04  35:33 /var/lib/kolla/venv/bin/python /var/lib/kolla/venv/bin/nova-compute
</span><span class='line'>root        <span class="m">86</span>  0.0  0.3 <span class="m">179816</span> <span class="m">32900</span> ?        S    Sep05   0:00 /var/lib/kolla/venv/bin/python /var/lib/kolla/venv/bin/privsep-helper <span class="p">&amp;</span>ndash<span class="p">;</span>config-file /etc/nova/nova.conf <span class="p">&amp;</span>ndash<span class="p">;</span>privsep_context vif_plug_ovs.privsep.vif_plug <span class="p">&amp;</span>ndash<span class="p">;</span>privsep_sock_path /tmp/tmpFvP0GS/privsep.sock
</span></code></pre></td></tr></table></div></figure></p>

<p>Some of you may have noticed that none of the containers expose any ports. So how do they communicate? The answer is very simple - all containers run in a <strong>host</strong> networking mode, effectively disabling any network isolation and giving all contaners access to TCP/IP stacks of their Docker hosts. This is a simple way to avoid having to deal with Docker networking complexities, while at the same time preserving the immutability and portability of Docker containers.</p>

<p>All containers are configured to restart in case of a failure, however there&rsquo;s no <abbr title="Container Management System">CMS</abbr> to provide full lifecycle management and advanced scheduling. If upgrade of scale-in/out is needed, Kolla-Ansible will have to be re-run with updated configuration options. There is sibling project called <a href="https://github.com/openstack/kolla-kubernetes">Kolla-Kubernetes</a> (still under developement), that&rsquo;s designed to address some of the mentioned shortcomings.</p>

<h2>Coming up</h2>

<p>Now that the lab is up we can start exploring the new OpenStack SDN features. In the next post I&rsquo;ll have a close look at Neutron&rsquo;s <abbr title=" Service Function Chainng">SFC</abbr> feature, how to configure it and how it&rsquo;s been implemented in OVS forwarding pipeline.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Configuring Cisco IOS XE With YDK and OpenDaylight]]></title>
    <link href="http://networkop.github.io/blog/2017/02/22/odl-ydk/"/>
    <updated>2017-02-22T00:00:00+00:00</updated>
    <id>http://networkop.github.io/blog/2017/02/22/odl-ydk</id>
    <content type="html"><![CDATA[<p>Now it&rsquo;s time to turn our gaze to the godfather of YANG models and one of the most famous open-source SDN controllers, OpenDaylight. In this post I&rsquo;ll show how to connect Cisco IOS XE device to ODL and use Yang Development Kit to push a simple BGP configuration through ODL&rsquo;s RESTCONF interface.</p>

<!--more-->


<hr />

<p>In the previous posts about <a href="/blog/2017/01/25/netconf-intro/">NETCONF</a> and <a href="/blog/2017/02/15/restconf-yang/">RESTCONF</a> I&rsquo;ve demonstrated how to interact with Cisco IOS XE device directly from the Linux shell of my development VM. This approach works fine in some cases, e.g. whenever I setup a new DC fabric, I would make calls directly to the devices I&rsquo;m configuring. However, it becomes impractical in the Ops world where change is constant and involves a large number of devices. This is where centralised service orchestrators come to the fore. The prime examples of such platforms are Network Services Orchestrator from Tail-f/Cisco and open-source project OpenDaylight. In this post we&rsquo;ll concentrate on ODL and how to make it work with Cisco IOS XE. Additionally, I&rsquo;ll show how to use an open-source tool <a href="https://developer.cisco.com/site/ydk/">YDK</a> to generate Python bindings for native YANG models and how it compares with <strong>pyangbind</strong>.</p>

<h2>OpenDaylight primer</h2>

<p>OpenDaylight is a swiss army knife of SDN controllers. At the moment it is comprised of dozens of projects implementing all possible sorts of SDN functionality starting from Openflow controller all the way up to L3VPN orchestrator. ODL speaks most of the modern Southbound protocols like Openflow, SNMP, NETCONF and BGP. The brain of the controller is in the Service Abstraction Layer, a framework to model all network-related characteristics and properties. All logic inside SAL is modelled in YANG which is why I called it the godfather of YANG models. Towards the end users ODL exposes Java function calls for applications running on the same host and REST API for application running remotely.</p>

<p><img class="center" src="/images/odl-sal.jpg"></p>

<p>OpenDaylight has several commercial offerings from companies involved in its development. Most notable ones are from Brocade and Cisco. Here I will allow myself a bit of a rant, feel free to skip it to go straight to the technical stuff.</p>

<p>One thing I find interesting is that Cisco are being so secretive about their Open SDN Controller, perhaps due to the earlier market pressure to come up with a single SDN story, but still have a very large number of contributors to this open-source project. It could be the case of having an egg in each basket, but the number of Cisco&rsquo;s employees involved in ODL development is substantial. I wonder if, now that the use cases for ACI and ODL have finally formed and ACI still not showing the uptake originally expected, Cisco will change their strategy and start promoting ODL more aggressively, or at least stop hiding it deep in the bowels of <a href="cisco.com">cisco.com</a>. Or, perhaps, it will always stay in the shade of Tail-f&rsquo;s NSC and Insieme&rsquo;s ACI and will be used only for customer with unique requirements, e.g. to have both OpenStack and network devices managed through the same controller.</p>

<h2>Environment setup</h2>

<p>We&rsquo;ll use the same environment we&rsquo;ve setup in the <a href="/blog/2017/01/25/netconf-intro/">previous posts</a>, consisting of a CSR1K and a Linux VM connected to the same network inside my hypervisor. IOS XE device needs to have <code>netconf-yang</code> configured in order to enable the northbound NETCONF interface.</p>

<p>On the same Linux VM, I&rsquo;ve downloaded and launched the latest version of ODL (Boron-SR2), and enabled NETCONF and RESTCONF plugins.</p>

<p><figure class='code panel panel-default'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'>unzip distribution-karaf-0.5.2-Boron-SR2.zip
</span><span class='line'>mv distribution-karaf-0.5.2-Boron-SR2 odl-0.5.2
</span><span class='line'><span class="nb">cd </span>odl-0.5.2/
</span><span class='line'>./bin/karaf
</span><span class='line'>opendaylight-user@root&gt;feature:install odl-netconf-connector-all
</span><span class='line'>opendaylight-user@root&gt;feature:install odl-restconf-all
</span></code></pre></td></tr></table></div></figure></p>

<p>We&rsquo;ll use NETCONF to connect to Cisco IOS XE device and RESTCONF to interact with ODL from a Linux shell.</p>

<p><img class="center" src="/images/odl-ydk.png"></p>

<p>It might be useful to turn on logging in karaf console to catch any errors we might encounter later:</p>

<p><figure class='code panel panel-default'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'>opendaylight-user@root&gt;log:tail
</span></code></pre></td></tr></table></div></figure></p>

<h2>Connecting IOS XE to ODL</h2>

<p>According to ODL <a href="http://docs.opendaylight.org/en/stable-boron/user-guide/netconf-user-guide.html">NETCONF</a> user guide, in order to connect a new device to the controller, we need to create an XML document which will include the IP, port and user credentials of the IOS XE device. Here&rsquo;s the excerpt from the <a href="https://github.com/networkop/yang/blob/master/odl-101/new_device.xml.1">full XML document</a>:</p>

<p><figure class='code panel panel-default'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
</pre></td><td class='code'><pre><code class='xml'><span class='line'><span class="nt">&lt;module</span> <span class="na">xmlns=</span><span class="s">&quot;urn:opendaylight:params:xml:ns:yang:controller:config&quot;</span><span class="nt">&gt;</span>
</span><span class='line'>  <span class="nt">&lt;type</span> <span class="na">xmlns:prefix=</span><span class="s">&quot;urn:opendaylight:params:xml:ns:yang:controller:md:sal:connector:netconf&quot;</span><span class="nt">&gt;</span>prefix:sal-netconf-connector<span class="nt">&lt;/type&gt;</span>
</span><span class='line'>  <span class="nt">&lt;name&gt;</span>CSR1K<span class="nt">&lt;/name&gt;</span>
</span><span class='line'>  <span class="nt">&lt;address</span> <span class="na">xmlns=</span><span class="s">&quot;urn:opendaylight:params:xml:ns:yang:controller:md:sal:connector:netconf&quot;</span><span class="nt">&gt;</span>192.168.145.51<span class="nt">&lt;/address&gt;</span>
</span><span class='line'>  <span class="nt">&lt;port</span> <span class="na">xmlns=</span><span class="s">&quot;urn:opendaylight:params:xml:ns:yang:controller:md:sal:connector:netconf&quot;</span><span class="nt">&gt;</span>830<span class="nt">&lt;/port&gt;</span>
</span><span class='line'>  <span class="nt">&lt;username</span> <span class="na">xmlns=</span><span class="s">&quot;urn:opendaylight:params:xml:ns:yang:controller:md:sal:connector:netconf&quot;</span><span class="nt">&gt;</span>admin<span class="nt">&lt;/username&gt;</span>
</span><span class='line'>  <span class="nt">&lt;password</span> <span class="na">xmlns=</span><span class="s">&quot;urn:opendaylight:params:xml:ns:yang:controller:md:sal:connector:netconf&quot;</span><span class="nt">&gt;</span>admin<span class="nt">&lt;/password&gt;</span>
</span></code></pre></td></tr></table></div></figure></p>

<p>Assuming this XML is saved in a file called <a href="https://github.com/networkop/yang/blob/master/odl-101/new_device.xml.1">new_device.xml.1</a>, we can use <code>curl</code> to send it to ODL&rsquo;s netconf-connector plugin:</p>

<p><figure class='code panel panel-default'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'>curl -v -k -u admin:admin -H <span class="p">&amp;</span>ldquo<span class="p">;</span>Content-Type: application/xml<span class="p">&amp;</span>rdquo<span class="p">;</span> -X POST <span class="se">\</span>
</span><span class='line'> &lt;a <span class="nv">href</span><span class="o">=</span><span class="s2">&quot;http://localhost:8181/restconf/config/network-topology:network-topology%0A&quot;</span>&gt;http://localhost:8181/restconf/config/network-topology:network-topology
</span><span class='line'>&lt;/a&gt; /topology/topology-netconf/node/controller-config/yang-ext:mount/config:modules<span class="se">\</span>
</span><span class='line'>  -d @new_device.xml.1
</span></code></pre></td></tr></table></div></figure></p>

<p>When the controller gets this information it will try to connect to the device via NETCONF and do the following three things:</p>

<ul>
<li>Discover device capabilities advertised in the Hello message</li>
<li>Download all YANG models advertised by the device into the <code>./cache/schema</code> directory</li>
<li>Go through all of the imports in each model and verify that they can be satisfied</li>
</ul>


<p>After ODL downloads all of the 260 available models (can take up to 20 minutes) we will see the following errors in the karaf console:</p>

<p><figure class='code panel panel-default'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'>Netconf device does not provide all yang models reported in hello message capabilities
</span><span class='line'>Unable to build schema context, unsatisfied imports
</span><span class='line'>Initialization in sal failed, disconnecting from device
</span><span class='line'>No more sources <span class="k">for</span> schema context
</span></code></pre></td></tr></table></div></figure></p>

<p>Due to inconsistencies between the advertised and the available models, ODL fails to build the full device YANG schema context, which ultimately results in inability to connect the device to the controller. However, we won&rsquo;t need all of the 260 models advertised by the device. In fact, most of the configuration can be done through a single Cisco native YANG model, <code>ned</code>. With ODL it is possible to override the default capabilities advertised in the Hello message and &ldquo;pin&rdquo; only the ones that are going to be used. Assuming that ODL has downloaded most of the models at the previous step, we can simply tell it use the selected few with the following additions to the <a href="https://github.com/networkop/yang/blob/master/odl-101/new_device.xml.2">XML document</a>:</p>

<p><figure class='code panel panel-default'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
</pre></td><td class='code'><pre><code class='xml'><span class='line'><span class="nt">&lt;yang-module-capabilities</span> <span class="na">xmlns=</span><span class="s">&quot;urn:opendaylight:params:xml:ns:yang:controller:md:sal:connector:netconf&quot;</span><span class="nt">&gt;</span>
</span><span class='line'>    <span class="nt">&lt;override&gt;</span>true<span class="nt">&lt;/override&gt;</span>
</span><span class='line'>    <span class="nt">&lt;capability</span> <span class="na">xmlns=</span><span class="s">&quot;urn:opendaylight:params:xml:ns:yang:controller:md:sal:connector:netconf&quot;</span><span class="nt">&gt;</span>
</span><span class='line'>      urn:ietf:params:xml:ns:yang:ietf-inet-types?module=ietf-inet-types<span class="ni">&amp;amp;</span>revision=2013-07-15
</span><span class='line'>    <span class="nt">&lt;/capability&gt;</span>
</span><span class='line'>    <span class="nt">&lt;capability</span> <span class="na">xmlns=</span><span class="s">&quot;urn:opendaylight:params:xml:ns:yang:controller:md:sal:connector:netconf&quot;</span><span class="nt">&gt;</span>
</span><span class='line'>      <span class="nt">&lt;a</span> <span class="na">href=</span><span class="s">&quot;http://cisco.com/ns/yang/ned/ios?module=ned&amp;amp;amp;revision=2016-10-24&quot;</span><span class="nt">&gt;</span>http://cisco.com/ns/yang/ned/ios?module=ned<span class="ni">&amp;amp;</span>amp;revision=2016-10-24<span class="nt">&lt;/a&gt;</span>
</span><span class='line'>    <span class="nt">&lt;/capability&gt;</span>
</span></code></pre></td></tr></table></div></figure></p>

<p>Assuming the updated XML is saved in <a href="https://github.com/networkop/yang/blob/master/odl-101/new_device.xml.2">new_device.xml.2</a> file, the following command will update the current configuration of <strong>CSR1K</strong> device:</p>

<p><figure class='code panel panel-default'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'>curl -v -k -u admin:admin -H <span class="p">&amp;</span>ldquo<span class="p">;</span>Content-Type: application/xml<span class="p">&amp;</span>rdquo<span class="p">;</span> -X PUT <span class="se">\</span>
</span><span class='line'>&lt;a <span class="nv">href</span><span class="o">=</span><span class="s2">&quot;http://localhost:8181/restconf/config/network-topology:network-topology%0A/topology/topology-netconf/node/controller-config%0A/yang-ext:mount/config:modules/module%0A/odl-sal-netconf-connector-cfg:sal-netconf-connector%0A/CSR1K&quot;</span>&gt;http://localhost:8181/restconf/config/network-topology:network-topology
</span><span class='line'>/topology/topology-netconf/node/controller-config
</span><span class='line'>/yang-ext:mount/config:modules/module
</span><span class='line'>/odl-sal-netconf-connector-cfg:sal-netconf-connector
</span><span class='line'>/CSR1K&lt;/a&gt; -d @new_device.xml.2
</span></code></pre></td></tr></table></div></figure></p>

<p>We can then verify that the device has been successfully mounted to the controller:</p>

<p><figure class='code panel panel-default'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'>curl -v -k -u admin:admin &lt;a <span class="nv">href</span><span class="o">=</span><span class="s2">&quot;http://localhost:8181/restconf/operational%0A/network-topology:network-topology/&quot;</span>&gt;http://localhost:8181/restconf/operational
</span><span class='line'>/network-topology:network-topology/&lt;/a&gt; <span class="p">|</span> python -m json.tool
</span></code></pre></td></tr></table></div></figure></p>

<p>The output should look similar to the following with the connection-status set to <code>connected</code> and no detected <code>unavailable-capabilities</code>:</p>

<p><figure class='code panel panel-default'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
</pre></td><td class='code'><pre><code class='json'><span class='line'><span class="err">&amp;ldquo;netconf-node-topology:connection-status&amp;rdquo;:</span> <span class="err">&amp;ldquo;connected&amp;rdquo;,</span>
</span><span class='line'><span class="err">&amp;ldquo;netconf-node-topology:host&amp;rdquo;:</span> <span class="err">&amp;ldquo;</span><span class="mf">192.168</span><span class="err">.</span><span class="mf">145.51</span><span class="err">&amp;rdquo;,</span>
</span><span class='line'><span class="err">&amp;ldquo;netconf-node-topology:port&amp;rdquo;:</span> <span class="mi">830</span><span class="err">,</span>
</span><span class='line'><span class="err">&amp;ldquo;netconf-node-topology:unavailable-capabilities&amp;rdquo;:</span> <span class="p">{}</span><span class="err">,</span>
</span><span class='line'><span class="err">&amp;ldquo;node-id&amp;rdquo;:</span> <span class="err">&amp;ldquo;CSR</span><span class="mi">1</span><span class="err">K&amp;rdquo;</span>
</span></code></pre></td></tr></table></div></figure></p>

<p>At this point we should be able to interact with IOS XE&rsquo;s native YANG model through ODL&rsquo;s RESTCONF interface using the following URL</p>

<p><figure class='code panel panel-default'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'> &lt;a <span class="nv">href</span><span class="o">=</span><span class="s2">&quot;http://localhost:8181/restconf/config/network-topology:network-topology%0A&quot;</span>&gt;http://localhost:8181/restconf/config/network-topology:network-topology
</span><span class='line'>&lt;/a&gt; /topology/topology-netconf/node/CSR1K/yang-ext:mount/ned:native
</span></code></pre></td></tr></table></div></figure></p>

<p>The only thing that&rsquo;s missing is the actual configuration data. To generate it, I&rsquo;ll use a new open-source tool called YDK.</p>

<h2>YDK primer</h2>

<p>Yang Development Kit is a suite of tools to work with NETCONF/RESTCONF interfaces of a network device. The way I see it, YDK accomplishes two things:</p>

<ul>
<li>Generates API bindings for programming languages (Python and C++) from YANG models</li>
<li>Creates an abstraction layer to interact with southbound protocols (NETCONF or RESTCONF) in a uniform way</li>
</ul>


<p>There&rsquo;s a lot of overlap between the tools that we&rsquo;ve used <a href="/blog/2017/02/15/restconf-yang/">before</a> and YDK. Effectively YDK combines in itself the functions of a NETCONF client, a REST client, pyangbind and pyang(the latter is used internally for model verification). Since one of the main functions of YDK is API generation I thought it&rsquo;d be interesting to know how it compares to Rob Shakir&rsquo;s <strong>pyangbind</strong> plugin. The following information is what I&rsquo;ve managed to find on the Internet and from the comment of Santiago Alvarez below:</p>

<table>
<thead>
<tr>
<th> Feature </th>
<th> Pyangbind </th>
<th> YDK </th>
</tr>
</thead>
<tbody>
<tr>
<td> PL support </td>
<td> Python </td>
<td> Python, C++ with Ruby and Go in the pipeline </td>
</tr>
<tr>
<td> Serialization </td>
<td> JSON, XML </td>
<td> only XML <a href="https://github.com/CiscoDevNet/ydk-gen/blob/master/sdk/python/core/ydk/providers/codec_provider.py#L53">at this stage</a> with JSON coming up in a few weeks </td>
</tr>
<tr>
<td> Southbound interfaces   </td>
<td> N/A </td>
<td> NETCONF, RESTCONF with ODL coming up in a few weeks </td>
</tr>
<tr>
<td> Support </td>
<td> Cisco&rsquo;s devnet team </td>
<td> Rob Shakir </td>
</tr>
</tbody>
</table>


<p>So it looks like YDK is a very promising alternative to <strong>pyangbind</strong>, however I, personally, would still prefer to use <strong>pyangbind</strong> due to familiarity, simplicity and the fact that I don&rsquo;t need the above extra features offered by YDK right now. However, given that YDK has been able to achieve so much in just under one year of its existence, I don&rsquo;t discount the possibility that I may switch to YDK as it becomes more mature and feature-rich.</p>

<h2>Python binding generation with YDK-GEN</h2>

<p>One of the first things we need to do is install YDK-GEN, the tools responsible for API bindings generation, and it&rsquo;s core Python packages on the local machine. The following few commands are my version of the official <a href="https://github.com/CiscoDevNet/ydk-gen">installation procedure</a>:</p>

<p><figure class='code panel panel-default'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'>git clone &lt;a <span class="nv">href</span><span class="o">=</span><span class="s2">&quot;https://github.com/CiscoDevNet/ydk-gen.git&quot;</span>&gt;https://github.com/CiscoDevNet/ydk-gen.git&lt;/a&gt; ~/ydk-gen
</span><span class='line'>pip install -r ~/ydk-gen/requirements.txt
</span><span class='line'><span class="nb">export </span><span class="nv">YDKGEN_HOME</span><span class="o">=</span>~/ydk-gen/
</span><span class='line'>~/ydk-gen/generate.py <span class="p">&amp;</span>ndash<span class="p">;</span>python <span class="p">&amp;</span>ndash<span class="p">;</span>core
</span><span class='line'>pip install ~/ydk-gen/gen-api/python/ydk/dist/ydk*.tar.gz
</span></code></pre></td></tr></table></div></figure></p>

<p>YDK-GEN generates Python bindings based on the so-called <strong>bundle profile</strong>. This is a simple JSON document which lists all YANG models to include in the output package. In our case we&rsquo;d need to include a <code>ned</code> model along with all its imports. The sample below shows only the model specification. Refer to my <a href="https://github.com/networkop/yang/blob/master/odl-101/cisco-ios-xe_0_1_0.json">Github repo</a> for a complete bundle profile for Cisco IOS XE native YANG model.</p>

<p><figure class='code panel panel-default'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
</pre></td><td class='code'><pre><code class='json'><span class='line'><span class="p">{</span><span class="err">&amp;ldquo;models&amp;rdquo;:{&amp;ldquo;git&amp;rdquo;:[{&amp;ldquo;url&amp;rdquo;:&amp;ldquo;&lt;a</span> <span class="err">href=</span><span class="nt">&quot;https://github.com/YangModels/yang.git&quot;</span><span class="err">&gt;https</span><span class="p">:</span><span class="err">//github.com/YangModels/yang.git&lt;/a&gt;&amp;rdquo;</span><span class="p">,</span>
</span><span class='line'>  <span class="err">&amp;ldquo;commits&amp;rdquo;:[{&amp;ldquo;commitid&amp;rdquo;:&amp;ldquo;6f4a025431103f8cbbf3405ce01bdc61d0811b1d&amp;rdquo;,</span>
</span><span class='line'>    <span class="err">&amp;ldquo;file&amp;rdquo;:[&amp;ldquo;vendor/cisco/xe/1641/ned.yang&amp;rdquo;,</span>
</span><span class='line'>      <span class="err">&amp;ldquo;vendor/cisco/xe/1641/tailf-common.yang&amp;rdquo;,</span>
</span><span class='line'>      <span class="err">&amp;ldquo;vendor/cisco/xe/1641/tailf-meta-extensions.yang&amp;rdquo;,</span>
</span><span class='line'>      <span class="err">&amp;ldquo;vendor/cisco/xe/1641/tailf-cli-extensions.yang&amp;rdquo;,</span>
</span><span class='line'>      <span class="err">&amp;ldquo;standard/ietf/RFC/ietf-inet-types.yang&amp;rdquo;,</span>
</span><span class='line'>      <span class="err">&amp;ldquo;standard/ietf/RFC/ietf-yang-types.yang&amp;rdquo;]</span>
</span><span class='line'>      <span class="p">}</span><span class="err">]}]}}</span>
</span></code></pre></td></tr></table></div></figure></p>

<p>Assuming that the IOS XE bundle profile is saved in a file called <a href="https://github.com/networkop/yang/blob/master/odl-101/cisco-ios-xe_0_1_0.json">cisco-ios-xe_0_1_0.json</a>, we can use YDK to generate and install the Python binding package:</p>

<p><figure class='code panel panel-default'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'>~/ydk-gen/generate.py <span class="p">&amp;</span>ndash<span class="p">;</span>python <span class="p">&amp;</span>ndash<span class="p">;</span>bundle cisco-ios-xe_0_1_0.json -v
</span><span class='line'>pip install ~/ydk-gen/gen-api/python/cisco_ios_xe-bundle/dist/ydk*.tar.gz
</span></code></pre></td></tr></table></div></figure></p>

<h2>Configuring BGP with YDK</h2>

<p>Now we can start configuring BGP using our newly generated Python package. First, we need to create an instance of BGP configuration data:</p>

<p><figure class='code panel panel-default'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class='python'><span class='line'><span class="kn">from</span> <span class="nn">ydk.models.cisco_ios_xe.ned</span> <span class="kn">import</span> <span class="n">Native</span>
</span><span class='line'><span class="n">bgp</span> <span class="o">=</span> <span class="n">Native</span><span class="p">()</span><span class="o">.</span><span class="n">router</span><span class="o">.</span><span class="n">Bgp</span><span class="p">()</span>
</span></code></pre></td></tr></table></div></figure></p>

<p>The configuration will follow the pattern defined in the original model, which is why it&rsquo;s important to understand <a href="/blog/2017/02/15/restconf-yang/">the internal structure</a> of a YANG model. YANG leafs are represented as simple instance attributes. All YANG containers need to be explicitly instantiated, just like the <code>Native</code> and <code>Bgp</code> classes in the example above. Presence containers (<code>router</code> in the above example) will be instantiated at the same time as its parent container, inside the <code>__init__</code> function of the <code>Native</code> class. Don&rsquo;t worry if this doesn&rsquo;t make sense, use <strong>iPython</strong> or any IDE with autocompletion and after a few tries, you&rsquo;ll get the hang of it.</p>

<p>Let&rsquo;s see how we can set the local BGP AS number and add a new BGP peer to the neighbor list.</p>

<p><figure class='code panel panel-default'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
</pre></td><td class='code'><pre><code class='python'><span class='line'><span class="n">bgp</span><span class="o">.</span><span class="n">id</span> <span class="o">=</span> <span class="mi">100</span>
</span><span class='line'><span class="n">new_neighbor</span> <span class="o">=</span> <span class="n">bgp</span><span class="o">.</span><span class="n">Neighbor</span><span class="p">()</span>
</span><span class='line'><span class="n">new_neighbor</span><span class="o">.</span><span class="n">id</span> <span class="o">=</span> <span class="o">&amp;</span><span class="n">lsquo</span><span class="p">;</span><span class="mf">2.2</span><span class="o">.</span><span class="mf">2.2</span><span class="o">&amp;</span><span class="n">rsquo</span><span class="p">;</span>
</span><span class='line'><span class="n">new_neighbor</span><span class="o">.</span><span class="n">remote_as</span> <span class="o">=</span> <span class="mi">65100</span>
</span><span class='line'><span class="n">bgp</span><span class="o">.</span><span class="n">neighbor</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">new_neighbor</span><span class="p">)</span>
</span></code></pre></td></tr></table></div></figure></p>

<p>At this point of time all data is stored inside the instance of a <code>Bgp</code> class. In order to get an XML representation of it, we need to use YDK&rsquo;s XML provider and encoding service:</p>

<p><figure class='code panel panel-default'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
</pre></td><td class='code'><pre><code class='python'><span class='line'><span class="kn">from</span> <span class="nn">ydk.providers</span> <span class="kn">import</span> <span class="n">CodecServiceProvider</span>
</span><span class='line'><span class="kn">from</span> <span class="nn">ydk.services</span> <span class="kn">import</span> <span class="n">CodecService</span>
</span><span class='line'><span class="n">provider</span> <span class="o">=</span> <span class="n">CodecServiceProvider</span><span class="p">(</span><span class="nb">type</span><span class="o">=&amp;</span><span class="n">ldquo</span><span class="p">;</span><span class="n">xml</span><span class="o">&amp;</span><span class="n">rdquo</span><span class="p">;)</span>
</span><span class='line'><span class="n">codec</span> <span class="o">=</span> <span class="n">CodecService</span><span class="p">()</span>
</span><span class='line'><span class="n">xml_string</span> <span class="o">=</span> <span class="n">codec</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="n">provider</span><span class="p">,</span> <span class="n">bgp</span><span class="p">)</span>
</span><span class='line'><span class="k">print</span> <span class="n">xml_string</span>
</span></code></pre></td></tr></table></div></figure></p>

<p>All what we&rsquo;ve got left now is to send the data to ODL:</p>

<p><figure class='code panel panel-default'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
</pre></td><td class='code'><pre><code class='python'><span class='line'><span class="kn">import</span> <span class="nn">requests</span>
</span><span class='line'><span class="n">url</span> <span class="o">=</span> <span class="p">(</span><span class="o">&amp;</span><span class="n">ldquo</span><span class="p">;</span><span class="o">&lt;</span><span class="n">a</span> <span class="n">href</span><span class="o">=</span><span class="s">&quot;http://localhost:8181/restconf&quot;</span><span class="o">&gt;</span><span class="n">http</span><span class="p">:</span><span class="o">//</span><span class="n">localhost</span><span class="p">:</span><span class="mi">8181</span><span class="o">/</span><span class="n">restconf</span><span class="o">&lt;/</span><span class="n">a</span><span class="o">&gt;&amp;</span><span class="n">rdquo</span><span class="p">;</span>
</span><span class='line'>       <span class="o">&amp;</span><span class="n">ldquo</span><span class="p">;</span><span class="o">/</span><span class="n">config</span><span class="o">/</span><span class="n">network</span><span class="o">-</span><span class="n">topology</span><span class="p">:</span><span class="n">network</span><span class="o">-</span><span class="n">topology</span><span class="o">&amp;</span><span class="n">rdquo</span><span class="p">;</span>
</span><span class='line'>       <span class="o">&amp;</span><span class="n">ldquo</span><span class="p">;</span><span class="o">/</span><span class="n">topology</span><span class="o">/</span><span class="n">topology</span><span class="o">-</span><span class="n">netconf</span><span class="o">/</span><span class="n">node</span><span class="o">&amp;</span><span class="n">rdquo</span><span class="p">;</span>
</span><span class='line'>       <span class="o">&amp;</span><span class="n">ldquo</span><span class="p">;</span><span class="o">/</span><span class="n">CSR1K</span><span class="o">/</span><span class="n">yang</span><span class="o">-</span><span class="n">ext</span><span class="p">:</span><span class="n">mount</span><span class="o">/</span><span class="n">ned</span><span class="p">:</span><span class="n">native</span><span class="o">&amp;</span><span class="n">rdquo</span><span class="p">;</span>
</span><span class='line'>       <span class="o">&amp;</span><span class="n">ldquo</span><span class="p">;</span><span class="o">/</span><span class="n">router</span><span class="o">&amp;</span><span class="n">rdquo</span><span class="p">;)</span>
</span><span class='line'><span class="n">headers</span> <span class="o">=</span> <span class="p">{</span><span class="o">&amp;</span><span class="n">lsquo</span><span class="p">;</span><span class="n">Content</span><span class="o">-</span><span class="n">Type</span><span class="o">&amp;</span><span class="n">rsquo</span><span class="p">;:</span> <span class="o">&amp;</span><span class="n">lsquo</span><span class="p">;</span><span class="n">application</span><span class="o">/</span><span class="n">xml</span><span class="o">&amp;</span><span class="n">rsquo</span><span class="p">;}</span>
</span><span class='line'><span class="n">result</span> <span class="o">=</span> <span class="n">requests</span><span class="o">.</span><span class="n">post</span><span class="p">(</span><span class="n">url</span><span class="p">,</span> <span class="n">auth</span><span class="o">=</span><span class="p">(</span><span class="o">&amp;</span><span class="n">lsquo</span><span class="p">;</span><span class="n">admin</span><span class="o">&amp;</span><span class="n">rsquo</span><span class="p">;,</span> <span class="o">&amp;</span><span class="n">lsquo</span><span class="p">;</span><span class="n">admin</span><span class="o">&amp;</span><span class="n">rsquo</span><span class="p">;),</span> <span class="n">headers</span><span class="o">=</span><span class="n">headers</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">xml_string</span><span class="p">)</span>
</span><span class='line'><span class="k">print</span> <span class="n">result</span><span class="o">.</span><span class="n">status_code</span>
</span></code></pre></td></tr></table></div></figure></p>

<p>The controller should have returned the status code <code>204 No Content</code>, meaning that configuration has been changed successfully.</p>

<h2>Verification</h2>

<p>Back at the IOS XE CLI we can see the new BGP configuration that has been pushed down from the controller.</p>

<p><figure class='code panel panel-default'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
</pre></td><td class='code'><pre><code class='text'><span class='line'>TEST#sh run | i router
</span><span class='line'>router bgp 100
</span><span class='line'> bgp log-neighbor-changes
</span><span class='line'> neighbor 2.2.2.2 remote-as 65100
</span></code></pre></td></tr></table></div></figure></p>

<h2>More examples</h2>

<p>You can find a shorter version of the above procedure in my <a href="https://github.com/networkop/yang/tree/master/odl-101">ODL 101 repo</a>.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[OpenStack SDN With OVN (Part 2) - Network Engineering Analysis]]></title>
    <link href="http://networkop.github.io/blog/2016/12/10/ovn-part2/"/>
    <updated>2016-12-10T00:00:00+00:00</updated>
    <id>http://networkop.github.io/blog/2016/12/10/ovn-part2</id>
    <content type="html"><![CDATA[<p>In this post we will see how OVN implements virtual networks for OpenStack. The structure of this post is such that starting from the highest level of networking abstraction we will delve deeper into implementation details with each subsequent section. The biggest emphasis will be on how networking data model gets transformed into a set of logical flows, which eventually become OpenFlow flows. The final section will introduce a new overlay protocol GENEVE and explain why VXLAN no longer satisfies the needs of an overlay protocol.</p>

<!--more-->


<h2>OpenStack - virtual network topology</h2>

<p>In the <a href="/blog/2016/11/27/ovn-part1/">previous post</a> we have installed OpenStack and created a simple virtual topology as shown below. In OpenStack&rsquo;s data model this topology consists of the following elements:</p>

<ul>
<li><strong>Network</strong> defines a virtual L2 broadcast domain</li>
<li><strong>Subnet</strong> attached to the network, defines an IP subnet within the network</li>
<li><strong>Router</strong> provides connectivity between all directly connected subnets</li>
<li><strong>Port</strong> VM&rsquo;s point of attachment to the subnet</li>
</ul>


<p><img class="center" src="/images/ovn-zoom1.png"></p>

<p>So far nothing unusual, this is a simple Neutron data model, all that information is stored in Neutron&rsquo;s database and can be queried with <code>neutron</code> CLI commands.</p>

<h2>OVN Northbound DB - logical network topology</h2>

<p>Every call to implement an element for the above data model is forwarded to OVN ML2 driver as defined by the <code>mechanism driver</code> setting of the ML2 plugin. This driver is responsible for the creation of an appropriate data model inside the OVN Northbound DB. The main elements of this data model are:</p>

<ul>
<li><strong>Switch</strong> equivalent of a Neutron&rsquo;s Subnet, enables L2 forwarding for all attached ports</li>
<li><strong>Distributed Router</strong> provides distributed routing between directly connected subnets</li>
<li><strong>Gateway Router</strong> provides connectivity between external networks and distributed routers, implements NAT and Load Balancing</li>
<li><strong>Port</strong> of a logical switch, attaches VM to the switch</li>
</ul>


<p>This is a visual representation of our network topology inside OVN&rsquo;s Northbound DB, built based on the output of <code>ovn-nbctl show</code> command:</p>

<p><img class="center" src="/images/ovn-zoom2.png"></p>

<p>This topology is pretty similar to Neutron&rsquo;s native data model with the exception of a gateway router. In OVN, a gateway router is a special non-distributed router which performs functions that are very hard or impossible to distribute amongst all nodes, like NAT and Load Balancing. This router only exists on a single compute node which is selected by the scheduler based on the <code>ovn_l3_scheduler</code> setting of the ML2 plugin. It is attached to a distributed router via a point-to-point /30 subnet defined in the <code>ovn_l3_admin_net_cidr</code> setting of the ML2 plugin.</p>

<p>Apart from the logical network topology, Northbound database keeps track of all QoS, NAT and ACL settings and their parent objects. The detailed description of all tables and properties of this database can be found in the official <a href="http://openvswitch.org/support/dist-docs/ovn-nb.5.html">Northbound DB documentation</a>.</p>

<h2>OVN Southbound DB - logical flows</h2>

<p>OVN <a href="http://openvswitch.org/support/dist-docs/ovn-northd.8.html">northd</a> process running on the controller node translates the above logical topology into a set of tables stored in Southbound DB. Each row in those tables is a logical flow and together they form a <strong>forwarding pipeline</strong> by stringing together multiple actions to be performed on a packet. These actions range from packet drop through packet header modification to packet output. The stringing is implemented with a special <code>next</code> action which moves the packet one step down the pipeline starting from table 0. Let&rsquo;s have a look at the <strong>simplified</strong> versions of L2 and L3 forwarding pipelines using examples from our virtual topology.</p>

<h3>L2 datapath</h3>

<p>In the first example we&rsquo;ll explore the L2 datapath between VM1 and VM3. Both VMs are attached to the ports of the same logical switch. The full datapath of a logical switch consists of two parts - ingress and egress datapath (the direction is from the perspective of a logical switch). The ultimate goal of an ingress datapath is to determine the output port or ports (in case of multicast) and pass the packet to the egress datapath. The egress datapath does a few security checks before sending the packet out to its destination. Two things are worth noting at this stage:</p>

<ol>
<li>The two datapaths can be located either on the same or on two different hypervisor nodes. In the latter case, the packet is passed between the two nodes in an overlay tunnel.</li>
<li>The egress datapath does not have a destination lookup step which means that all information about the output port MUST be supplied by the ingress datapath. This means that destination lookup does not have to be done twice and it also has some interesting implications on the choice of encapsulation protocol as we&rsquo;ll see in the next section.</li>
</ol>


<p><img class="center" src="/images/ovn-zoom3-l2.png"></p>

<p>Let&rsquo;s have a closer look at each of the stages of the forwarding pipeline. I&rsquo;ll include snippets of logical flows demonstrating the most interesting behaviour at each stage. Full logical datapath is quite long and can be viewed with <code>ovn-sbctl lflow-list [DATAPATH]</code> command. Here is some useful information, collected from the Northbound database, that will be used in the examples below:</p>

<hr />

<table>
<thead>
<tr>
<th> VM# </th>
<th> IP </th>
<th> MAC </th>
<th> Port UUID </th>
</tr>
</thead>
<tbody>
<tr>
<td> VM1 </td>
<td> 10.0.0.2 </td>
<td> fa:16:3e:4f:2f:b8 </td>
<td> 26c23a54-6a91-48fd-a019-3bd8a7e118de </td>
</tr>
<tr>
<td> VM3 </td>
<td> 10.0.0.5 </td>
<td> fa:16:3e:2a:60:32 </td>
<td> 5c62cfbe-0b2f-4c2a-98c3-7ee76c9d2879 </td>
</tr>
</tbody>
</table>


<hr />

<ul>
<li><strong>Port security</strong> - makes sure that incoming packet has the correct source MAC and IP addresses.</li>
</ul>


<pre><code>table=0 (ls_in_port_sec_l2), priority=50, match=(inport == "26c23a54-6a91-48fd-a019-3bd8a7e118de"
  &amp;&amp; eth.src == {fa:16:3e:4f:2f:b8}), action=(next;)
table=1 (ls_in_port_sec_ip), priority=90, match=(inport == "26c23a54-6a91-48fd-a019-3bd8a7e118de"
  &amp;&amp; eth.src == fa:16:3e:4f:2f:b8 &amp;&amp; ip4.src == {10.0.0.2}), action=(next;)
</code></pre>

<ul>
<li><strong>Egress ACL</strong> - set of tables that implement Neutron&rsquo;s Egress Port Security functionality. Default rules allow all egress traffic from a VM. The first flow below matches all new connections coming from VM1 and marks them for connection tracking with <code>reg0[1] = 1</code>. The next table catches these marked packets and commits them to the connection tracker. Special <code>ct_label=0/1</code> action ensures return traffic is allowed which is a standard behaviour of all stateful firewalls.</li>
</ul>


<pre><code>table=6 (ls_in_acl), priority=2002 , match=(((ct.new &amp;&amp; !ct.est) ||
  (!ct.new &amp;&amp; ct.est &amp;&amp; !ct.rpl &amp;&amp; ct_label.blocked == 1)) &amp;&amp;
  (inport == "26c23a54-6a91-48fd-a019-3bd8a7e118de" &amp;&amp; ip4)),
  action=(reg0[1] = 1; next;)
table=9 (ls_in_stateful), priority=100  , match=(reg0[1] == 1),
  action=(ct_commit(ct_label=0/1); next;)
</code></pre>

<ul>
<li><strong>ARP Responder</strong> - matches an incoming ARP/ND request and generates an appropriate ARP/ND response. The way it is accomplished is similar to Neutron&rsquo;s native <a href="/blog/2016/05/06/neutron-l2pop/">ARP responder</a> feature. Effectively an ARP request gets transformed into an ARP response by swapping source and destination fields.</li>
</ul>


<pre><code>table=10(ls_in_arp_rsp), priority=50, match=(arp.tpa == 10.0.0.5 &amp;&amp; arp.op == 1),
  action=(eth.dst = eth.src; eth.src = fa:16:3e:2a:60:32; arp.op = 2; /* ARP reply */
  arp.tha = arp.sha; arp.sha = fa:16:3e:2a:60:32; arp.tpa = arp.spa; arp.spa = 10.0.0.5;
  outport = inport; flags.loopback = 1; output;)
</code></pre>

<ul>
<li><strong>DHCP Processing</strong> - set of tables that implement the DHCP server functionality using the approach similar to the ARP responder described above.</li>
</ul>


<pre><code>table=12(ls_in_dhcp_response), priority=100, match=(inport == "26c23a54-6a91-48fd-a019-3bd8a7e118de"
  &amp;&amp; eth.src == fa:16:3e:4f:2f:b8 &amp;&amp; ip4.src == 0.0.0.0 &amp;&amp; ip4.dst == 255.255.255.255
  &amp;&amp; udp.src == 68 &amp;&amp; udp.dst == 67 &amp;&amp; reg0[3]),
  action=(eth.dst = eth.src; eth.src = fa:16:3e:94:b6:bc; ip4.dst = 10.0.0.2;
  ip4.src = 10.0.0.1; udp.src = 67; udp.dst = 68; outport = inport; flags.loopback = 1; output;)
</code></pre>

<ul>
<li><strong>Destination Lookup</strong> - implements L2 forwarding based on the destination MAC address of a frame. At this stage the <strong>outport</strong> variable is set to the VM3&rsquo;s port UUID.</li>
</ul>


<pre><code>table=13(ls_in_l2_lkup), priority=50, match=(eth.dst == fa:16:3e:2a:60:32),
  action=(outport = "5c62cfbe-0b2f-4c2a-98c3-7ee76c9d2879"; output;)
</code></pre>

<ul>
<li><strong>Ingress ACL</strong> - set of tables that implement Neutron&rsquo;s Ingress Port security. For the sake of argument let&rsquo;s assume that we have enabled inbound SSH connections. The principle is same as before - the packet gets matched in one table and submitted to connection tracking in another table.</li>
</ul>


<pre><code>table=4 (ls_out_acl), priority=2002 , match=(((ct.new &amp;&amp; !ct.est)
  || (!ct.new &amp;&amp; ct.est &amp;&amp; !ct.rpl &amp;&amp; ct_label.blocked == 1))
  &amp;&amp; (outport == "26c23a54-6a91-48fd-a019-3bd8a7e118de" &amp;&amp; ip4
  &amp;&amp; ip4.src == 0.0.0.0/0 &amp;&amp; tcp &amp;&amp; tcp.dst == 22)),
  action=(reg0[1] = 1; next;
table=6 (ls_out_stateful), priority=100  , match=(reg0[1] == 1),
  action=(ct_commit(ct_label=0/1); next;)
</code></pre>

<ul>
<li><strong>Port Security</strong> - implements inbound port security for destination VM by checking the sanity of destination MAC and IP addresses.</li>
</ul>


<pre><code>table=7 (ls_out_port_sec_ip), priority=90, match=(outport == "5c62cfbe-0b2f-4c2a-98c3-7ee76c9d2879"
  &amp;&amp; eth.dst == fa:16:3e:2a:60:32 &amp;&amp; ip4.dst == {255.255.255.255, 224.0.0.0/4, 10.0.0.5}),
  action=(next;)
table=8 (ls_out_port_sec_l2), priority=50, match=(outport == "5c62cfbe-0b2f-4c2a-98c3-7ee76c9d2879"
  &amp;&amp; eth.dst == {fa:16:3e:2a:60:32}),
  action=(output;)
</code></pre>

<h3>L3 datapath</h3>

<p>Similar to a logical switch pipeline, L3 datapath is split into ingress and egress parts. In this example we&rsquo;ll concentrate on  the Gateway router datapath. This router is connected to a distributed logical router via a transit subnet (SWtr) and to an external network via an external bridge (SWex) and performs NAT translation for all VM traffic.</p>

<p><img class="center" src="/images/ovn-zoom3-l3.png"></p>

<p>Here is some useful information about router interfaces and ports that will be used in the examples below.</p>

<hr />

<table>
<thead>
<tr>
<th> SW function </th>
<th> IP </th>
<th> MAC </th>
<th> Port UUID </th>
</tr>
</thead>
<tbody>
<tr>
<td> External </td>
<td> 169.254.0.54/24 </td>
<td> fa:16:3e:39:c8:d8 </td>
<td> lrp-dc1ae9e3-d8fd-4451-aed8-3d6ddc5d095b </td>
</tr>
<tr>
<td> DVR-GW transit </td>
<td> 169.254.128.2/30 </td>
<td> fa:16:3e:7e:96:e7 </td>
<td> lrp-gtsp-186d8754-cc4b-40fd-9e5d-b0d26fc063bd </td>
</tr>
</tbody>
</table>


<hr />

<ul>
<li><strong>Port security</strong> - implements sanity check for all incoming packets.</li>
</ul>


<pre><code>table=0 (lr_in_admission), priority=50, match=((eth.mcast || eth.dst == fa:16:3e:7e:96:e7)
 &amp;&amp; inport == "lrp-gtsp-186d8754-cc4b-40fd-9e5d-b0d26fc063bd"), action=(next;)
</code></pre>

<ul>
<li><p><strong>IP Input</strong> - performs additional L3 sanity checks and implements typical IP services of a router (e.g. ICMP/ARP reply)
<code>
table=1 (lr_in_ip_input), priority=100, match=(ip4.src == {169.254.128.2, 169.254.128.3}),
action=(drop;)
table=1 (lr_in_ip_input), priority=90, match=(inport == "lrp-gtsp-186d8754-cc4b-40fd-9e5d-b0d26fc063bd"
&amp;&amp; arp.tpa == 169.254.128.2 &amp;&amp; arp.op == 1),
action=(eth.dst = eth.src; eth.src = fa:16:3e:7e:96:e7; arp.op = 2;
/* ARP reply */ arp.tha = arp.sha; arp.sha = fa:16:3e:7e:96:e7;
arp.tpa = arp.spa; arp.spa = 169.254.128.2;
outport = "lrp-gtsp-186d8754-cc4b-40fd-9e5d-b0d26fc063bd"; flags.loopback = 1; output;)
table=1 (lr_in_ip_input), priority=90, match=(ip4.dst == 169.254.128.2
&amp;&amp; icmp4.type == 8 &amp;&amp; icmp4.code == 0),
action=(ip4.dst &lt;-&gt; ip4.src; ip.ttl = 255; icmp4.type = 0; flags.loopback = 1; next; )
</code></p></li>
<li><p><strong>UNSNAT</strong> - translates the destination IP to the real address for packets coming from <strong>external</strong> networks
<code>
table=3 (lr_in_unsnat), priority=100, match=(ip &amp;&amp; ip4.dst == 169.254.0.54),
action=(ct_snat; next;)
</code></p></li>
<li><p><strong>DNAT</strong> - implements what is commonly known as static NAT, i.e. performs one-to-one destination IP translation for every configured floating IP.
<code>
table=4 (lr_in_dnat), priority=100, match=(ip &amp;&amp; ip4.dst == 169.254.0.52),
action=(flags.loopback = 1; ct_dnat(10.0.0.5);)
</code></p></li>
<li><p><strong>IP routing</strong> - implements L3 forwarding based on the destination IP address. At this stage the <code>outport</code> is decided, IP TTL is decremented and the new next-hop IP is set in register0.</p></li>
</ul>


<pre><code>table=5 (lr_in_ip_routing), priority=1, match=(ip4.dst == 0.0.0.0/0),
  action=(ip.ttl--; reg0 = 169.254.0.1; reg1 = 169.254.0.54; eth.src = fa:16:3e:39:c8:d8;
  outport = "lrp-dc1ae9e3-d8fd-4451-aed8-3d6ddc5d095b"; flags.loopback = 1; next;)
</code></pre>

<ul>
<li><p><strong>Next Hop Resolver</strong> - discovers the next-hop MAC address for a packet. This could either be a statically configured value when the next-hop is an OVN-managed router or a dynamic binding learned through ARP and stored in a special <code>MAC_Binding</code> table of Southbound DB.
<code>
table=6 (lr_in_arp_resolve), priority=100, match=(outport == "lrp-gtsp-186d8754-cc4b-40fd-9e5d-b0d26fc063bd"
&amp;&amp; reg0 == 169.254.128.1), action=(eth.dst = fa:16:3e:2a:7f:25; next;)
table=6 (lr_in_arp_resolve), priority=0, match=(ip4),
action=(get_arp(outport, reg0); next;)
</code></p></li>
<li><p><strong>SNAT</strong> - implements what is commonly known as overload NAT. Translates source IP, source UDP/TCP port number and ICMP Query ID to hide them behind a single IP address</p></li>
</ul>


<pre><code>table=0 (lr_out_snat), priority=25, match=(ip &amp;&amp; ip4.src == 10.0.0.0/24),
  action=(ct_snat(169.254.0.54);)
</code></pre>

<ul>
<li><strong>Output</strong> - send the packet out the port determined during the IP routing stage.</li>
</ul>


<pre><code>table=1 (lr_out_delivery), priority=100, match=(outport == "lrp-gtsp-186d8754-cc4b-40fd-9e5d-b0d26fc063bd"),
  action=(output;)
</code></pre>

<p>This was a very high-level, abridged and simplified version of how logical datapaths are built in OVN. Hopefully this lays enough groundwork to move on to the official <a href="http://openvswitch.org/support/dist-docs/ovn-northd.8.html">northd documentation</a> which describes both L2 and L3 datapaths in much greater detail.</p>

<p>Apart from the logical flows, Southbound DB also contains a number of tables that establish the logical-to-physical bindings. For example, the <code>Port_Binding</code> table establishes binding between logical switch, logical port, logical port overlay ID (a.k.a. tunnel key) and the unique hypervisor ID. In the next section we&rsquo;ll see how this information is used to translate logical flows into OpenFlow flows at each compute node. For full description of Southbound DB, its tables and their properties refer to the official SB <a href="http://openvswitch.org/support/dist-docs/ovn-sb.5.html">schema documentation</a>.</p>

<h2>OVN Controller - OpenFlow flows</h2>

<p><a href="http://openvswitch.org/support/dist-docs/ovn-controller.8.html">OVN Controller</a> process is the distributed part of OVN SDN controller. This process, running on each compute node, connects to Southbound DB via OVSDB and configures local OVS according to information received from it. It also uses Southbound DB to exchange the physical location information with other hypervisors. The two most important bits of information that OVN controller contributes to Southbound DB are physical location of logical ports and overlay tunnel IP address. These are the last two missing pieces to map logical flows to physical nodes and networks.</p>

<p>The whole flat space of OpenFlow tables is split into multiple areas. Tables 16 to 47 implement an ingress logical pipeline and tables 48 to 63 implement an egress logical pipeline. These tables have no notion of physical ports and are functionally equivalent to logical flows in Southbound DB. Tables 0 and 65 are responsible for mapping between the physical and logical realms. In table 0 packets are matched on the physical incoming port and assigned to a correct logical datapath as was defined by the <code>Port_Binding</code> table. In table 65 the information about the outport, that was determined during the ingress pipeline processing, is mapped to a local physical interface and the packet is sent out.</p>

<p>To demonstrate the details of OpenFlow implementation, I&rsquo;ll use the traffic flow between VM1 and external destination (8.8.8.8). For the sake of brevity I will only cover the major steps of packet processing inside OVS, omitting security checks and ARP/DHCP processing.</p>

<p><img class="center" src="/images/ovn-zoom4-openflow.png"></p>

<p>When packets traverse OpenFlow tables they get labelled or annotated with special values to simplify matching in subsequent tables. For example, when table 0 matches the incoming port, it annotates the packet with the datapath ID. Since it would have been impractical to label packets with globally unique UUIDs from Soutbound DB, these UUIDs get mapped to smaller values called <strong>tunnel keys</strong>. To make things even more confusing, each port will have a local kernel ID, unique within each hypervisor. We&rsquo;ll need both tunnel keys and local port IDs to be able to track the packets inside the OVS. The figure below depicts all port and datapath IDs that have been collected from the Soutbound DB and local OVSDB on each hypervisor. Local port numbers are attached with a dotted line to their respective tunnel keys.</p>

<p><img class="center" src="/images/ovn-zoom4-tunnelkey.png"></p>

<p>When VM1 sends the first packet to 8.8.8.8, it reaches OVS on local port 13. OVN Controller knows that this port belongs to VM1 and installs an OpenFlow rule to match all packets from this port and annotate them with datapath ID (OXM_OF_METADATA), incoming port ID (NXM_NX_REG14), conntrack zone (NXM_NX_REG13). It then moves these annotated packets to the first table of the ingress pipeline.
<code>
table=0, priority=100,in_port=13 actions=load:0x2-&gt;NXM_NX_REG13[],
  load:0x2-&gt;OXM_OF_METADATA[],load:0x2-&gt;NXM_NX_REG14[],
  resubmit(,16)
</code></p>

<p>Skipping to the L2 MAC address lookup stage, the output port (0x1) is decided based on the destination MAC address and saved in register 15.
<code>
table=29, priority=50,metadata=0x2,dl_dst=fa:16:3e:0d:df:ea
  actions=load:0x1-&gt;NXM_NX_REG15[],resubmit(,32)
</code></p>

<p>Finally, the packet reaches the last table where it is sent out the physical patch port interface towards R1.
<code>
table=65, priority=100,reg15=0x1,metadata=0x2 actions=output:1
</code></p>

<p>The other end of this patch port is connected to a local instance of distributed router R1. That means our packet, unmodified, re-enters OpenFlow table 0, only this time on a different port. Local port 2 is associated with a logical pipeline of a router, hence <code>metadata</code> for this packet is set to 4.
<code>
table=0, priority=100,in_port=2 actions=load:0x4-&gt;OXM_OF_METADATA[],
  load:0x1-&gt;NXM_NX_REG14[],resubmit(,16)
</code></p>

<p>The packet progresses through logical router datapath and finally gets to table 21 where destination IP lookup take place. It matches the catch-all <strong>default route</strong> rule and the values for its next-hop IP (0xa9fe8002), MAC address (fa:16:3e:2a:7f:25) and logical output port (0x03) are set.
<code>
table=21, priority=1,ip,metadata=0x4 actions=dec_ttl(),load:0xa9fe8002-&gt;NXM_NX_XXREG0[96..127],
  load:0xa9fe8001-&gt;NXM_NX_XXREG0[64..95],mod_dl_src:fa:16:3e:2a:7f:25,
  load:0x3-&gt;NXM_NX_REG15[],load:0x1-&gt;NXM_NX_REG10[0],resubmit(,22)
</code></p>

<p>Table 65 converts the logical output port 3 to physical port 6, which is yet another patch port connected to a transit switch.
<code>
table=65, priority=100,reg15=0x3,metadata=0x4 actions=output:6
</code></p>

<p>The packet once again re-enters OpenFlow pipeline from table 0, this time from port 5. Table 0 maps incoming port 5 to the logical datapath of a transit switch with Tunnel key 7.</p>

<pre><code>table=0, priority=100,in_port=5 actions=load:0x7-&gt;OXM_OF_METADATA[],
  load:0x1-&gt;NXM_NX_REG14[],resubmit(,16)
</code></pre>

<p>Destination lookup determines the output port (2) but this time, instead of entering the egress pipeline locally, the packet gets sent out the physical tunnel port (7) which points to the IP address of a compute node hosting the GW router. The headers of an overlay packet are populated with logical datapath ID (0x7), logical input port (copied from register 14) and logical output port (0x2).
<code>
table=29, priority=50,metadata=0x7,dl_dst=fa:16:3e:7e:96:e7
  actions=load:0x2-&gt;NXM_NX_REG15[],resubmit(,32)
table=32, priority=100,reg15=0x2,metadata=0x7 actions=load:0x7-&gt;NXM_NX_TUN_ID[0..23],
  set_field:0x2/0xffffffff-&gt;tun_metadata0,move:NXM_NX_REG14[0..14]-&gt;NXM_NX_TUN_METADATA0[16..30],
  output:7
</code></p>

<p>When packet reaches the destination node, it once again enters the OpenFlow table 0, but this time all information is extracted from the tunnel keys.</p>

<pre><code>table=0, priority=100,in_port=17 actions=move:NXM_NX_TUN_ID[0..23]-&gt;OXM_OF_METADATA[0..23],
  move:NXM_NX_TUN_METADATA0[16..30]-&gt;NXM_NX_REG14[0..14],
  move:NXM_NX_TUN_METADATA0[0..15]-&gt;NXM_NX_REG15[0..15],
  resubmit(,33)
</code></pre>

<p>At the end of the transit switch datapath the packet gets sent out port 12, whose peer is patch port 16.
<code>
table=65, priority=100,reg15=0x2,metadata=0x7 actions=output:12
</code></p>

<p>The packet re-enters OpenFlow table 0 from port 16, where it gets mapped to the logical datapath of a gateway router.
<code>
table=0, priority=100,in_port=16 actions=load:0x2-&gt;NXM_NX_REG11[],
  load:0x6-&gt;NXM_NX_REG12[],load:0x6-&gt;OXM_OF_METADATA[],
  load:0x2-&gt;NXM_NX_REG14[],resubmit(,16)
</code></p>

<p>Similar to a distributed router R1, table 21 determines the next-hop MAC address for a packet and saves the output port in register 15.
<code>
table=21, priority=1,ip,metadata=0x6 actions=dec_ttl(),load:0xa9fe0001-&gt;NXM_NX_XXREG0[96..127],
  load:0xa9fe0036-&gt;NXM_NX_XXREG0[64..95],mod_dl_src:fa:16:3e:39:c8:d8,
  load:0x1-&gt;NXM_NX_REG15[],load:0x1-&gt;NXM_NX_REG10[0],resubmit(,22)
</code></p>

<p>The first table of an egress pipeline source-NATs packets to external IP address of the GW router.
<code>
table=48, priority=33,ip,metadata=0x6,nw_src=10.0.0.2
  actions=ct(commit,table=49,zone=NXM_NX_REG12[0..15],nat(src=169.254.0.56))
</code></p>

<p>The modified packet is sent out the physical port 14 towards the external switch.
<code>
table=65, priority=100,reg15=0x1,metadata=0x6 actions=output:14
</code></p>

<p>External switch determines the output port connected to the <code>br-ex</code> on a local hypervisor and send the packet out.
<code>
table=0, priority=100,in_port=13 actions=load:0x5-&gt;NXM_NX_REG11[],
  load:0x3-&gt;NXM_NX_REG12[],load:0x3-&gt;OXM_OF_METADATA[],
  load:0x2-&gt;NXM_NX_REG14[],resubmit(,16)
table=29, priority=0,metadata=0x3 actions=load:0xfffe-&gt;NXM_NX_REG15[],resubmit(,32)
table=33, priority=100,reg15=0xfffe,metadata=0x3
  actions=load:0x1-&gt;NXM_NX_REG13[],load:0x1-&gt;NXM_NX_REG15[],
  resubmit(,34),load:0xfffe-&gt;NXM_NX_REG15[]
table=65, priority=100,reg15=0x1,metadata=0x3 actions=output:15
</code></p>

<p>As we&rsquo;ve just seen, OpenFlow repeats the logical topology by interconnecting logical datapaths of switches and routers with virtual point-to-point patch cables. This may seem like an unnecessary modelling element with a potential for a performance impact. However, when flows get installed in kernel datapath, these patch ports <a href="http://galsagie.github.io/2015/11/23/ovn-l3-deepdive">do not exist</a>, which means that there isn&rsquo;t any performance impact on packets in fastpath.</p>

<h2>Physical network - GENEVE overlay</h2>

<p>Before we wrap up, let us have a quick look at the new overlay protocol GENEVE. The goal of any overlay protocol is to transport all the necessary tunnel keys. With VXLAN the only tunnel key that could be transported is the Virtual Network Identifier (VNI). In OVN&rsquo;s case these tunnel keys include not only the logical datapath ID (commonly known as VNI) but also both input and output port IDs. You could have carved up the 24 bits of VXLAN tunnel ID to encode all this information but this would only have given you 256 unique values per key. Some other overlay protocols, like STT have even bigger tunnel ID header size but they, too, have a strict upper limit.</p>

<p>GENEVE was designed to have a variable-length header. The first few bytes are well-defined fixed size fields followed by variable-length Options. This kind of structure allows software developers to innovate at their own pace while still getting the benefits of hardware offload for the fixed-size portion of the header. OVN developers <a href="http://openvswitch.org/support/dist-docs/ovn-architecture.7.html">decided</a> to use Options header type 0x80 to store the 15-bit logical ingress port ID and a 16-bit egress port ID (an extra bit is for logical multicast groups).</p>

<p><img class="center" src="/images/ovn-zoom5-geneve.png"></p>

<p>The figure above shows the ICMP ping coming from VM1(10.0.0.2) to Google&rsquo;s DNS. As I&rsquo;ve showed in the previous section, GENEVE is used between the ingress and egress pipelines of a transit switch (SWtr), whose datapath ID is encoded in the VNI field (0x7). Packets enter the transit switch on port 1 and leave it on port 2. These two values are encoded in the <code>00010002</code> value of the <code>Options Data</code> field.</p>

<p>So now that GENEVE has taken over as the inter-hypervisor overlay protocol, does that mean that VXLAN is dead? OVN still supports VXLAN but only for interconnects with 3rd party devices like VXLAN-VLAN gateways or VXLAN TOR switches. Rephrasing the official OVN <a href="http://openvswitch.org/support/dist-docs/ovn-architecture.7.html">documentation</a>, VXLAN gateways will continue to be supported but they will have a reduced feature set due to lack of extensibility.</p>

<h2>Conclusion</h2>

<p>OpenStack networking has always been one of the first use cases of any new SDN controller. All the major SDN platforms like ACI, NSX, Contrail, VSP or ODL have some form of OpenStack integration. And it made sense, since native Neutron networking has always been one of the biggest pain points in OpenStack deployments. As I&rsquo;ve just demonstrated, OVN can now do all of the common networking functionality natively, without having to rely on 3rd party agents. In addition to that it has a fantastic <a href="http://openvswitch.org/support/dist-docs/">documentation</a>, implements all forwarding inside a single OVS bridge and it is an open-source project. As an OpenStack networking solution it is still, perhaps, a few months away from being production ready - active/active HA is not supported with OVSDB, GW router scheduling options are limited, lack of native support for DNS and Metadata proxy. However I anticipate that starting from the next OpenStack release (Ocata, Feb 2017) OVN will be ready for mass deployment even by companies without an army of OVS/OpenStack developers. And when that happens there will even less need for proprietary OpenStack SDN platforms.</p>
]]></content>
  </entry>
  
</feed>
