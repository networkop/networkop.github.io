<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: Sdn | Network-oriented programming]]></title>
  <link href="http://networkop.github.io/blog/categories/sdn/atom.xml" rel="self"/>
  <link href="http://networkop.github.io/"/>
  <updated>2016-05-05T21:16:04-07:00</updated>
  <id>http://networkop.github.io/</id>
  <author>
    <name><![CDATA[Michael Kashin]]></name>
    <email><![CDATA[mmkashin@gmail.com]]></email>
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Openstack SDN - L2 Population and ARP Proxy]]></title>
    <link href="http://networkop.github.io/blog/2016/05/06/neutron-l2pop/"/>
    <updated>2016-05-06T00:00:00-07:00</updated>
    <id>http://networkop.github.io/blog/2016/05/06/neutron-l2pop</id>
    <content type="html"><![CDATA[<p>In the <a href="http://networkop.github.io/blog/2016/04/22/neutron-native/">previous post</a> we&rsquo;ve had a look at how native OpenStack SDN works and what are some of its limitations. In this post we&rsquo;ll tackle the first one of them - overhead created by multicast source replication.</p>

<!--more-->


<h2>MAC learning in a controller-less VXLAN overlay</h2>

<p>VXLAN <a href="https://tools.ietf.org/html/rfc7348">standard</a> does not specify any control plane protocol to exchange MAC-IP bindings between VTEPs. Instead it relies on data plane flood-and-learn behaviour, just like a normal switch. To force this behaviour in an underlay, the standard stipulates that each VXLAN network should be mapped to its own multicast address and each VTEP participating in a network should join the corresponding multicast group. That multicast group would be used to flood the <abbr title="Broadcast Unknown unicast and Multicast">BUM</abbr> traffic in an underlay to all subscribed VTEPs thereby populating dynamic MAC address tables.</p>

<p>Default OpenvSwitch implementation <a href="https://github.com/openvswitch/ovs/blob/master/FAQ.md#q-how-much-of-the-vxlan-protocol-does-open-vswitch-currently-support">does not support</a> VXLAN multicast flooding and uses unicast source replication instead. This decision comes with a number of tradeoffs:</p>

<ul>
<li>Duplicate packets consume additional bandwidth. Extra 100 bytes exchanged every 3 minutes in a 100-nodes environment generate around 500 kbit/s of traffic on average. This can be considered negligible inside modern high-speed DC fabrics.</li>
<li>Hardware VTEP gateways rely on multicast for MAC learning and VTEP discovery. As we&rsquo;ll see later in the series, these gateways can now be controlled by Neutron just like a normal OVS inside a compute host.</li>
<li>Duplicate packets are processed by hosts that do not need them, e.g. ARP request is processed by tunnel and integration bridges of all hosts that have VMs in the same broadcast domain. This presents some serious scaling limitation and is addressed by the L2 population feature described in this post.</li>
</ul>


<p>Despite all the tradeoffs, OVS with unicast source replication has become a de-facto standard in most recent OpenStack implementations. The biggest advantage of such approach is the lack of requirement for multicast in the underlay network.</p>

<h2>VXLAN MAC learning with an SDN controller</h2>

<p>Neutron server is aware of all active MAC and IP addresses within the environment. This information can be used to prepopulate forwarding entries on all tunnel bridges. This is accomplished by a <a href="https://github.com/openstack/neutron/tree/master/neutron/plugins/ml2/drivers/l2pop">L2 population</a> driver. However that in itself isn&rsquo;t enough. Whenever a VM doesn&rsquo;t know the destination MAC address, it will send a broadcast ARP request which needs to be intercepted and responded by a local host to stop it from being flooded in the network. The latter is accomplished by a feature called <a href="https://assafmuller.com/2014/05/21/ovs-arp-responder-theory-and-practice/">ARP responder</a> which simulates the functionality commonly known as <strong>ARP proxy</strong> inside the tunnel bridge.</p>

<p><img class="center" src="/images/neutron-l2-arp.png"></p>

<h3>Configuration</h3>

<p>Configuration of these two features is <a href="https://kimizhang.wordpress.com/2014/04/01/how-ml2vxlan-works/">fairly straight-forward</a>. First, we need to add L2 population to the list of supported mechanism drivers on our control node and restart the neutron server.</p>

<pre><code class="bash Update on control node">$ sed -ri 's/(mechanism_drivers.*)/\1,l2population/' /etc/neutron/plugin.ini
$ service neutron-server restart  
</code></pre>

<p>Next we need to enable L2 population and ARP responder features on all 3 compute nodes.</p>

<pre><code class="bash Updates on all 3 compute nodes">$ sed -ri 's/.*(arp_responder).*/\1 = true/' /etc/neutron/plugins/ml2/openvswitch_agent.ini
$ sed -ri 's/.*(l2_population).*/\1 = true/' /etc/neutron/plugins/ml2/openvswitch_agent.ini
$ service neutron-openvswitch-agent restart
</code></pre>

<p>Since L2 population is triggered by the <a href="https://assafmuller.com/2014/02/23/ml2-address-population/">port_up</a> messages, we might need to restart both our VMs for the change to take effect.</p>

<h3>BUM frame from VM-1 for MAC address of VM-2 (Revisited)</h3>

<p>Now let&rsquo;s once again examine what happens when VM-1 issues an ARP request for VM-2&rsquo;s MAC address (1a:bf).</p>

<p>First, the frame hits the flood-and-learn rule of the integration bridge and gets flooded down to the tunnel bridge as desribed in the <a href="http://networkop.github.io/blog/2016/04/22/neutron-native/">previous post</a>. Once in the br-tun, the frames gets matched by the incoming port and resubmitted to table 2. In addition to a default unicast/multicast bit match, table 2 now also matches all ARP requests and resubmitts them to the new table 21. Note how the ARP entry has a higher priority to always match before the default catch-all multicast rule.</p>

<pre><code class="bash ovs-ofctl dump-flows br-tun">table=0, priority=1,in_port=1 actions=resubmit(,2)
table=2, priority=1,arp,dl_dst=ff:ff:ff:ff:ff:ff actions=resubmit(,21)
table=2, priority=0,dl_dst=00:00:00:00:00:00/01:00:00:00:00:00 actions=resubmit(,20)
table=2, priority=0,dl_dst=01:00:00:00:00:00/01:00:00:00:00:00 actions=resubmit(,22)
</code></pre>

<p>Inside table 21 are the entries created by the ARP responder feature. The following is an example entry that matches all ARP requests where target IP address field equals the IP of VM-2(10.0.0.9).</p>

<pre><code class="bash ovs-ofctl dump-flows br-tun"> table=21, priority=1,arp,dl_vlan=1,arp_tpa=10.0.0.9 
 actions=move:NXM_OF_ETH_SRC[]-&gt;NXM_OF_ETH_DST[],
 mod_dl_src:fa:16:3e:ab:1a:bf,
 load:0x2-&gt;NXM_OF_ARP_OP[],
 move:NXM_NX_ARP_SHA[]-&gt;NXM_NX_ARP_THA[],
 move:NXM_OF_ARP_SPA[]-&gt;NXM_OF_ARP_TPA[],
 load:0xfa163eab1abf-&gt;NXM_NX_ARP_SHA[],
 load:0xa000009-&gt;NXM_OF_ARP_SPA[],
 IN_PORT
</code></pre>

<p>The resulting action builds an ARP response by modifying the fields and headers on the original ARP request message, specifically OVS:</p>

<ol>
<li>Copies the source MAC address (VM-1) to the destination MAC address header</li>
<li>Spoofs the source MAC address to make it look like it comes from VM-2</li>
<li>Modifies the operation code of ARP message to 0x2, meaning <strong>reply</strong></li>
<li>Overwrites the target IP and MAC address fields inside the ARP packet with VM-1&rsquo;s values</li>
<li>Overwrites the source hardware address with VM-2&rsquo;s MAC</li>
<li>Overwrites the source IP address with the address of VM-2(0xa000009)</li>
<li>Sends the packet out the port from which it was received</li>
</ol>


<h3>Unicast frame from VM-1 to VM-2 (Revisited)</h3>

<p>Now that VM-1 has learned the MAC address of VM-2 it can start sending the unicast frames. The first few steps will again be the same. The frame hits the tunnel bridge, gets classified as a unicast and resubmitted to table 20. Table 20 will still have an entry generated by a <strong>learn</strong> action triggered by a packet coming from VM-2, however now it also has and identical entry with a higher priority(priority=2), which was preconfigured by a L2 population feature.</p>

<pre><code class="bash">table=0, priority=1,in_port=1 actions=resubmit(,2)
table=2, priority=0,dl_dst=00:00:00:00:00:00/01:00:00:00:00:00 actions=resubmit(,20)
table=20, priority=2,dl_vlan=1,dl_dst=fa:16:3e:ab:1a:bf actions=strip_vlan,set_tunnel:0x54,output:2
table=20, priority=1,vlan_tci=0x0001/0x0fff,dl_dst=fa:16:3e:ab:1a:bf actions=load:0-&gt;NXM_OF_VLAN_TCI[],load:0x54-&gt;NXM_NX_TUN_ID[],output:2
</code></pre>

<h2>Other BUM traffic</h2>

<p>The two features described in this post only affect the ARP traffic to VMs <strong>known</strong> to the Neutron server. All the other BUM traffic will still be flooded as described in the <a href="http://networkop.github.io/blog/2016/04/22/neutron-native/">previous post</a>.</p>

<h2>Results</h2>

<p>As the result of enabling L2 population and ARP responder features we were able to reduce the amount of BUM traffic in the overlay network and reduce the eliminate processing on compute hosts incurred by ARP request flooding.</p>

<p>However one downside of this approach is the increased number of flow entries in tunnel bridges of compute hosts. Specifically, for each known VM there now will be two entries in the tunnel bridge with different priorities. This may have negative impact on performance and is something to keep in mind when designing OpenStack solutions for scale.</p>

<h2>Coming Up</h2>

<p>In the next post I&rsquo;ll show how to overcome the requirement of a direct L2 adjacency between the network node and external subnet. Specifically, I&rsquo;ll use Arista switch to extend a L2 provider network over a L3 leaf-spine Cisco fabric.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Network Engineering Analysis of OpenStack SDN]]></title>
    <link href="http://networkop.github.io/blog/2016/04/22/neutron-native/"/>
    <updated>2016-04-22T00:00:00-07:00</updated>
    <id>http://networkop.github.io/blog/2016/04/22/neutron-native</id>
    <content type="html"><![CDATA[<p>Now that we have our 3-node OpenStack lab <a href="http://networkop.github.io/blog/2016/04/18/os-unl-lab/">up and running</a> we can start exploring how virtual networks are implemented under the hood.</p>

<!--more-->


<h2>Intro</h2>

<p>This is going to be quite a lengthy blogpost so I&rsquo;ll try to explain its structure first. I&rsquo;ll start with a high level overview of components used to build virtual networks by examining 3 types of traffic:</p>

<ul>
<li>Unicast traffic between VM1 and VM2</li>
<li>Unicast traffic between VM1 and the outside world (represented by an external subnet)</li>
<li>Broadcast, Unknown unicast and Multicast or BUM traffic from VM1</li>
</ul>


<p>Following that I&rsquo;ll give a brief overview of how to interpret the configuration and dynamic state of OpenvSwitch to manually trace the path of a packet. This will be required for the next section where I&rsquo;ll go over the same 3 types of traffic but this time corroborating every step with the actual outputs collected from the virtual switches. For the sake of brevity I&rsquo;ll abridge a lot of the output to only contain the relevant information.</p>

<h2>High Level Overview</h2>

<p><a href="http://www.innervoice.in/blogs/2015/03/31/openstack-neutron-plugins-and-agents/">Neutron</a> server, residing in a control node, is responsible for orchestrating and provisioning of all virtual networks within an OpenStack environment. Its goal is to enable end-to-end reachability among the VMs and between the VMs and external subnets. To do that, Neutron uses concepts that should be very familiar to every network engineer like subnet, router, firewall, DHCP and NAT. In the <a href="http://networkop.github.io/blog/2016/04/04/openstack-unl/">previous post</a> we&rsquo;ve seen how to create a virtual router and attach it to public and private networks. We&rsquo;ve also attached both of our VMs to a newly created private network and verified connectivity by logging into those virtual machines. Now let&rsquo;s see how exactly these VMs communicate with each other and the outside world.</p>

<p><img class="center" src="/images/neutron-high-level.png"></p>

<h3>Unicast frame between VM1 and VM2</h3>

<ol>
<li><p>As soon as the frame leaves the vNIC of VM1 it hits the firewall. The firewall is implemented on a <a href="http://www.innervoice.in/blogs/2013/12/08/tap-interfaces-linux-bridge/">tap interface</a> of the integration bridge. A set of <abbr title="Access Control List">ACL</abbr> rules, defined in a <strong>Security Group</strong> that VM belongs to, gets translated into Linux <a href="https://www.frozentux.net/iptables-tutorial/iptables-tutorial.html#TRAVERSINGOFTABLES">iptables</a> rules and attached to this tap interface. These simple reflexive access lists are what VMware and Cisco are calling microsegmentation and touting as one of the main use case of their SDN solutions.</p></li>
<li><p>Next our frame enters the integration bridge implemented using <a href="http://openvswitch.org/">OpenvSwitch</a>. Its primary function is to interconnect all virtual machines running on the host. Its secondary function is to provide isolation between different subnets and tenants by keeping them in different VLANs. VLAN IDs used for this are locally significant and don&rsquo;t propagate outside of the physical host.</p></li>
<li><p>A dot1q-tagged packet is forwarded down a layer 2 trunk to the tunnel bridge, also implemented using OpenvSwitch. It is programmed to strip the dot1q tags, replace them with VXLAN headers and forward an IP/UDP packet with VXLAN payload on to the physical network.</p></li>
<li><p>Our simple routed underlay delivers the packets to the destination host, where the tunnel bridge swaps the <abbr title=" VXLAN Network ID">VNI</abbr> with a dot1q tag and forwards the packet up to the integration bridge.</p></li>
<li><p>Integration bridge consults the local MAC table, finds the output interface, clears the dot1q tag and send the frame up to the VM.</p></li>
<li><p>The frame gets screened by incoming iptables rules and gets delivered to the VM2.</p></li>
</ol>


<h3>Unicast frame between VM1 and External host</h3>

<ol>
<li><p>The first 3 steps will still be the same. VM1 sends a frame with destination MAC address of a virtual router. This packet will get encapsulated in a VXLAN header and forwarded to the Network node.</p></li>
<li><p>The tunnel and integration bridges of the network node deliver the packet to the private interface of a virtual router. This virtual router lives in a <a href="http://blog.scottlowe.org/2013/09/04/introducing-linux-network-namespaces/">linux network namespaces</a> (similar to <abbr title="Virtual Routing and Forwarding">VRF</abbr>s) used to provide isolation between OpenStack tenants.</p></li>
<li><p>The router finds the outgoing interface (a port attached to the external bridge), and a next-hop IP which we have set when we configured a public subnet <a href="http://networkop.github.io/blog/2016/04/04/openstack-unl/">earlier</a>.</p></li>
<li><p>The router then performs a source NAT on the packet before forwarding it out. This way the private IP of the VM stays completely hidden and hosts outside of OpenStack can talk back to the VM by sending packets to (publicly routable) external subnet.</p></li>
<li><p>External bridge (also an OpenvSwitch) receives the packet and forwards it out the attached physical interface (eth1.300).</p></li>
</ol>


<h3>BUM frame from VM1 for MAC address of VM2</h3>

<ol>
<li><p>VM1 sends a multicast frame, which gets examined by the iptables rules and enters the integration bridge.</p></li>
<li><p>The integration bridge follows the same process as for the unicast frame to assign the dot1q tag and floods the frame to the tunnel bridge.</p></li>
<li><p>The tunnel bridge sees the multicast bit in the destination MAC address and performs source replication by sending a duplicate copy of the frame to both compute host #2 and the network node.</p></li>
<li><p>Tunnel bridges of both receiving hosts strip the VXLAN header, add the dot1q tag and flood the frame to their respective integration bridges.</p></li>
<li><p>Integration bridges flood the frame within the VLAN identified by the dot1q header.</p></li>
<li><p>The response from VM2 follows the same process as the unicast frame.</p></li>
</ol>


<p>One thing worth noting is when an ARP packet enters the integration bridge, its source IP address (in case of IPv4) or source MAC address (in case of IPv6) gets examined to make sure it belong to that VM. This is how <strong>ARP spoofing protection</strong> is implemented in OpenStack.</p>

<h2>OpenvSwitch quick intro</h2>

<p>Before we dive deeper into the details of the packet flows inside OVS let me give a brief overview of how it works. There are two main protocols to configure OVS:</p>

<ul>
<li><p>OVSDB - a management protocol used to configure bridges, ports, VLANs, QoS, monitoring etc.</p></li>
<li><p>OpenFlow - used to install flow entries for traffic switching, similar to how you would configure a static route but allowing you to match on most of the L2-L4 protocol headers.</p></li>
</ul>


<p>Control node instructs all <a href="http://www.innervoice.in/blogs/2015/03/31/openstack-neutron-plugins-and-agents/">local OVS agents</a> about how to configure virtual networks. Each local OVS agent then uses these two protocols to configure OVS and install all the required forwarding entries. Each entry contains a set of matching fields (e.g. incoming port, MAC/IP addresses) and an action field which determines what to do with the packet. These forwarding entries are implemented as <a href="https://wiki.openstack.org/wiki/Ovs-flow-logic">tables</a>. This is how a packet traverses these tables:</p>

<ol>
<li><p>First packet always hits table 0. The entries are examined in order of their priority (highest first) to find the first match. Note that it&rsquo;s the first and not necessarily the more specific match. It&rsquo;s the responsibility of a controller to build tables so that more specific flows are matched first. Normally this is done by assigning a higher priority to a more specific flow. Exact matches (where all L2-L4 fields are specified) implicitly have the highest priority value of 65535.</p></li>
<li><p>When a flow is matched, the <strong>action</strong> field of that flow is examined. Here are some of the most commonly used actions:</p>

<table>
<thead>
<tr>
<th> Action </th>
<th></th>
<th> Description </th>
</tr>
</thead>
<tbody>
<tr>
<td> resubmit(X,) </td>
<td></td>
<td> Resubmit a packet to table X </td>
</tr>
<tr>
<td> output:Y </td>
<td></td>
<td> Send a packet out port Y </td>
</tr>
<tr>
<td> NORMAL </td>
<td></td>
<td> Use a standard flood-and-learn behaviour of a switch to populate a local dynamic MAC address table </td>
</tr>
<tr>
<td> learn(table=Z) </td>
<td></td>
<td> Create an exact-match entry for the matched flow in table Z (we&rsquo;ll see how its used later on) </td>
</tr>
</tbody>
</table>


<p> These actions can be combined in a sequence to create complex behaviours like sending the same packet to multiple ports for multicast source replication.</p></li>
<li><p>OVS also <a href="https://networkheresy.com/2014/11/13/accelerating-open-vswitch-to-ludicrous-speed/">implements</a> what Cisco calls <strong>Fast switching</strong>, where the first packet lookup triggers a cache entry to be installed in the kernel-space process to be used by all future packets from the same flow.</p></li>
</ol>


<h2>Detailed packet flow analysis</h2>

<p>Let&rsquo;s start by recapping what we know about our private virtual network. All these values can be obtained from Horizon GUI by examining the private network configuration under Project -> Network -> Networks -> private_network:</p>

<ul>
<li>VM1, IP=10.0.0.8, MAC=fa:16:3e:19:e4:91, port id = <strong>258336bc-4f</strong>38-4bec-9229-4bc76e27f568</li>
<li>VM2, IP=10.0.0.9, MAC=fa:16:3e:ab:1a:bf, port id = <strong>e5f7eaca-1a</strong>36-4b08-aa9b-14e9787f80b0</li>
<li>Router, IP=10.0.0.1, MAC=fa:16:3e:cf:89:47, port id = <strong>96dfc1d3-d2</strong>3f-4d28-a461-fa2404767df2</li>
</ul>


<p>The first 11 characters of port id will be used inside an integration bridge to build the port names, e.g.:</p>

<ul>
<li>tap258336bc-4f - interface connected to VM1</li>
<li>qr-96dfc1d3-d2 - interface connected to the router</li>
</ul>


<h3>Enumerating OVS ports</h3>

<p>In its forwarding entries OVS uses internal port numbers a lot, therefore it would make sense to collect all port number information before we start. This is how it can be done:</p>

<ul>
<li>Use <code>ovs-vsctl show</code> command to collect information about existing port names and their attributes (e.g. dot1q tag, VXLAN tunnel IPs, etc). This is the output collected on compute host #1:</li>
</ul>


<pre><code class="bash ovs-vsctl show | grep -E "Bridge|Port|tag|options"">    Bridge br-tun
        Port br-tun
        Port patch-int
                options: {peer=patch-tun}
        Port "vxlan-0a00020a"
                options: {df_default="true", in_key=flow, local_ip="10.0.1.10", out_key=flow, remote_ip="10.0.2.10"}
        Port "vxlan-0a00030a"
                options: {df_default="true", in_key=flow, local_ip="10.0.1.10", out_key=flow, remote_ip="10.0.3.10"}
    Bridge br-int
        Port br-int
        Port "tap258336bc-4f"
            tag: 5
        Port patch-tun
                options: {peer=patch-int}
</code></pre>

<ul>
<li>Use <code>ovs-ofctl dump-ports-desc &lt;bridge_ID&gt;</code> command to correlate port names and numbers. Example below is for integration bridge of compute host #1:</li>
</ul>


<pre><code class="bash ovs-ofctl dump-ports-desc br-int | grep addr"> 2(patch-tun): addr:5a:c5:44:fc:ac:72
 7(tap258336bc-4f): addr:fe:16:3e:19:e4:91
 LOCAL(br-int): addr:46:fe:10:de:1b:4f
</code></pre>

<p>I&rsquo;ve put together a diagram showing all the relevant integration bridge (<strong>br-int</strong>) and tunnel bridge (<strong>br-tun</strong>) ports on all 3 hosts.</p>

<p><img class="center" src="/images/neutron-port-details.png"></p>

<h3>Unicast frame between VM1 and VM2</h3>

<ol>
<li> Frame enters the br-int on port 7. Default iptables rules allow all outbound traffic from a VM.</li>

<li> Inside the br-int our frame is matched by the "catch-all" rule which triggers the flood-and-learn behaviour:

<figure class='code'><figcaption><span>ovs-ofctl dump-flows br-int</span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'><span class="nv">table</span><span class="o">=</span>0, <span class="nv">priority</span><span class="o">=</span>10,arp,in_port<span class="o">=</span><span class="m">7</span> <span class="nv">actions</span><span class="o">=</span>resubmit<span class="o">(</span>,24<span class="o">)</span>
</span><span class='line'><span class="nv">table</span><span class="o">=</span>0, <span class="nv">priority</span><span class="o">=</span><span class="m">0</span> <span class="nv">actions</span><span class="o">=</span>NORMAL
</span></code></pre></td></tr></table></div></figure></li>

<li> Since it's a unicast frame the MAC address table is already populated by ARP:

<figure class='code'><figcaption><span>ovs-appctl fdb/show br-int</span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'> port  VLAN  MAC                Age
</span><span class='line'>    <span class="m">2</span>     <span class="m">5</span>  fa:16:3e:ab:1a:bf    1
</span></code></pre></td></tr></table></div></figure></li>

Target IP address is behind port 2 which is where the frame gets forwarded next.

<li> Inside the tunnel bridge the frame will match three different tables. The first table simply matches the incoming port and resubmits the frame to table 2. Table 2 will match the unicast bit of the MAC address (the least significant bit of the first byte) and resubmit the frame to unicast table 20:

<figure class='code'><figcaption><span>ovs-ofctl dump-flows br-tun</span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'><span class="nv">table</span><span class="o">=</span>0, <span class="nv">priority</span><span class="o">=</span>1, <span class="nv">in_port</span><span class="o">=</span><span class="m">1</span> <span class="nv">actions</span><span class="o">=</span>resubmit<span class="o">(</span>,2<span class="o">)</span>
</span><span class='line'><span class="nv">table</span><span class="o">=</span>2, <span class="nv">priority</span><span class="o">=</span>0, <span class="nv">dl_dst</span><span class="o">=</span>00:00:00:00:00:00/01:00:00:00:00:00 <span class="nv">actions</span><span class="o">=</span>resubmit<span class="o">(</span>,20<span class="o">)</span>
</span><span class='line'><span class="nv">table</span><span class="o">=</span>20, <span class="nv">priority</span><span class="o">=</span>1, <span class="nv">vlan_tci</span><span class="o">=</span>0x0005/0x0fff,dl_dst<span class="o">=</span>fa:16:3e:ab:1a:bf <span class="nv">actions</span><span class="o">=</span>load:0-&gt;NXM_OF_VLAN_TCI<span class="o">[]</span>,load:0x54-&gt;NXM_NX_TUN_ID<span class="o">[]</span>,output:2
</span></code></pre></td></tr></table></div></figure>

The final match is done on a VLAN tag and destination MAC address. Resulting action is a combination of three consecutive steps:
<ol>
  <li> Clear the dot1q tag - load:0->NXM_OF_VLAN_TCI[]</li>
  <li> Tag the frame with VNI 0x54 - load:0x54->NXM_NX_TUN_ID[]</li>
  <li> Send the frame to compute host 2 - output:2</li>
</ol>
This last match entry is quite interesting in a way that it contains the destination MAC address of VM2, which means this entry was created <b>after</b> the ARP process. In fact, as we'll see in the next step, this entry is populated by a <b>learn</b> action triggered by the ARP response coming from VM2.
</li>

<li>A VXLAN packet arrives at compute host 2 and enters the tunnel bridge through port 2. It's matched on the incoming port and resubmitted to a table where it is assigned with an internal VLAN ID 3 based on the matched tunnel id 0x54. 

<figure class='code'><figcaption><span>ovs-ofctl dump-flows br-tun</span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'><span class="nv">table</span><span class="o">=</span>0, <span class="nv">priority</span><span class="o">=</span>1,in_port<span class="o">=</span><span class="m">2</span> <span class="nv">actions</span><span class="o">=</span>resubmit<span class="o">(</span>,4<span class="o">)</span>
</span><span class='line'><span class="nv">table</span><span class="o">=</span>4, <span class="nv">priority</span><span class="o">=</span>1,tun_id<span class="o">=</span>0x54 <span class="nv">actions</span><span class="o">=</span>mod_vlan_vid:3,resubmit<span class="o">(</span>,10<span class="o">)</span>
</span><span class='line'><span class="nv">table</span><span class="o">=</span>10, <span class="nv">priority</span><span class="o">=</span><span class="m">1</span> <span class="nv">actions</span><span class="o">=</span>learn<span class="o">(</span><span class="nv">table</span><span class="o">=</span>20,hard_timeout<span class="o">=</span>300,priority<span class="o">=</span>1,NXM_OF_VLAN_TCI<span class="o">[</span>0..11<span class="o">]</span>,NXM_OF_ETH_DST<span class="o">[]=</span>NXM_OF_ETH_SRC<span class="o">[]</span>,load:0-&gt;NXM_OF_VLAN_TCI<span class="o">[]</span>,load:NXM_NX_TUN_ID<span class="o">[]</span>-&gt;NXM_NX_TUN_ID<span class="o">[]</span>,output:NXM_OF_IN_PORT<span class="o">[])</span>,output:1
</span></code></pre></td></tr></table></div></figure>

The last match does two things:
<ol>
  <li> Creates a mirroring entry in table 20 for the reverse packet flow. This is the entry similar to the one we've just seen in step 4.  </li>
  <li> Sends the packet towards the integration bridge.</li>
</ol>
</li>  
<li>The integration bridge checks the local dynamic MAC address table to find the MAC address of VM2(1a:bf).

<figure class='code'><figcaption><span>ovs-appctl fdb/show br-int</span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'>port  VLAN  MAC                Age
</span><span class='line'>  <span class="m">5</span>     <span class="m">3</span>  fa:16:3e:ab:1a:bf    0
</span></code></pre></td></tr></table></div></figure>
</li>

<li>The frame is checked against the iptables rules configured on port 5 and gets sent up to VM2</li>
</ol>


<h3>Unicast frame to external host (192.168.247.1)</h3>

<ol>
  <li>
    The first 5 steps will be similar to the previous section. The only exception will be that the tunnel bridge of compute host 1 will send the VXLAN packet out port 3 towards the network node.
  </li>
  <li>
    The integration bridge of the network node consults the MAC address table to find the location of the virtual router (89:47) and forwards the packet out port 6.
<figure class='code'><figcaption><span>ovs-appctl fdb/show br-int</span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'> port  VLAN  MAC                Age
</span><span class='line'>    <span class="m">6</span>     <span class="m">1</span>  fa:16:3e:cf:89:47    1
</span></code></pre></td></tr></table></div></figure>
  </li>
  <li> The virtual router does the route lookup to find the outgoing interface (qg-18bff97b-57)
<figure class='code'><figcaption><span>ip route get 192.168.247.1</span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'>192.168.247.1 dev qg-18bff97b-57  src 192.168.247.90
</span></code></pre></td></tr></table></div></figure>
Remember that since our virtual router resides in a network namespace all commands must be prepended with <code>ip netns exec qrouter-uuid</code>
  
  </li>
  <li> The virtual router performs the source IP translation to hide the private IP address: 
<figure class='code'><figcaption><span>iptables -t nat -S | grep qg-18bff97b-57</span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'>-A neutron-l3-agent-POSTROUTING ! -i qg-18bff97b-57 ! -o qg-18bff97b-57 -m conntrack ! --ctstate DNAT -j ACCEPT
</span><span class='line'>-A neutron-l3-agent-snat -o qg-18bff97b-57 -j SNAT --to-source 192.168.247.90
</span></code></pre></td></tr></table></div></figure>
By default all packets will get translated to the external address of the router. For each assigned floating IP address there will be a pair of source/destination NAT entries created in the same table. 

  </li>
  <li> The router consults its local ARP table to find the MAC address of the next hop:
<figure class='code'><figcaption><span>ip neigh show 192.168.247.1</span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'>192.168.247.1 dev qg-18bff97b-57 lladdr 00:50:56:c0:00:01 DELAY
</span></code></pre></td></tr></table></div></figure>
  </li>
  <li> External bridge receives the frame from the virtual router on port 4, consults its own MAC address table built by ARP and forwards the packet to the final destination.
<figure class='code'><figcaption><span>ovs-appctl fdb/show br-ex</span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'> port  VLAN  MAC                Age
</span><span class='line'>    <span class="m">4</span>     <span class="m">0</span>  fa:16:3e:5c:90:e0    1
</span><span class='line'>    <span class="m">1</span>     <span class="m">0</span>  00:50:56:c0:00:01    1
</span></code></pre></td></tr></table></div></figure></li>
</ol>


<h3>BUM frame from VM1 for MAC address of VM2</h3>

<ol>
  <li>The integration bridge of the sending host will check the source IP of the ARP packet to make sure it hasn't been spoofed before flooding the packet within the local broadcast domain (VLAN 5).

<figure class='code'><figcaption><span>ovs-ofctl dump-flows br-int</span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'><span class="nv">table</span><span class="o">=</span>0, <span class="nv">priority</span><span class="o">=</span>10,arp,in_port<span class="o">=</span><span class="m">7</span> <span class="nv">actions</span><span class="o">=</span>resubmit<span class="o">(</span>,24<span class="o">)</span>
</span><span class='line'><span class="nv">table</span><span class="o">=</span>24, <span class="nv">priority</span><span class="o">=</span>2,arp,in_port<span class="o">=</span>7,arp_spa<span class="o">=</span>10.0.0.8 <span class="nv">actions</span><span class="o">=</span>NORMAL
</span></code></pre></td></tr></table></div></figure>
</li>
<li> The flooded packet reaches the tunnel bridge where it goes through 3 different tables. The first table matches the incoming interface, the second table matches the multicast bit of the MAC address.

<figure class='code'><figcaption><span>ovs-ofctl dump-flows br-tun</span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'><span class="nv">table</span><span class="o">=</span>0, <span class="nv">priority</span><span class="o">=</span>1,in_port<span class="o">=</span><span class="m">1</span> <span class="nv">actions</span><span class="o">=</span>resubmit<span class="o">(</span>,2<span class="o">)</span>
</span><span class='line'><span class="nv">table</span><span class="o">=</span>2, <span class="nv">priority</span><span class="o">=</span>0,dl_dst<span class="o">=</span>01:00:00:00:00:00/01:00:00:00:00:00 <span class="nv">actions</span><span class="o">=</span>resubmit<span class="o">(</span>,22<span class="o">)</span>
</span><span class='line'><span class="nv">table</span><span class="o">=</span>22, <span class="nv">dl_vlan</span><span class="o">=</span><span class="m">5</span> <span class="nv">actions</span><span class="o">=</span>strip_vlan,set_tunnel:0x54,output:3,output:2
</span></code></pre></td></tr></table></div></figure>

The final table swaps the dot1q and VXLAN identifiers and does the source replication by forwarding the packet out ports 2 and 3.
</li>
<li> The following steps are similar to the unicast frame propagation with the exception that the local MAC table of the integration bridges will flood the packet to all interfaces in the same broadcast domain. That means that duplicate ARP requests will reach both the private interface of the virtual router and VM2. The latter, recognising its own IP, will send a unicast ARP response whose source IP will be verified by the ARP spoofing rule of the integration bridge. As the result of that process, both integration bridges on compute host 1 and 2 will populate their local MAC tables with addresses of VM1 and VM2.
</li>
</ol>


<h2>Native OpenStack SDN advantages and limitation</h2>

<p>Current implementation of OpenStack networking has several advantages compared to the traditional SDN solutions:</p>

<ul>
<li>Data-plane learning allows network to function even in the absence of the controller node</li>
<li>Multicast source replication does not rely on multicast support in the underlay network</li>
<li>ARP spoofing protection is the default security setting</li>
</ul>


<p>However at this point it should also be clear that there a number of limitations that can impact the overall network scalability and performance:</p>

<ul>
<li>Multicast source replication creates unnecessary overhead by flooding ARP packets to all hosts</li>
<li>All routed traffic has to go through the network node which becomes a bottleneck for the whole network</li>
<li>There is no ability to control physical devices, even the ones that support OVSDB/Openflow</li>
<li>Network node must be layer 2 adjacent with the external network segment</li>
</ul>


<h2>Things to explore next</h2>

<p>In the following posts I&rsquo;ll continue poking around Neutron and explore a number of features designed to address some of the limitations described above:</p>

<ul>
<li><a href="http://networkop.github.io/blog/2016/05/06/neutron-l2pop/">L2 population</a></li>
<li><a href="https://wiki.openstack.org/wiki/Neutron/DVR">Distributed Virtual Router</a></li>
<li><a href="https://wiki.openstack.org/wiki/Neutron/L2-GW">L2 hardware gateway</a></li>
<li><a href="https://wiki.openstack.org/wiki/Neutron/L3_High_Availability_VRRP">Network High Availability</a></li>
<li><a href="https://wiki.openstack.org/wiki/Neutron/LBaaS">Load-Balancing-as-a-Service</a></li>
<li><a href="https://github.com/openstack/networking-ovn">Open Virtual Network for OVS</a></li>
<li><a href="http://specs.openstack.org/openstack/neutron-specs/specs/mitaka/bgp-dynamic-routing.html">Neutron&rsquo;s dynamic BGP routing</a></li>
</ul>


<h2>C<sub>2</sub>O</h2>

<p>While writing this post I&rsquo;ve compiled a list of commands most useful to query the state of OpenvSwitch. So now, inspired by a similar  IOS to JUNOS (I2J) command <a href="http://www.net-gyver.com/?page_id=1166">conversion tables</a>, I&rsquo;ve put together my own Cisco to OVS conversion table, just for fun.</p>

<table>
<thead>
<tr>
<th> Action </th>
<th> Cisco </th>
<th> OpenvSwitch </th>
</tr>
</thead>
<tbody>
<tr>
<td> Show MAC address table </td>
<td> show mac address-table dynamic   </td>
<td> <code>ovs-appctl fdb/show &lt;bridge_id&gt;</code> </td>
</tr>
<tr>
<td> Show port numbers </td>
<td> show interface status </td>
<td> <code>ovs-ofctl dump-ports-desc &lt;bridge_ID&gt;</code> </td>
</tr>
<tr>
<td> Show OVS configuration </td>
<td> show run </td>
<td> <code>ovs-vsctl show</code> </td>
</tr>
<tr>
<td> Show packet forwarding rules </td>
<td> show ip route  </td>
<td> <code>ovs-ofctl dump-flows &lt;bridge_id&gt;</code> </td>
</tr>
<tr>
<td> Simulate packet flow </td>
<td> packet-tracer   </td>
<td> <code>ovs-appctl ofproto/trace &lt;bridge_id&gt; in_port=1</code> </td>
</tr>
<tr>
<td> View command history </td>
<td> show archive log config </td>
<td> <code>ovsdb-tool show-log -m</code> </td>
</tr>
</tbody>
</table>


<h2>References</h2>

<p>In this post I have glossed over some details like iptables and DHCP for the sake of brevity and readability. However this post wouldn&rsquo;t be complete if I didn&rsquo;t include references to other resources that contain a more complete, even if at times outdated, overview of OpenStack networking. This is also a way to pay tribute to blogs where I&rsquo;ve learned most of what I was writing about here:</p>

<ul>
<li><a href="https://www.rdoproject.org/networking/networking-in-too-much-detail/">Networking in too much detail</a></li>
<li><a href="http://www.opencloudblog.com/?p=300">Neutron using VXLAN</a></li>
<li><a href="http://docs.ocselected.org/openstack-manuals/kilo/networking-guide/content/under_the_hood_openvswitch.html">Under the hood of OVS</a></li>
<li><a href="https://kimizhang.wordpress.com/2014/04/01/how-ml2vxlan-works/">How ML2/VXLAN works</a></li>
<li><a href="http://docs.openstack.org/openstack-ops/content/network_troubleshooting.html">Official network troubleshooting guide</a></li>
<li><a href="http://therandomsecurityguy.com/openvswitch-cheat-sheet/">OVS commands cheat sheet</a></li>
</ul>

]]></content>
  </entry>
  
</feed>
